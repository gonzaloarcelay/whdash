{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59963d54-4417-457c-b7bc-59ae5755733f",
   "metadata": {},
   "source": [
    "# Economic Data Dashboard Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983528a-8568-4e3e-8c8c-365dccc88e77",
   "metadata": {},
   "source": [
    "# http://127.0.0.1:8042/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4f49b-1a67-45b9-8ad1-5971f7da7a30",
   "metadata": {},
   "source": [
    "# 1. Configuration and Initialization. (FredApi and Start Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0031f673-254a-4056-96e2-445e3a6f4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Initialization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fredapi import Fred\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FRED API Configuration\n",
    "api_key = '7227512392e5e5d2a2679a261d2bb3a9'\n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "# Define the start and end dates\n",
    "start = '2015-01-01'\n",
    "end = '2024-07-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573ac658-7b63-4d15-ab42-726ac2bde116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import investpy\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Get economic calendar data for the United States from the year 2020 onwards\n",
    "economic_calendar_data = investpy.economic_calendar(\n",
    "    countries=['united states'],\n",
    "    from_date='01/01/2017',\n",
    "    to_date='31/12/2024'\n",
    ")\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "calendar_df = pd.DataFrame(economic_calendar_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b1d496-f969-400a-b597-5f59ead996e2",
   "metadata": {},
   "source": [
    "# 2. Fetching Data from FRED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d3b19-45f7-4d1e-b718-4435fa1ee5a3",
   "metadata": {},
   "source": [
    "# CPI Page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153930b-c6a7-464d-b6f8-d98e54088834",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5703a502-f1d2-4a16-8403-dd48b3852284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_1():\n",
    "    # Initialize FRED with the provided API Key\n",
    "    fred = Fred(api_key=api_key)\n",
    "    \n",
    "    # Retrieve CPI and Core CPI data\n",
    "    cpi_data = fred.get_series('CPIAUCSL')\n",
    "    core_cpi_data = fred.get_series('CPILFESL')\n",
    "    \n",
    "    # Resample data monthly and compute the six-month annualized growth rate\n",
    "    def annualized_growth_rate(series, window=6):\n",
    "        return (series.pct_change(window) + 1) ** (12/window) - 1\n",
    "    \n",
    "    cpi_growth = annualized_growth_rate(cpi_data)\n",
    "    core_cpi_growth = annualized_growth_rate(core_cpi_data)\n",
    "    \n",
    "    # Compute YoY percentage change for both series\n",
    "    cpi_yoy = cpi_data.pct_change(periods=12) * 100\n",
    "    core_cpi_yoy = core_cpi_data.pct_change(periods=12) * 100\n",
    "    \n",
    "    # Filter data from 2015 onwards\n",
    "    cpi_growth = cpi_growth[cpi_growth.index >= '2015-01-01']\n",
    "    core_cpi_growth = core_cpi_growth[core_cpi_growth.index >= '2015-01-01']\n",
    "    cpi_yoy = cpi_yoy[cpi_yoy.index >= '2015-01-01']\n",
    "    core_cpi_yoy = core_cpi_yoy[core_cpi_yoy.index >= '2015-01-01']\n",
    "    \n",
    "    # Prepare date range for plotting\n",
    "    dates = cpi_growth.index\n",
    "    \n",
    "    # Get the most recent readings for both series\n",
    "    recent_cpi_value = cpi_growth.dropna().iloc[-1] * 100\n",
    "    recent_core_cpi_value = core_cpi_growth.dropna().iloc[-1] * 100\n",
    "    recent_cpi_yoy_value = cpi_yoy.dropna().iloc[-1]\n",
    "    recent_core_cpi_yoy_value = core_cpi_yoy.dropna().iloc[-1]\n",
    "    \n",
    "    # Prepare data for the table with new order and labels\n",
    "    table_data = pd.DataFrame({\n",
    "        \"CPI YoY (%)\": cpi_yoy.dropna().tail(30).values,\n",
    "        \"CPI 6M (%)\": cpi_growth.dropna().tail(30).values * 100,\n",
    "        \"Core CPI YoY (%)\": core_cpi_yoy.dropna().tail(30).values,\n",
    "        \"Core CPI 6M (%)\": core_cpi_growth.dropna().tail(30).values * 100\n",
    "    }).T.round(1)\n",
    "    \n",
    "    # Extract the dates as column headers\n",
    "    dates_for_table = cpi_growth.dropna().tail(30).index.strftime(\"%y-%m\")\n",
    "    \n",
    "    # Heatmap color functions\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "    \n",
    "    # Generate colors for the table based on the data rows\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_data.iterrows()]\n",
    "    \n",
    "    # Transpose the list of colors to match Plotly's requirement (each sublist represents a column of colors)\n",
    "    flat_colors = list(map(list, zip(*colors)))\n",
    "    \n",
    "    # Create subplots: 2 columns for charts and 1 row for the table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2, \n",
    "        row_heights=[0.6, 0.4],  # 60% for charts, 40% for table\n",
    "        specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}], [{\"type\": \"table\", \"colspan\": 2}, None]],  # Use full width for the table\n",
    "        subplot_titles=('Headline CPI', 'Core CPI'),\n",
    "        vertical_spacing=0.05  # Smaller gap between plots and table\n",
    "    )\n",
    "    \n",
    "    # Add Headline CPI chart (6M Annualized, Light Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=cpi_growth * 100, mode='lines', name='6M Annualized CPI', \n",
    "        line=dict(color='cyan', width=2),\n",
    "        text=[f\"Latest: {recent_cpi_value:.2f}%\" for _ in dates],\n",
    "        hoverinfo='text+y'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add Core CPI chart (6M Annualized, Light Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=core_cpi_growth * 100, mode='lines', name='6M Annualized Core CPI', \n",
    "        line=dict(color='cyan', width=2),\n",
    "        text=[f\"Latest: {recent_core_cpi_value:.2f}%\" for _ in dates],\n",
    "        hoverinfo='text+y'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add YoY CPI (White)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=cpi_yoy, mode='lines', name='YoY CPI', \n",
    "        line=dict(color='white', width=1),\n",
    "        hoverinfo='none'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add YoY Core CPI (White)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=core_cpi_yoy, mode='lines', name='YoY Core CPI', \n",
    "        line=dict(color='white', width=1),\n",
    "        hoverinfo='none'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add a single 2% Fed target line to both charts (only one shown in legend)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[2]*len(dates), mode='lines', name='Fed Reserve Goal', \n",
    "        line=dict(color='crimson', dash='dash')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Duplicate the Fed target line for the second chart without showing it in the legend\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[2]*len(dates), mode='lines', name='', showlegend=False, \n",
    "        line=dict(color='crimson', dash='dash')\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add the initial table below the charts\n",
    "    table = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Items\"] + list(dates_for_table),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_data.index,  # Row labels\n",
    "                *[table_data[col] for col in table_data.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(dates_for_table)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4] + [0.5] * len(dates_for_table)  # Adjusted column widths\n",
    "    )\n",
    "    fig.add_trace(table, row=2, col=1)  # Table spans both columns\n",
    "    \n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "    \n",
    "    # Calculate global y-axis range for both plots\n",
    "    # Combine all y-values from lines and bars to determine global min and max\n",
    "    y_values = []\n",
    "    for column in ['cpi_growth', 'core_cpi_growth', 'cpi_yoy', 'core_cpi_yoy']:\n",
    "        if column == 'cpi_growth':\n",
    "            y_values.extend(cpi_growth.dropna().values * 100)\n",
    "        elif column == 'core_cpi_growth':\n",
    "            y_values.extend(core_cpi_growth.dropna().values * 100)\n",
    "        elif column == 'cpi_yoy':\n",
    "            y_values.extend(cpi_yoy.dropna().values)\n",
    "        elif column == 'core_cpi_yoy':\n",
    "            y_values.extend(core_cpi_yoy.dropna().values)\n",
    "    global_y_min = min(y_values)\n",
    "    global_y_max = max(y_values)\n",
    "    # Add some padding\n",
    "    padding = (global_y_max - global_y_min) * 0.05\n",
    "    global_y_min -= padding\n",
    "    global_y_max += padding\n",
    "    \n",
    "    # Define rolling windows (e.g., 30-month rolling windows)\n",
    "    window_size = 30  # Number of months in each window\n",
    "    windows = []\n",
    "    for i in range(len(cpi_growth) - window_size + 1):\n",
    "        window = {\n",
    "            'cpi_yoy': cpi_yoy.iloc[i:i+window_size],\n",
    "            'cpi_growth': cpi_growth.iloc[i:i+window_size],\n",
    "            'core_cpi_yoy': core_cpi_yoy.iloc[i:i+window_size],\n",
    "            'core_cpi_growth': core_cpi_growth.iloc[i:i+window_size],\n",
    "            'dates': cpi_growth.index[i:i+window_size]\n",
    "        }\n",
    "        windows.append(window)\n",
    "    \n",
    "    # Function to prepare table data for a given window\n",
    "    def prepare_table_data(window):\n",
    "        window_data = {\n",
    "            \"CPI YoY (%)\": window['cpi_yoy'].values,\n",
    "            \"CPI 6M (%)\": window['cpi_growth'].values * 100,\n",
    "            \"Core CPI YoY (%)\": window['core_cpi_yoy'].values,\n",
    "            \"Core CPI 6M (%)\": window['core_cpi_growth'].values * 100\n",
    "        }\n",
    "        table_df = pd.DataFrame(window_data).T.round(1)\n",
    "        window_dates = window['dates'].strftime(\"%y-%m\")\n",
    "        return table_df, window_dates\n",
    "    \n",
    "    # Generate frames for each window\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        table_df, window_dates = prepare_table_data(window)\n",
    "        \n",
    "        # Generate colors for the table\n",
    "        window_colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "        window_flat_colors = list(map(list, zip(*window_colors)))  # Transpose\n",
    "        \n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                table_df.index,  # Row labels\n",
    "                *[table_df[col] for col in table_df.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(window_dates)] + window_flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Items\"] + list(window_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window['dates'].min()\n",
    "        window_end = window['dates'].max()\n",
    "        \n",
    "        # Define the shaded rectangle shapes for both plots\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=global_y_min,\n",
    "            y1=global_y_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        shaded_shape_plot2 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x2\",  # References the x-axis of the second subplot\n",
    "            yref=\"y2\",  # References the y-axis of the second subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=global_y_min,\n",
    "            y1=global_y_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        # Create the frame with updated table and shaded shapes\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape_plot1, shaded_shape_plot2]  # Add shaded areas to both plots\n",
    "            ),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]  # Update the existing table trace\n",
    "        )\n",
    "        frames.append(frame)\n",
    "    \n",
    "    fig.frames = frames\n",
    "    \n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i in range(len(windows)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows[i]['dates'].min().strftime(\"%Y-%m\")  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "    \n",
    "    # Optionally, reverse the slider steps to have newest on the left\n",
    "    slider_steps = slider_steps[::-1]\n",
    "    \n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps\n",
    "    )]\n",
    "    \n",
    "    # Add the slider to the layout\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "    \n",
    "    # Add annotations for the latest values on both plots\n",
    "    fig.add_annotation(\n",
    "        x=dates[-1], y=recent_cpi_value, xref=\"x1\", yref=\"y1\", \n",
    "        text=f\"Latest: {recent_cpi_value:.2f}%\", showarrow=False,\n",
    "        font=dict(size=8, color=\"cyan\"),\n",
    "        xanchor=\"center\", yanchor=\"bottom\",  # Align tag above the line\n",
    "        ax=0, ay=40  # Shift the tag 40 pixels up\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=dates[-1], y=recent_core_cpi_value, xref=\"x2\", yref=\"y2\", \n",
    "        text=f\"Latest: {recent_core_cpi_value:.2f}%\", showarrow=False,\n",
    "        font=dict(size=8, color=\"cyan\"),\n",
    "        xanchor=\"center\", yanchor=\"bottom\",  # Align tag above the line\n",
    "        ax=0, ay=40  # Shift the tag 40 pixels up\n",
    "    )\n",
    "    \n",
    "    # Add source annotation at the bottom of the chart with hyperlinks\n",
    "    fig.add_annotation(\n",
    "        text=('Source: Federal Reserve Economic Data (FRED). '\n",
    "              '<a href=\"https://fred.stlouisfed.org/graph/?g=1tEZX\" style=\"color: white\">Headline CPI</a>, '\n",
    "              '<a href=\"https://fred.stlouisfed.org/graph/?g=1tF03\" style=\"color: white\">Core CPI</a>.'),\n",
    "        font=dict(size=8, color=\"white\"),  # Font size and color\n",
    "        xref=\"paper\", yref=\"paper\",  # Use paper coordinates\n",
    "        x=0.5, y=-0.03,  # Position the source annotation at the bottom\n",
    "        showarrow=False\n",
    "    )\n",
    "    \n",
    "    # Update layout and labels\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        yaxis_title=\"Growth Rate (%)\",\n",
    "        yaxis2_title=\"Growth Rate (%)\",\n",
    "        template=\"plotly_dark\",\n",
    "        font=dict(color=\"white\", size=8),\n",
    "        title_x=0.5,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",  # Set the legend to be horizontal\n",
    "            yanchor=\"top\",  # Anchor the legend to the top\n",
    "            y=1.2,  # Set the legend position slightly below the title\n",
    "            xanchor=\"center\",  # Center the legend\n",
    "            x=0.5,\n",
    "            font=dict(size=8)  # Set the font size for the legend\n",
    "        ),\n",
    "        height=600,  # Adjusted height\n",
    "        width=1000,  # Adjusted width\n",
    "        margin=dict(t=50, b=50, l=20, r=20)  # Adjusted side margins\n",
    "    )\n",
    "    \n",
    "    # Fix the y-axis range for both plots to prevent dynamic scaling\n",
    "    fig.update_yaxes(range=[global_y_min, global_y_max], row=1, col=1)\n",
    "    fig.update_yaxes(range=[global_y_min, global_y_max], row=1, col=2)\n",
    "    \n",
    "    # Update Y-axis labels to reflect that we're displaying Contributions (percentage points)\n",
    "    fig.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=2)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ef068af-4338-4240-ba0c-e7ad392a7e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Surprise Index: 0.006807070417542748\n"
     ]
    }
   ],
   "source": [
    "def generate_cpi_detailed_graph_2():\n",
    "    # Initialize Fred API with your API key\n",
    "    fred = Fred(api_key=api_key)  # Replace with your actual FRED API key\n",
    "\n",
    "    # Define the FRED series IDs for the different CPI components, including Core Goods\n",
    "    series_ids = {\n",
    "        \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
    "        \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
    "        \"Food\": \"CPIUFDNS\",                    # Food CPI\n",
    "        \"Energy\": \"CPIENGSL\",                  # Energy CPI\n",
    "        \"Core Services\": \"CUSR0000SASLE\",      # Core Services CPI\n",
    "        \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
    "    }\n",
    "\n",
    "    # Fetch the data from FRED\n",
    "    cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    cpi_df = pd.DataFrame(cpi_data)\n",
    "\n",
    "    # Ensure the DataFrame index is in datetime format\n",
    "    cpi_df.index = pd.to_datetime(cpi_df.index)\n",
    "\n",
    "    # Define the display start date\n",
    "    display_start_date = datetime(2015, 1, 1)\n",
    "\n",
    "    # Calculate MoM data\n",
    "    cpi_df_mom = cpi_df.pct_change(periods=1) * 100  # MoM percentage change\n",
    "\n",
    "    # Calculate additional statistics for MoM\n",
    "    cpi_df_mom['All Items (3-mo MA)'] = cpi_df_mom['All Items'].rolling(window=3).mean()\n",
    "    cpi_df_mom['Core CPI (3-mo MA)'] = cpi_df_mom['Core CPI'].rolling(window=3).mean()\n",
    "\n",
    "    # Drop rows with NaN values after calculations\n",
    "    cpi_df_mom = cpi_df_mom.dropna()\n",
    "\n",
    "    # Further filter data to display only from display_start_date onwards\n",
    "    cpi_df_mom = cpi_df_mom[cpi_df_mom.index >= display_start_date]\n",
    "\n",
    "    # Define window size\n",
    "    window_size = 30  # Number of months in each window\n",
    "\n",
    "    # Create subplots: 3 rows (2 for plots, 1 for table)\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=[0.35, 0.35, 0.3],  # Adjust the heights of the rows\n",
    "        subplot_titles=(\"Core CPI & All Items CPI %\", \"Selected Components % (Stacked)\", \"CPI Table\"),\n",
    "        vertical_spacing=0.05,  # Smaller gap between plots and the table\n",
    "        specs=[[{\"type\": \"scatter\"}], [{\"type\": \"bar\"}], [{\"type\": \"table\"}]]\n",
    "    )\n",
    "\n",
    "    # Plot 1: Core CPI and All Items CPI (MoM)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['All Items'],\n",
    "        mode='lines', name='All Items CPI %',\n",
    "        line=dict(color='white')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['Core CPI'],\n",
    "        mode='lines', name='Core CPI %',\n",
    "        line=dict(color='magenta')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Add 3-month moving average (MoM)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['All Items (3-mo MA)'],\n",
    "        mode='lines', name='All Items (3-mo MA)',\n",
    "        line=dict(color='white', dash='dot')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['Core CPI (3-mo MA)'],\n",
    "        mode='lines', name='Core CPI (3-mo MA)',\n",
    "        line=dict(color='magenta', dash='dot')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Plot 2: Stacked bar plot for components (MoM)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['Core Goods'], name='Core Goods %', marker_color='purple'\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['Core Services'], name='Core Services %', marker_color='green'\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['Energy'], name='Energy %', marker_color='orange'\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cpi_df_mom.index, y=cpi_df_mom['Food'], name='Food %', marker_color='blue'\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    # Prepare data for the table (MoM)\n",
    "    if len(cpi_df_mom) < window_size:\n",
    "        raise ValueError(f\"Not enough data points to create a window of size {window_size}.\")\n",
    "\n",
    "    # Generate windows for MoM\n",
    "    windows_mom = [cpi_df_mom.iloc[i:i + window_size] for i in range(len(cpi_df_mom) - window_size + 1)]\n",
    "\n",
    "    # Function to generate colors for each row based on values\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 - norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Prepare the initial table data (MoM)\n",
    "    initial_window = windows_mom[0]\n",
    "    table_df = initial_window[['All Items', 'Core CPI', 'Core Goods', 'Core Services', 'Food', 'Energy']].round(1)\n",
    "    table_df = table_df.T  # Transpose for desired format\n",
    "    table_header_dates = table_df.columns.strftime(\"%y-%m\")\n",
    "\n",
    "    # Generate colors for the initial table\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "    flat_colors = list(map(list, zip(*colors)))  # Transpose to match Plotly's requirement\n",
    "\n",
    "    # Add the initial table\n",
    "    table_trace = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Items\"] + list(table_header_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_df.index,  # Row labels\n",
    "                *[table_df[col] for col in table_df.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(table_header_dates)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4] + [0.5] * len(table_header_dates)  # Adjust column widths\n",
    "    )\n",
    "    fig.add_trace(table_trace, row=3, col=1)  # Table is the third subplot\n",
    "\n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "\n",
    "    # Function to prepare table data for a given window\n",
    "    def prepare_table_data(window):\n",
    "        window_data = window[['All Items', 'Core CPI', 'Core Goods', 'Core Services', 'Food', 'Energy']].round(1)\n",
    "        window_df = window_data.copy()\n",
    "        window_df = window_df.T  # Transpose for desired format\n",
    "        window_dates = window_df.columns.strftime(\"%y-%m\")\n",
    "        return window_df, window_dates\n",
    "\n",
    "    # Generate frames for the slider (MoM)\n",
    "    frames_mom = []\n",
    "    for i, window in enumerate(windows_mom):\n",
    "        frame_table_df, window_dates = prepare_table_data(window)\n",
    "\n",
    "        # Generate colors for the table\n",
    "        frame_colors = [get_row_heatmap_colors(row) for _, row in frame_table_df.iterrows()]\n",
    "        frame_flat_colors = list(map(list, zip(*frame_colors)))  # Transpose\n",
    "\n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                frame_table_df.index,  # Row labels\n",
    "                *[frame_table_df[col] for col in frame_table_df.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(window_dates)] + frame_flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Items\"] + list(window_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window.index.min()\n",
    "        window_end = window.index.max()\n",
    "\n",
    "        # Define the shaded rectangle shapes for both plots\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=cpi_df_mom['All Items'].min(),\n",
    "            y1=cpi_df_mom['All Items'].max(),\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "\n",
    "        shaded_shape_plot2 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # Shared x-axis\n",
    "            yref=\"y2\",  # References the y-axis of the second subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=cpi_df_mom[['Core Goods', 'Core Services', 'Energy', 'Food']].min().min(),\n",
    "            y1=cpi_df_mom[['Core Goods', 'Core Services', 'Energy', 'Food']].max().max(),\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "\n",
    "        # Create the frame with updated table and shaded shapes\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape_plot1, shaded_shape_plot2]\n",
    "            ),\n",
    "            name=f\"MoM_{i}\",\n",
    "            traces=[table_trace_index]  # Update the existing table trace\n",
    "        )\n",
    "        frames_mom.append(frame)\n",
    "\n",
    "    # Assign frames to figure\n",
    "    fig.frames = frames_mom\n",
    "\n",
    "    # Define slider steps for MoM\n",
    "    slider_steps_mom = []\n",
    "    for i in range(len(windows_mom)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [f\"MoM_{i}\"],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows_mom[i].index.min().strftime(\"%Y-%m\")  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps_mom.append(step)\n",
    "\n",
    "    # Optionally, reverse the slider steps to have newest on the left\n",
    "    slider_steps_mom = slider_steps_mom[::-1]\n",
    "\n",
    "    # Add sliders to the layout\n",
    "    sliders_mom = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps_mom,\n",
    "        visible=True\n",
    "    )]\n",
    "\n",
    "    # Update layout with the sliders\n",
    "    fig.update_layout(\n",
    "        sliders=sliders_mom\n",
    "    )\n",
    "\n",
    "    # Add source annotation\n",
    "    source_links = (\n",
    "        \"<a href='https://fred.stlouisfed.org/series/CPIAUCSL' style='color:white'>All Items</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/series/CPILFESL' style='color:white'>Core CPI</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/series/CPIUFDNS' style='color:white'>Food</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/series/CPIENGSL' style='color:white'>Energy</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/series/CUSR0000SASLE' style='color:white'>Core Services</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/series/CUSR0000SACL1E' style='color:white'>Core Goods</a>\"\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=(\"Source: Federal Reserve Economic Data (FRED). \" + source_links),\n",
    "        font=dict(size=8, color=\"white\"),\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=-0.03,  # Position the source annotation at the bottom\n",
    "        showarrow=False\n",
    "    )\n",
    "\n",
    "    # Update layout with dynamic title and other aesthetics\n",
    "    fig.update_layout(\n",
    "        title=\"CPI Month-over-Month (MoM) Changes\",\n",
    "        title_font=dict(size=12),\n",
    "        width=1000,\n",
    "        height=900,  # Increased height for larger plots\n",
    "        margin=dict(t=80, b=80, l=20, r=20),  # Adjusted side margins\n",
    "        template='plotly_dark',\n",
    "        barmode='relative',  # Enable stacked bars for the component plot\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",  # Set the legend to be horizontal\n",
    "            yanchor=\"top\",    # Align to top\n",
    "            y=1.05,           # Set the legend position slightly above the plots\n",
    "            xanchor=\"center\", # Center the legend\n",
    "            x=0.5,\n",
    "            font=dict(size=8)  # Set font size for the legend\n",
    "        ),\n",
    "        font=dict(size=8)  # Global font size for axis labels, tick marks, etc.\n",
    "    )\n",
    "\n",
    "    # Set initial y-axis ranges for MoM\n",
    "    fig.update_yaxes(range=[cpi_df_mom[['All Items', 'Core CPI']].min().min(), cpi_df_mom[['All Items', 'Core CPI']].max().max()], row=1, col=1)\n",
    "    fig.update_yaxes(range=[cpi_df_mom[['Core Goods', 'Core Services', 'Energy', 'Food']].min().min(), cpi_df_mom[['Core Goods', 'Core Services', 'Energy', 'Food']].max().max()], row=2, col=1)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a42a5bfd-f973-4ce3-9868-1fdc8f6f0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_3():\n",
    "    # Initialize Fred API with your API key\n",
    "    fred = Fred(api_key=api_key)  # Replace with your actual FRED API key\n",
    "\n",
    "    # Define the FRED series IDs for the different CPI components\n",
    "    series_ids = {\n",
    "        'All Items': 'CPIAUCSL',         # All Items CPI\n",
    "        'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
    "        'Food': 'CPIUFDNS',              # Food CPI\n",
    "        'Energy': 'CPIENGSL',            # Energy CPI\n",
    "        'Core Goods': 'CUSR0000SACL1E',  # Core Goods\n",
    "        'Core Services': 'CUSR0000SASLE' # Core Services\n",
    "    }\n",
    "\n",
    "    # Fetch data for each series from FRED and store in a DataFrame\n",
    "    cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
    "    df = pd.DataFrame(cpi_data)\n",
    "\n",
    "    # Ensure the DataFrame index is in datetime format\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Define relative importance weights (in percentages)\n",
    "    relative_importance = {\n",
    "        \"Core Services\": 61,   # Included in Core CPI\n",
    "        \"Core Goods\": 18.4,    # Included in Core CPI\n",
    "        \"Food\": 13.4,\n",
    "        \"Energy\": 6.9,\n",
    "        \"All Items\": 100.0     # Already includes Food, Energy, and Core CPI\n",
    "    }\n",
    "\n",
    "    # Define the display start date\n",
    "    display_start_date = datetime(2015, 1, 1)\n",
    "\n",
    "    # Calculate MoM percentage changes\n",
    "    df_mom = df.pct_change(periods=1) * 100\n",
    "\n",
    "    # Drop rows with NaN values after calculations\n",
    "    df_mom = df_mom.dropna()\n",
    "\n",
    "    # Filter data from display_start_date onwards\n",
    "    df_mom = df_mom[df_mom.index >= display_start_date]\n",
    "\n",
    "    # Calculate contributions by multiplying percentage changes by relative importance\n",
    "    contribution_mom = df_mom.copy()\n",
    "    for column in ['Energy', 'Food', 'Core Goods', 'Core Services', 'All Items']:\n",
    "        contribution_mom[column] = contribution_mom[column] * relative_importance[column] / 100\n",
    "\n",
    "    # Round the contribution data to 2 decimal places for plotting\n",
    "    contribution_mom = contribution_mom.round(2)\n",
    "\n",
    "    # Create subplots: main plot and table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=[0.7, 0.3],\n",
    "        vertical_spacing=0.05,\n",
    "        specs=[[{\"type\": \"scatter\"}], [{\"type\": \"table\"}]]\n",
    "    )\n",
    "\n",
    "    # Plot 1: Lines for All Items and Core CPI (MoM)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=contribution_mom.index, y=contribution_mom['All Items'],\n",
    "        mode='lines', name='All Items CPI (MoM)',\n",
    "        line=dict(color='white')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=contribution_mom.index, y=contribution_mom['Core CPI'],\n",
    "        mode='lines', name='Core CPI (MoM)',\n",
    "        line=dict(color='magenta', dash='dot')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Plot 1: Stacked Bar Plot for Contributions (MoM)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_mom.index, y=contribution_mom['Core Services'],\n",
    "        name='Core Services', marker_color='green'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_mom.index, y=contribution_mom['Core Goods'],\n",
    "        name='Core Goods', marker_color='purple'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_mom.index, y=contribution_mom['Food'],\n",
    "        name='Food', marker_color='blue'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_mom.index, y=contribution_mom['Energy'],\n",
    "        name='Energy', marker_color='orange'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Ensure barmode is 'relative' for stacked bars\n",
    "    fig.update_layout(barmode='relative')\n",
    "\n",
    "    # Prepare data for the table (MoM)\n",
    "    window_size = 30  # Number of months in each window for the table\n",
    "    data_length_mom = len(contribution_mom)\n",
    "    max_start_index_mom = data_length_mom - window_size\n",
    "\n",
    "    # Generate windows for MoM\n",
    "    windows_mom = [contribution_mom.iloc[i:i + window_size] for i in range(max_start_index_mom + 1)]\n",
    "\n",
    "    # Function to generate colors for each row based on values\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 - norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Prepare the initial table data (MoM)\n",
    "    initial_window = windows_mom[0]\n",
    "    table_df = initial_window[['All Items', 'Core CPI', 'Core Goods', 'Core Services', 'Food', 'Energy']].round(2)\n",
    "    table_df = table_df.T  # Transpose for desired format\n",
    "    table_header_dates = table_df.columns.strftime(\"%y-%m\")  # Format dates as 'YY-MM'\n",
    "\n",
    "    # Generate colors for the initial table\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "    flat_colors = list(map(list, zip(*colors)))  # Transpose to match Plotly's requirement\n",
    "\n",
    "    # Add the initial table\n",
    "    table_trace = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Item\", \"Relative Importance (%)\"] + list(table_header_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_df.index,  # Row labels (Item names)\n",
    "                [relative_importance.get(item, 0) for item in table_df.index],  # Relative Importance (%)\n",
    "                *[table_df[col] for col in table_df.columns]  # Contribution values\n",
    "            ],\n",
    "            fill_color=[['black']] * 2 + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'] + ['center'] * len(table_header_dates),\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4, 4] + [1] * len(table_header_dates)  # Adjust column widths\n",
    "    )\n",
    "    fig.add_trace(table_trace, row=2, col=1)  # Table is the second subplot\n",
    "\n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "\n",
    "    # Generate frames for MoM\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows_mom):\n",
    "        frame_table_df = window[['All Items', 'Core CPI', 'Core Goods', 'Core Services', 'Food', 'Energy']].round(2)\n",
    "        frame_table_df = frame_table_df.T  # Transpose\n",
    "        frame_header_dates = frame_table_df.columns.strftime(\"%y-%m\")  # Format dates as 'YY-MM'\n",
    "\n",
    "        # Generate colors for the table\n",
    "        frame_colors = [get_row_heatmap_colors(row) for _, row in frame_table_df.iterrows()]\n",
    "        frame_flat_colors = list(map(list, zip(*frame_colors)))  # Transpose\n",
    "\n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                frame_table_df.index,  # Row labels (Item names)\n",
    "                [relative_importance.get(item, 0) for item in frame_table_df.index],  # Relative Importance (%)\n",
    "                *[frame_table_df[col] for col in frame_table_df.columns]  # Contribution values\n",
    "            ],\n",
    "            fill_color=[['black']] * 2 + frame_flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'] + ['center'] * len(frame_header_dates),\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Item\", \"Relative Importance (%)\"] + list(frame_header_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window.index.min()\n",
    "        window_end = window.index.max()\n",
    "\n",
    "        # Define the shaded rectangle shape for the plot\n",
    "        shaded_shape = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x\",  # Shared x-axis\n",
    "            yref=\"y\",  # References the y-axis of the first subplot\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=contribution_mom[['All Items', 'Core CPI', 'Core Goods', 'Core Services', 'Food', 'Energy']].min().min(),\n",
    "            y1=contribution_mom[['All Items', 'Core CPI', 'Core Goods', 'Core Services', 'Food', 'Energy']].max().max(),\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            layer=\"below\",\n",
    "            line_width=0\n",
    "        )\n",
    "\n",
    "        # Create the frame\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape]\n",
    "            ),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Define slider steps for MoM\n",
    "    slider_steps_mom = []\n",
    "    for i in range(len(windows_mom)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows_mom[i].index.min().strftime(\"%y-%m\")\n",
    "        )\n",
    "        slider_steps_mom.append(step)\n",
    "\n",
    "    # Reverse the slider steps to have the newest on the left\n",
    "    slider_steps_mom = slider_steps_mom[::-1]\n",
    "\n",
    "    # Create slider\n",
    "    sliders_mom = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps_mom,\n",
    "    )]\n",
    "\n",
    "    # Add slider to the layout\n",
    "    fig.update_layout(\n",
    "        sliders=sliders_mom\n",
    "    )\n",
    "\n",
    "    # Add footnote with a link to BLS CPI report\n",
    "    fig.add_annotation(\n",
    "        text=\"Source: <a href='https://www.bls.gov/news.release/pdf/cpi.pdf' style='color:white;' target='_blank'>BLS CPI Report</a> (Weights updated manually)\",\n",
    "        showarrow=False,\n",
    "        xref='paper', yref='paper',\n",
    "        x=0.5, y=-0.05,\n",
    "        xanchor='center', yanchor='top',\n",
    "        font=dict(size=8),\n",
    "        align='center'\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        barmode='relative',\n",
    "        height=900,\n",
    "        template='plotly_dark',\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=1.05,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "            font=dict(size=8)\n",
    "        ),\n",
    "        font=dict(size=8),\n",
    "        margin=dict(l=20, r=20, t=80, b=80),\n",
    "        title=\"CPI Contributions (Month-over-Month Changes)\"\n",
    "    )\n",
    "\n",
    "    # Set initial y-axis range for MoM\n",
    "    fig.update_yaxes(range=[-1.5, 1.5], row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Contributions (percentage points)\", row=1, col=1)\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05446804-c16f-4b32-90bf-876e00a15c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_5():\n",
    "    # Initialize FRED with the provided API Key\n",
    "    fred = Fred(api_key=api_key)\n",
    "    \n",
    "    # Retrieve PCEPI and PCEPILFE data\n",
    "    pcepi_data = fred.get_series('PCEPI')\n",
    "    pcepilfe_data = fred.get_series('PCEPILFE')\n",
    "    \n",
    "    # Resample data monthly and compute the six-month annualized growth rate\n",
    "    def annualized_growth_rate(series, window=6):\n",
    "        return (series.pct_change(window) + 1) ** (12/window) - 1\n",
    "    \n",
    "    pcepi_growth = annualized_growth_rate(pcepi_data)\n",
    "    pcepilfe_growth = annualized_growth_rate(pcepilfe_data)\n",
    "    \n",
    "    # Compute YoY percentage change for both series\n",
    "    pcepi_yoy = pcepi_data.pct_change(periods=12) * 100\n",
    "    pcepilfe_yoy = pcepilfe_data.pct_change(periods=12) * 100\n",
    "    \n",
    "    # Filter data from 2015 onwards\n",
    "    pcepi_growth = pcepi_growth[pcepi_growth.index >= '2015-01-01']\n",
    "    pcepilfe_growth = pcepilfe_growth[pcepilfe_growth.index >= '2015-01-01']\n",
    "    pcepi_yoy = pcepi_yoy[pcepi_yoy.index >= '2015-01-01']\n",
    "    pcepilfe_yoy = pcepilfe_yoy[pcepilfe_yoy.index >= '2015-01-01']\n",
    "    \n",
    "    # Prepare date range for plotting\n",
    "    dates = pcepi_growth.index\n",
    "    \n",
    "    # Get the most recent readings for both series\n",
    "    recent_pcepi_value = pcepi_growth.dropna().iloc[-1] * 100\n",
    "    recent_pcepilfe_value = pcepilfe_growth.dropna().iloc[-1] * 100\n",
    "    recent_pcepi_yoy_value = pcepi_yoy.dropna().iloc[-1]\n",
    "    recent_pcepilfe_yoy_value = pcepilfe_yoy.dropna().iloc[-1]\n",
    "    \n",
    "    # Prepare data for the table with new order and labels\n",
    "    table_data = pd.DataFrame({\n",
    "        \"PCEPI YoY (%)\": pcepi_yoy.dropna().tail(30).values,\n",
    "        \"PCEPI 6M (%)\": pcepi_growth.dropna().tail(30).values * 100,\n",
    "        \"PCEPILFE YoY (%)\": pcepilfe_yoy.dropna().tail(30).values,\n",
    "        \"PCEPILFE 6M (%)\": pcepilfe_growth.dropna().tail(30).values * 100\n",
    "    }).T.round(1)\n",
    "    \n",
    "    # Extract the dates as column headers\n",
    "    dates_for_table = pcepi_growth.dropna().tail(30).index.strftime(\"%y-%m\")\n",
    "    \n",
    "    # Heatmap color functions\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "    \n",
    "    # Generate colors for the table based on the data rows\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_data.iterrows()]\n",
    "    \n",
    "    # Transpose the list of colors to match Plotly's requirement (each sublist represents a column of colors)\n",
    "    flat_colors = list(map(list, zip(*colors)))\n",
    "    \n",
    "    # Calculate long-term averages for PCEPI and PCEPILFE growth rates\n",
    "    average_pcepi_growth = pcepi_growth.mean() * 100  # Convert to percentage\n",
    "    average_pcepilfe_growth = pcepilfe_growth.mean() * 100  # Convert to percentage\n",
    "    \n",
    "    # Create subplots: 2 columns for charts and 1 row for the table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2, \n",
    "        row_heights=[0.6, 0.4],  # 60% for charts, 40% for table\n",
    "        specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}], [{\"type\": \"table\", \"colspan\": 2}, None]],  # Use full width for the table\n",
    "        subplot_titles=('PCEPI', 'PCEPILFE'),\n",
    "        vertical_spacing=0.05  # Smaller gap between plots and table\n",
    "    )\n",
    "    \n",
    "    # Add PCEPI chart (6M Annualized, Light Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=pcepi_growth * 100, mode='lines', name='6M Annualized PCEPI', \n",
    "        line=dict(color='cyan', width=2),\n",
    "        text=[f\"Latest: {recent_pcepi_value:.2f}%\" for _ in dates],\n",
    "        hoverinfo='text+y'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add PCEPILFE chart (6M Annualized, Light Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=pcepilfe_growth * 100, mode='lines', name='6M Annualized PCEPILFE', \n",
    "        line=dict(color='cyan', width=2),\n",
    "        text=[f\"Latest: {recent_pcepilfe_value:.2f}%\" for _ in dates],\n",
    "        hoverinfo='text+y'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add YoY PCEPI (White)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=pcepi_yoy, mode='lines', name='YoY PCEPI', \n",
    "        line=dict(color='white', width=1),\n",
    "        hoverinfo='none'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add YoY PCEPILFE (White)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=pcepilfe_yoy, mode='lines', name='YoY PCEPILFE', \n",
    "        line=dict(color='white', width=1),\n",
    "        hoverinfo='none'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add Long-term Average PCEPI line (Orange Dash)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[average_pcepi_growth]*len(dates), mode='lines', name='Long-term Average PCEPI', \n",
    "        line=dict(color='red', dash='dash')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add Long-term Average PCEPILFE line (Purple Dash)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[average_pcepilfe_growth]*len(dates), mode='lines', name='Long-term Average PCEPILFE', \n",
    "        line=dict(color='red', dash='dash')\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add the initial table below the charts\n",
    "    table = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Items\"] + list(dates_for_table),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_data.index,  # Row labels\n",
    "                *[table_data[col] for col in table_data.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(dates_for_table)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4] + [0.5] * len(dates_for_table)  # Adjusted column widths\n",
    "    )\n",
    "    fig.add_trace(table, row=2, col=1)  # Table spans both columns\n",
    "    \n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "    \n",
    "    # Calculate global y-axis range for both plots\n",
    "    # Combine all y-values from lines and bars to determine global min and max\n",
    "    y_values = []\n",
    "    for column in ['pcepi_growth', 'pcepilfe_growth', 'pcepi_yoy', 'pcepilfe_yoy']:\n",
    "        if column == 'pcepi_growth':\n",
    "            y_values.extend(pcepi_growth.dropna().values * 100)\n",
    "        elif column == 'pcepilfe_growth':\n",
    "            y_values.extend(pcepilfe_growth.dropna().values * 100)\n",
    "        elif column == 'pcepi_yoy':\n",
    "            y_values.extend(pcepi_yoy.dropna().values)\n",
    "        elif column == 'pcepilfe_yoy':\n",
    "            y_values.extend(pcepilfe_yoy.dropna().values)\n",
    "    global_y_min = min(y_values)\n",
    "    global_y_max = max(y_values)\n",
    "    # Add some padding\n",
    "    padding = (global_y_max - global_y_min) * 0.05\n",
    "    global_y_min -= padding\n",
    "    global_y_max += padding\n",
    "    \n",
    "    # Define rolling windows (e.g., 30-month rolling windows)\n",
    "    window_size = 30  # Number of months in each window\n",
    "    windows = []\n",
    "    for i in range(len(pcepi_growth) - window_size + 1):\n",
    "        window = {\n",
    "            'pcepi_yoy': pcepi_yoy.iloc[i:i+window_size],\n",
    "            'pcepi_growth': pcepi_growth.iloc[i:i+window_size],\n",
    "            'pcepilfe_yoy': pcepilfe_yoy.iloc[i:i+window_size],\n",
    "            'pcepilfe_growth': pcepilfe_growth.iloc[i:i+window_size],\n",
    "            'dates': pcepi_growth.index[i:i+window_size]\n",
    "        }\n",
    "        windows.append(window)\n",
    "    \n",
    "    # Function to prepare table data for a given window\n",
    "    def prepare_table_data(window):\n",
    "        window_data = {\n",
    "            \"PCEPI YoY (%)\": window['pcepi_yoy'].values,\n",
    "            \"PCEPI 6M (%)\": window['pcepi_growth'].values * 100,\n",
    "            \"PCEPILFE YoY (%)\": window['pcepilfe_yoy'].values,\n",
    "            \"PCEPILFE 6M (%)\": window['pcepilfe_growth'].values * 100\n",
    "        }\n",
    "        table_df = pd.DataFrame(window_data).T.round(1)\n",
    "        window_dates = window['dates'].strftime(\"%y-%m\")\n",
    "        return table_df, window_dates\n",
    "    \n",
    "    # Generate frames for each window\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        table_df, window_dates = prepare_table_data(window)\n",
    "        \n",
    "        # Generate colors for the table\n",
    "        window_colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "        window_flat_colors = list(map(list, zip(*window_colors)))  # Transpose\n",
    "        \n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                table_df.index,  # Row labels\n",
    "                *[table_df[col] for col in table_df.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(window_dates)] + window_flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Items\"] + list(window_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window['dates'].min()\n",
    "        window_end = window['dates'].max()\n",
    "        \n",
    "        # Define the shaded rectangle shapes for both plots\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=global_y_min,\n",
    "            y1=global_y_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        shaded_shape_plot2 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x2\",  # References the x-axis of the second subplot\n",
    "            yref=\"y2\",  # References the y-axis of the second subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=global_y_min,\n",
    "            y1=global_y_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        # Create the frame with updated table and shaded shapes\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape_plot1, shaded_shape_plot2]  # Add shaded areas to both plots\n",
    "            ),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]  # Update the existing table trace\n",
    "        )\n",
    "        frames.append(frame)\n",
    "    \n",
    "    fig.frames = frames\n",
    "    \n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i in range(len(windows)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows[i]['dates'].min().strftime(\"%Y-%m\")  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "    \n",
    "    # Optionally, reverse the slider steps to have newest on the left\n",
    "    slider_steps = slider_steps[::-1]\n",
    "    \n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps\n",
    "    )]\n",
    "    \n",
    "    # Add the slider to the layout\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "    \n",
    "    # Add annotations for the latest values on both plots\n",
    "    fig.add_annotation(\n",
    "        x=dates[-1], y=recent_pcepi_value, xref=\"x1\", yref=\"y1\", \n",
    "        text=f\"Latest: {recent_pcepi_value:.2f}%\", showarrow=False,\n",
    "        font=dict(size=8, color=\"cyan\"),\n",
    "        xanchor=\"center\", yanchor=\"bottom\",  # Align tag above the line\n",
    "        ax=0, ay=40  # Shift the tag 40 pixels up\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=dates[-1], y=recent_pcepilfe_value, xref=\"x2\", yref=\"y2\", \n",
    "        text=f\"Latest: {recent_pcepilfe_value:.2f}%\", showarrow=False,\n",
    "        font=dict(size=8, color=\"cyan\"),\n",
    "        xanchor=\"center\", yanchor=\"bottom\",  # Align tag above the line\n",
    "        ax=0, ay=40  # Shift the tag 40 pixels up\n",
    "    )\n",
    "    \n",
    "    # Add source annotation at the bottom of the chart with hyperlinks\n",
    "    fig.add_annotation(\n",
    "        text=('Source: Federal Reserve Economic Data (FRED). '\n",
    "              '<a href=\"https://fred.stlouisfed.org/series/PCEPI\" style=\"color: white\">PCEPI</a>, '\n",
    "              '<a href=\"https://fred.stlouisfed.org/series/PCEPILFE\" style=\"color: white\">PCEPILFE</a>.'),\n",
    "        font=dict(size=8, color=\"white\"),  # Font size and color\n",
    "        xref=\"paper\", yref=\"paper\",  # Use paper coordinates\n",
    "        x=0.5, y=-0.03,  # Position the source annotation at the bottom\n",
    "        showarrow=False\n",
    "    )\n",
    "    \n",
    "    # Update layout and labels\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        yaxis_title=\"Growth Rate (%)\",\n",
    "        yaxis2_title=\"Growth Rate (%)\",\n",
    "        template=\"plotly_dark\",\n",
    "        font=dict(color=\"white\", size=8),\n",
    "        title_x=0.5,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",  # Set the legend to be horizontal\n",
    "            yanchor=\"top\",  # Anchor the legend to the top\n",
    "            y=1.2,  # Set the legend position slightly below the title\n",
    "            xanchor=\"center\",  # Center the legend\n",
    "            x=0.5,\n",
    "            font=dict(size=8)  # Set the font size for the legend\n",
    "        ),\n",
    "        height=600,  # Adjusted height\n",
    "        width=1000,  # Adjusted width\n",
    "        margin=dict(t=50, b=50, l=20, r=20)  # Adjusted side margins\n",
    "    )\n",
    "    \n",
    "    # Fix the y-axis range for both plots to prevent dynamic scaling\n",
    "    fig.update_yaxes(range=[global_y_min, global_y_max], row=1, col=1)\n",
    "    fig.update_yaxes(range=[global_y_min, global_y_max], row=1, col=2)\n",
    "    \n",
    "    # Update Y-axis labels to reflect that we're displaying Growth Rates (percentage points)\n",
    "    fig.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=2)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "325ee418-776f-4cd6-9f8d-6b6a247e22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_4(start_date='2020-01-01'):\n",
    "    # Initialize FRED with the provided API Key\n",
    "    fred = Fred(api_key=api_key)\n",
    "\n",
    "    # Define the series IDs (expanded with Rent added)\n",
    "    series_ids = {\n",
    "        'All Items CPI': 'CPIAUCSL',        # All Items CPI\n",
    "        'Core CPI': 'CPILFESL',             # Core CPI (less food and energy)\n",
    "        'Food': 'CPIUFDNS',                 # Food CPI\n",
    "        'Energy': 'CPIENGSL',               # Energy CPI\n",
    "        'Core Goods': 'CUSR0000SACL1E',     # Core Goods CPI\n",
    "        'Core Services': 'CUSR0000SASLE',   # Core Services CPI\n",
    "        'Rent': 'CUSR0000SEHA'              # Rent CPI\n",
    "    }\n",
    "\n",
    "    # Fetch data from FRED for the past two years with error handling\n",
    "    try:\n",
    "        data = {name: fred.get_series(series_id, start=start_date) for name, series_id in series_ids.items()}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Calculate the 6-month annualized growth rates\n",
    "    growth_rates_6m = df.pct_change(periods=6).apply(lambda x: ((1 + x) ** 2) - 1) * 100\n",
    "\n",
    "    # Align growth rates with months\n",
    "    growth_rates_6m = growth_rates_6m.dropna()\n",
    "\n",
    "    # Get the latest date\n",
    "    latest_date = growth_rates_6m.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    # Prepare data for plotting, including 6M Ago, 12M Ago, 18M Ago, and the Latest Data Point\n",
    "    plot_data = {\n",
    "        '18M Ago': growth_rates_6m.iloc[-18] if len(growth_rates_6m) > 18 else None,\n",
    "        '12M Ago': growth_rates_6m.iloc[-12] if len(growth_rates_6m) > 12 else None,\n",
    "        '6M Ago': growth_rates_6m.iloc[-6] if len(growth_rates_6m) > 6 else None,\n",
    "        f'Latest Data Point ({latest_date})': growth_rates_6m.iloc[-1]\n",
    "    }\n",
    "\n",
    "    # Filter out None values from plot_data\n",
    "    plot_data = {k: v for k, v in plot_data.items() if v is not None}\n",
    "\n",
    "    # Create DataFrame for easier plotting\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    # Plotting with Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add bars for each time period with numbers on top of each bar\n",
    "    colors = ['#A67D5D', '#708090', '#B0C4DE', '#4682B4', '#2F4F4F']\n",
    "    for i, period in enumerate(plot_df.columns):\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=plot_df.index,\n",
    "            y=plot_df[period],\n",
    "            name=period,\n",
    "            marker_color=colors[i % len(colors)],\n",
    "            width=0.2,  # Adjust width based on the number of bars\n",
    "            text=plot_df[period].round(1),  # Show the values on top of the bars with 1 decimal place\n",
    "            textposition='outside',         # Display the text outside the bar\n",
    "            texttemplate='%{text:.1f}',     # Format the text to 1 decimal place\n",
    "            textfont_size=8                # Set font size to 12\n",
    "        ))\n",
    "\n",
    "    # Update layout to match the style with more neutral colors and space\n",
    "    fig.update_layout(\n",
    "        yaxis_title='Inflation Rate (%)',\n",
    "        xaxis_title='',\n",
    "        barmode='group',\n",
    "        template='plotly_dark',\n",
    "        font=dict(color='white'),\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        title_font=dict(size=8),\n",
    "        bargap=0.2,  # Adjust gap between bar groups for more spacing\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.1,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a9f7389-0138-4a34-9737-221cd30209d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_6():\n",
    "    # Initialize FRED API\n",
    "    fred = Fred(api_key=api_key)\n",
    "\n",
    "    # Fetch Core PCE data starting from December 2022 to get accurate MoM for January 2023\n",
    "    data = fred.get_series('PCEPILFE', observation_start='2022-12-01')\n",
    "\n",
    "    # Calculate month-over-month changes (annualized)\n",
    "    core_pce_mom_ann = data.pct_change().dropna() * 12 * 100\n",
    "\n",
    "    # Filter the data for 2023 and 2024\n",
    "    data_2023_2024 = core_pce_mom_ann['2023-01-01':]\n",
    "\n",
    "    # Define months\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "    # Extract data for 2023\n",
    "    core_pce_2023 = data_2023_2024['2023'].reindex(\n",
    "        pd.PeriodIndex(['2023-{:02d}-01'.format(m) for m in range(1,13)], freq='M').to_timestamp()\n",
    "    ).tolist()\n",
    "\n",
    "    # Extract data for 2024\n",
    "    core_pce_2024 = data_2023_2024['2024'].reindex(\n",
    "        pd.PeriodIndex(['2024-{:02d}-01'.format(m) for m in range(1,13)], freq='M').to_timestamp()\n",
    "    ).tolist()\n",
    "\n",
    "    # Handle missing data by replacing NaN with None\n",
    "    core_pce_2023 = [x if pd.notnull(x) else None for x in core_pce_2023]\n",
    "    core_pce_2024 = [x if pd.notnull(x) else None for x in core_pce_2024]\n",
    "\n",
    "    # Calculate differences where data for both years is available\n",
    "    core_pce_diff = [\n",
    "        round(core_pce_2024[i] - core_pce_2023[i], 2) if (core_pce_2023[i] is not None and core_pce_2024[i] is not None) else None\n",
    "        for i in range(12)\n",
    "    ]\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_2023 = round(sum(filter(None, core_pce_2023)) / len(list(filter(None, core_pce_2023))), 2)\n",
    "    avg_2024 = round(sum(filter(None, core_pce_2024)) / len(list(filter(None, core_pce_2024))), 2)\n",
    "    avg_diff = round(avg_2024 - avg_2023, 2)\n",
    "\n",
    "    # Prepare display data with two decimal places\n",
    "    core_pce_2023_display = [f\"{x:.2f}\" if x is not None else \"\" for x in core_pce_2023]\n",
    "    core_pce_2024_display = [f\"{x:.2f}\" if x is not None else \"\" for x in core_pce_2024]\n",
    "    core_pce_diff_display = [f\"{x:.2f}\" if x is not None else \"\" for x in core_pce_diff]\n",
    "\n",
    "    # Append averages to the display lists\n",
    "    months_to_display = months + ['Avg to Last Month']\n",
    "    core_pce_2023_display.append(f\"{avg_2023:.2f}\")\n",
    "    core_pce_2024_display.append(f\"{avg_2024:.2f}\")\n",
    "    core_pce_diff_display.append(f\"{avg_diff:.2f}\")\n",
    "\n",
    "    # Append averages to data lists (they won't be plotted)\n",
    "    core_pce_2023.append(avg_2023)\n",
    "    core_pce_2024.append(avg_2024)\n",
    "\n",
    "    # Create subplots: one for the bar chart and one for the table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1, \n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.05, \n",
    "        row_heights=[0.6, 0.4],  # Adjust heights as needed\n",
    "        specs=[[{\"type\": \"bar\"}], [{\"type\": \"table\"}]],\n",
    "        subplot_titles=[\"Core PCE (M/M, Annualized) Comparison: 2023 vs 2024\", \"\"]\n",
    "    )\n",
    "\n",
    "    # Add Bar for 2023\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=months,\n",
    "            y=core_pce_2023[:-1],  # Exclude average\n",
    "            name='2023',\n",
    "            marker_color='rgba(0, 170, 255, 0.7)'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add Bar for 2024\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=months,\n",
    "            y=core_pce_2024[:-1],  # Exclude average\n",
    "            name='2024',\n",
    "            marker_color='rgba(255, 165, 0, 0.7)'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Update layout for grouped bars\n",
    "    fig.update_layout(\n",
    "        barmode='group',\n",
    "        title_text=\"Core PCE, Month-over-Month Annualized Changes\",\n",
    "        template=\"plotly_dark\",\n",
    "        font=dict(color='white'),\n",
    "        height=800,  # Adjust height as needed\n",
    "        margin=dict(l=50, r=50, t=100, b=100),\n",
    "        legend=dict(x=0.8, y=1.15, orientation='h')\n",
    "    )\n",
    "\n",
    "    # Prepare font sizes for the table\n",
    "    # Assuming 13 rows (12 months + average) and 4 columns\n",
    "    num_rows = len(months_to_display)\n",
    "    num_cols = 4\n",
    "    main_font_size = 10\n",
    "    diff_font_size = 8\n",
    "\n",
    "    # Create a list of font sizes: [main, main, main, diff] for each row\n",
    "    font_size_list = [main_font_size, main_font_size, main_font_size, diff_font_size] * num_rows\n",
    "\n",
    "    # Create the table\n",
    "    table = go.Table(\n",
    "        header=dict(\n",
    "            values=['Month', '2023', '2024', 'Diff'],\n",
    "            fill_color='#1f1f1f',\n",
    "            align='center',\n",
    "            font=dict(color='white', size=12)\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[months_to_display, core_pce_2023_display, core_pce_2024_display, core_pce_diff_display],\n",
    "            fill_color='black',\n",
    "            align='center',\n",
    "            font=dict(color='white', size=10),  # Default font size\n",
    "            # Apply the font sizes list to the 'Diff' column\n",
    "            # Since Plotly doesn't support per-column font sizes directly,\n",
    "            # we simulate it by creating a flat list where 'Diff' cells have smaller font\n",
    "            font_size=font_size_list\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add table to the second row\n",
    "    fig.add_trace(table, row=2, col=1)\n",
    "\n",
    "    # Add footnote with a link to PCE data and source text\n",
    "    fig.add_annotation(\n",
    "        text=(\"Source: <a href='https://fred.stlouisfed.org/series/PCEPILFE' style='color:white;' target='_blank'>FRED</a>\"),\n",
    "        showarrow=False,\n",
    "        xref='paper', yref='paper',\n",
    "        x=0.5, y=-0.25,\n",
    "        xanchor='center', yanchor='top',\n",
    "        font=dict(size=10),\n",
    "        align='center'\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "977bf266-4971-4c2a-99f5-abef5d7ade40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_7():\n",
    "    # Initialize FRED with the provided API Key\n",
    "    fred = Fred(api_key=api_key)\n",
    "    \n",
    "    # Retrieve PPI data\n",
    "    ppiaco_data = fred.get_series('PPIACO')  # Producer Price Index for All Commodities\n",
    "    ppifes_data = fred.get_series('PPIFES')  # Producer Price Index for Finished Goods\n",
    "    \n",
    "    # Resample data monthly and compute the six-month annualized growth rate\n",
    "    def annualized_growth_rate(series, window=6):\n",
    "        return (series.pct_change(window) + 1) ** (12/window) - 1\n",
    "    \n",
    "    ppiaco_growth = annualized_growth_rate(ppiaco_data)\n",
    "    ppifes_growth = annualized_growth_rate(ppifes_data)\n",
    "    \n",
    "    # Compute YoY percentage change for both series\n",
    "    ppiaco_yoy = ppiaco_data.pct_change(periods=12) * 100\n",
    "    ppifes_yoy = ppifes_data.pct_change(periods=12) * 100\n",
    "    \n",
    "    # Filter data from 2015 onwards\n",
    "    ppiaco_growth = ppiaco_growth[ppiaco_growth.index >= '2015-01-01']\n",
    "    ppifes_growth = ppifes_growth[ppifes_growth.index >= '2015-01-01']\n",
    "    ppiaco_yoy = ppiaco_yoy[ppiaco_yoy.index >= '2015-01-01']\n",
    "    ppifes_yoy = ppifes_yoy[ppifes_yoy.index >= '2015-01-01']\n",
    "    \n",
    "    # Prepare date range for plotting\n",
    "    dates = ppiaco_growth.index\n",
    "    \n",
    "    # Get the most recent readings for both series\n",
    "    recent_ppiaco_value = ppiaco_growth.dropna().iloc[-1] * 100\n",
    "    recent_ppifes_value = ppifes_growth.dropna().iloc[-1] * 100\n",
    "    recent_ppiaco_yoy_value = ppiaco_yoy.dropna().iloc[-1]\n",
    "    recent_ppifes_yoy_value = ppifes_yoy.dropna().iloc[-1]\n",
    "    \n",
    "    # Compute long-term averages\n",
    "    ppiaco_long_term_avg = ppiaco_growth.mean() * 100\n",
    "    ppifes_long_term_avg = ppifes_growth.mean() * 100\n",
    "    \n",
    "    # Prepare data for the table with new order and labels\n",
    "    table_data = pd.DataFrame({\n",
    "        \"PPI All Comm YoY (%)\": ppiaco_yoy.dropna().tail(30).values,\n",
    "        \"PPI All Comm 6M (%)\": ppiaco_growth.dropna().tail(30).values * 100,\n",
    "        \"PPI Final Demand YoY (%)\": ppifes_yoy.dropna().tail(30).values,\n",
    "        \"PPI Final Demand 6M (%)\": ppifes_growth.dropna().tail(30).values * 100\n",
    "    }).T.round(1)\n",
    "    \n",
    "    # Extract the dates as column headers\n",
    "    dates_for_table = ppiaco_growth.dropna().tail(30).index.strftime(\"%y-%m\")\n",
    "    \n",
    "    # Heatmap color functions\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "    \n",
    "    # Generate colors for the table based on the data rows\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_data.iterrows()]\n",
    "    \n",
    "    # Transpose the list of colors to match Plotly's requirement (each sublist represents a column of colors)\n",
    "    flat_colors = list(map(list, zip(*colors)))\n",
    "    \n",
    "    # Create subplots: 2 columns for charts and 1 row for the table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2, \n",
    "        row_heights=[0.6, 0.4],  # 60% for charts, 40% for table\n",
    "        specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}], [{\"type\": \"table\", \"colspan\": 2}, None]],  # Use full width for the table\n",
    "        subplot_titles=('PPI All Commodities', 'PPI Final Demand'),\n",
    "        vertical_spacing=0.05  # Smaller gap between plots and table\n",
    "    )\n",
    "    \n",
    "    # Add PPI All Commodities chart (6M Annualized, Light Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=ppiaco_growth * 100, mode='lines', name='6M Annualized PPI All Comm', \n",
    "        line=dict(color='cyan', width=2),\n",
    "        text=[f\"Latest: {recent_ppiaco_value:.2f}%\" for _ in dates],\n",
    "        hoverinfo='text+y'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add PPI Final Demand chart (6M Annualized, Light Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=ppifes_growth * 100, mode='lines', name='6M Annualized PPI Final Demand', \n",
    "        line=dict(color='cyan', width=2),\n",
    "        text=[f\"Latest: {recent_ppifes_value:.2f}%\" for _ in dates],\n",
    "        hoverinfo='text+y'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add YoY PPI All Commodities (White)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=ppiaco_yoy, mode='lines', name='YoY PPI All Comm', \n",
    "        line=dict(color='white', width=1),\n",
    "        hoverinfo='none'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add YoY PPI Final Demand (White)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=ppifes_yoy, mode='lines', name='YoY PPI Final Demand', \n",
    "        line=dict(color='white', width=1),\n",
    "        hoverinfo='none'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add the Long Term Average line to both charts\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[ppiaco_long_term_avg]*len(dates), mode='lines', name='Long Term Average', \n",
    "        line=dict(color='crimson', dash='dash')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Duplicate the Long Term Average line for the second chart without showing it in the legend\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[ppifes_long_term_avg]*len(dates), mode='lines', name='', showlegend=False, \n",
    "        line=dict(color='crimson', dash='dash')\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Add the initial table below the charts\n",
    "    table = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Items\"] + list(dates_for_table),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_data.index,  # Row labels\n",
    "                *[table_data[col] for col in table_data.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(dates_for_table)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4] + [0.5] * len(dates_for_table)  # Adjusted column widths\n",
    "    )\n",
    "    fig.add_trace(table, row=2, col=1)  # Table spans both columns\n",
    "    \n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "    \n",
    "    # Calculate global y-axis range for both plots\n",
    "    # Combine all y-values from lines and bars to determine global min and max\n",
    "    y_values = []\n",
    "    for column in ['ppiaco_growth', 'ppifes_growth', 'ppiaco_yoy', 'ppifes_yoy']:\n",
    "        if column == 'ppiaco_growth':\n",
    "            y_values.extend(ppiaco_growth.dropna().values * 100)\n",
    "        elif column == 'ppifes_growth':\n",
    "            y_values.extend(ppifes_growth.dropna().values * 100)\n",
    "        elif column == 'ppiaco_yoy':\n",
    "            y_values.extend(ppiaco_yoy.dropna().values)\n",
    "        elif column == 'ppifes_yoy':\n",
    "            y_values.extend(ppifes_yoy.dropna().values)\n",
    "    global_y_min = min(y_values)\n",
    "    global_y_max = max(y_values)\n",
    "    # Add some padding\n",
    "    padding = (global_y_max - global_y_min) * 0.05\n",
    "    global_y_min -= padding\n",
    "    global_y_max += padding\n",
    "    \n",
    "    # Define rolling windows (e.g., 30-month rolling windows)\n",
    "    window_size = 30  # Number of months in each window\n",
    "    windows = []\n",
    "    for i in range(len(ppiaco_growth) - window_size + 1):\n",
    "        window = {\n",
    "            'ppiaco_yoy': ppiaco_yoy.iloc[i:i+window_size],\n",
    "            'ppiaco_growth': ppiaco_growth.iloc[i:i+window_size],\n",
    "            'ppifes_yoy': ppifes_yoy.iloc[i:i+window_size],\n",
    "            'ppifes_growth': ppifes_growth.iloc[i:i+window_size],\n",
    "            'dates': ppiaco_growth.index[i:i+window_size]\n",
    "        }\n",
    "        windows.append(window)\n",
    "    \n",
    "    # Function to prepare table data for a given window\n",
    "    def prepare_table_data(window):\n",
    "        window_data = {\n",
    "            \"PPI All Comm YoY (%)\": window['ppiaco_yoy'].values,\n",
    "            \"PPI All Comm 6M (%)\": window['ppiaco_growth'].values * 100,\n",
    "            \"PPI Final Demand YoY (%)\": window['ppifes_yoy'].values,\n",
    "            \"PPI Final Demand 6M (%)\": window['ppifes_growth'].values * 100\n",
    "        }\n",
    "        table_df = pd.DataFrame(window_data).T.round(1)\n",
    "        window_dates = window['dates'].strftime(\"%y-%m\")\n",
    "        return table_df, window_dates\n",
    "    \n",
    "    # Generate frames for each window\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        table_df, window_dates = prepare_table_data(window)\n",
    "        \n",
    "        # Generate colors for the table\n",
    "        window_colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "        window_flat_colors = list(map(list, zip(*window_colors)))  # Transpose\n",
    "        \n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                table_df.index,  # Row labels\n",
    "                *[table_df[col] for col in table_df.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(window_dates)] + window_flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Items\"] + list(window_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window['dates'].min()\n",
    "        window_end = window['dates'].max()\n",
    "        \n",
    "        # Define the shaded rectangle shapes for both plots\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=global_y_min,\n",
    "            y1=global_y_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        shaded_shape_plot2 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x2\",  # References the x-axis of the second subplot\n",
    "            yref=\"y2\",  # References the y-axis of the second subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=global_y_min,\n",
    "            y1=global_y_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        # Create the frame with updated table and shaded shapes\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape_plot1, shaded_shape_plot2]  # Add shaded areas to both plots\n",
    "            ),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]  # Update the existing table trace\n",
    "        )\n",
    "        frames.append(frame)\n",
    "    \n",
    "    fig.frames = frames\n",
    "    \n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i in range(len(windows)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows[i]['dates'].min().strftime(\"%Y-%m\")  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "    \n",
    "    # Optionally, reverse the slider steps to have newest on the left\n",
    "    slider_steps = slider_steps[::-1]\n",
    "    \n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps\n",
    "    )]\n",
    "    \n",
    "    # Add the slider to the layout\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "    \n",
    "    # Add annotations for the latest values on both plots\n",
    "    fig.add_annotation(\n",
    "        x=dates[-1], y=recent_ppiaco_value, xref=\"x1\", yref=\"y1\", \n",
    "        text=f\"Latest: {recent_ppiaco_value:.2f}%\", showarrow=False,\n",
    "        font=dict(size=8, color=\"cyan\"),\n",
    "        xanchor=\"center\", yanchor=\"bottom\",  # Align tag above the line\n",
    "        ax=0, ay=40  # Shift the tag 40 pixels up\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=dates[-1], y=recent_ppifes_value, xref=\"x2\", yref=\"y2\", \n",
    "        text=f\"Latest: {recent_ppifes_value:.2f}%\", showarrow=False,\n",
    "        font=dict(size=8, color=\"cyan\"),\n",
    "        xanchor=\"center\", yanchor=\"bottom\",  # Align tag above the line\n",
    "        ax=0, ay=40  # Shift the tag 40 pixels up\n",
    "    )\n",
    "    \n",
    "    # Add source annotation at the bottom of the chart with hyperlinks\n",
    "    fig.add_annotation(\n",
    "        text=('Source: Federal Reserve Economic Data (FRED). '\n",
    "              '<a href=\"https://fred.stlouisfed.org/graph/?g=1tHOq\" style=\"color: white\">PPI: Final Demand</a>, '\n",
    "              '<a href=\"https://fred.stlouisfed.org/graph/?g=1tHOy\" style=\"color: white\">PPI: All Comm</a>.'),\n",
    "        font=dict(size=8, color=\"white\"),  # Font size and color\n",
    "        xref=\"paper\", yref=\"paper\",  # Use paper coordinates\n",
    "        x=0.5, y=-0.03,  # Position the source annotation at the bottom\n",
    "        showarrow=False\n",
    "    )\n",
    "    \n",
    "    # Update layout and labels\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        yaxis_title=\"Growth Rate (%)\",\n",
    "        yaxis2_title=\"Growth Rate (%)\",\n",
    "        template=\"plotly_dark\",\n",
    "        font=dict(color=\"white\", size=8),\n",
    "        title_x=0.5,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",  # Set the legend to be horizontal\n",
    "            yanchor=\"top\",  # Anchor the legend to the top\n",
    "            y=1.2,  # Set the legend position slightly below the title\n",
    "            xanchor=\"center\",  # Center the legend\n",
    "            x=0.5,\n",
    "            font=dict(size=8)  # Set the font size for the legend\n",
    "        ),\n",
    "        height=600,  # Adjusted height\n",
    "        width=1000,  # Adjusted width\n",
    "        margin=dict(t=50, b=50, l=20, r=20)  # Adjusted side margins\n",
    "    )\n",
    "    \n",
    "    # Fix the y-axis range for both plots to prevent dynamic scaling\n",
    "    fig.update_yaxes(range=[global_y_min, global_y_max], row=1, col=1)\n",
    "    fig.update_yaxes(range=[global_y_min, global_y_max], row=1, col=2)\n",
    "    \n",
    "    # Update Y-axis labels to reflect that we're displaying Contributions (percentage points)\n",
    "    fig.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Growth Rate (%)\", row=1, col=2)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2630532d-27cb-4818-a636-80c01ad2c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_8(selected_period='MoM', months_for_table=30):\n",
    "    # Initialize Fred API with your API key\n",
    "    fred = Fred(api_key='7227512392e5e5d2a2679a261d2bb3a9')  # Ensure your API key is secure\n",
    "    \n",
    "    # Define the FRED series IDs for the different PPI components\n",
    "    series_ids = {\n",
    "        'All Items PPI': 'PPIFID',            # All Items PPI\n",
    "        'Core PPI': 'WPUFD413',               # Core PPI (Final Demand Goods Less Foods and Energy)\n",
    "        'Foods PPI': 'PPIFDF',                # Foods PPI\n",
    "        'Energy PPI': 'PPIFDE',               # Energy PPI\n",
    "        'Goods PPI': 'PPIFDG',                # Goods PPI (Final Demand)\n",
    "        'Services PPI': 'PPIFDS',             # Services PPI\n",
    "        'Construction PPI': 'PPIFDC'          # Construction PPI\n",
    "    }\n",
    "    \n",
    "    # Fetch the data from FRED\n",
    "    ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
    "    \n",
    "    # Convert the data into a DataFrame\n",
    "    ppi_df = pd.DataFrame(ppi_data)\n",
    "    \n",
    "    # Ensure the DataFrame index is in datetime format\n",
    "    ppi_df.index = pd.to_datetime(ppi_df.index)\n",
    "    \n",
    "    # Filter data from February 2015 onwards\n",
    "    ppi_df = ppi_df[ppi_df.index >= '2015-02-01']\n",
    "    \n",
    "    # Determine y-axis ranges and other parameters based on selected_period\n",
    "    if selected_period == 'MoM':\n",
    "        required_prior_months = 1  # To compute MoM for the first display month\n",
    "        window_size = months_for_table  # Number of months in each window\n",
    "        y1_min, y1_max = -5, 5         # Y-axis range for the first plot\n",
    "        y2_min, y2_max = -20, 20       # Y-axis range for the second plot\n",
    "        title = \"Current graph displays Month-over-Month (MoM) Changes\"\n",
    "    elif selected_period == 'YoY':\n",
    "        required_prior_months = 12  # To compute YoY for the first display month\n",
    "        window_size = months_for_table  # Number of months in each window\n",
    "        y1_min, y1_max = -15, 15      # Y-axis range for the first plot\n",
    "        y2_min, y2_max = -30, 30      # Y-axis range for the second plot\n",
    "        title = \"Current graph displays Year-over-Year (YoY) Changes\"\n",
    "    else:\n",
    "        raise ValueError(\"selected_period must be either 'MoM' or 'YoY'.\")\n",
    "    \n",
    "    # Calculate the start date needed to accommodate the buffer\n",
    "    display_start_date = ppi_df.index.min()\n",
    "    buffer_start_date = display_start_date - relativedelta(months=required_prior_months)\n",
    "    \n",
    "    # Fetch data starting from buffer_start_date to ensure calculations are possible\n",
    "    ppi_df = ppi_df[ppi_df.index >= buffer_start_date]\n",
    "    \n",
    "    # Calculate the Month-over-Month or Year-over-Year percentage change based on the selected_period input\n",
    "    if selected_period == 'MoM':\n",
    "        data_df = ppi_df.pct_change(periods=1) * 100  # MoM percentage change\n",
    "        \n",
    "        # Calculate 3-month moving average (MoM)\n",
    "        data_df['All Items PPI (3-mo MA)'] = data_df['All Items PPI'].rolling(window=3).mean()\n",
    "        data_df['Core PPI (3-mo MA)'] = data_df['Core PPI'].rolling(window=3).mean()\n",
    "        \n",
    "        # MoM source links\n",
    "        source_links = (\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tRZ4' style='color:white'>All Items PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tRZu' style='color:white'>Core PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tRZH' style='color:white'>Foods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tRZO' style='color:white'>Energy PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS05' style='color:white'>Goods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS0o' style='color:white'>Services PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS0C' style='color:white'>Construction PPI</a>\"\n",
    "        )\n",
    "\n",
    "    else:  # 'YoY'\n",
    "        data_df = ppi_df.pct_change(periods=12) * 100  # YoY percentage change\n",
    "        \n",
    "        # Use MoM data to calculate the 6-month annualized growth rate\n",
    "        data_df_mom = ppi_df.pct_change(periods=1)\n",
    "        \n",
    "        # Calculate the 6-month annualized rate using MoM data\n",
    "        data_df['All Items PPI (6-mo Annualized)'] = (\n",
    "            data_df_mom['All Items PPI'].rolling(window=6).apply(lambda x: np.prod(1 + x) ** (12 / 6) - 1)) * 100\n",
    "        data_df['Core PPI (6-mo Annualized)'] = (\n",
    "            data_df_mom['Core PPI'].rolling(window=6).apply(lambda x: np.prod(1 + x) ** (12 / 6) - 1)) * 100\n",
    "\n",
    "        # YoY source links\n",
    "        source_links = (\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1p' style='color:white'>All Items PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1r' style='color:white'>Core PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1t' style='color:white'>Foods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1x' style='color:white'>Energy PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1z' style='color:white'>Goods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1D' style='color:white'>Services PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tS1K' style='color:white'>Construction PPI</a>\"\n",
    "        )\n",
    "    \n",
    "    # Drop rows with NaN values after calculations\n",
    "    data_df = data_df.dropna()\n",
    "    \n",
    "    # Further filter data to display only from display_start_date onwards\n",
    "    data_df = data_df[data_df.index >= display_start_date]\n",
    "    \n",
    "    # Create subplots: 3 rows (2 for plots, 1 for table)\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=[0.35, 0.35, 0.3],  # Adjust the heights of the rows to allocate more space for the table\n",
    "        subplot_titles=(\"Core PPI & All Items PPI %\", \"Selected Components % (Stacked)\", \"PPI Table\"),\n",
    "        vertical_spacing=0.05,  # Smaller gap between plots and the table\n",
    "        specs=[[{\"type\": \"scatter\"}], [{\"type\": \"bar\"}], [{\"type\": \"table\"}]]\n",
    "    )\n",
    "    \n",
    "    # Plot 1: Core PPI and All Items PPI (Main plot)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data_df.index, y=data_df['All Items PPI'],\n",
    "        mode='lines', name='All Items PPI %',\n",
    "        line=dict(color='white')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data_df.index, y=data_df['Core PPI'],\n",
    "        mode='lines', name='Core PPI %',\n",
    "        line=dict(color='magenta')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add 6-month annualized rate (for YoY plot)\n",
    "    if selected_period == 'YoY':\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data_df.index, y=data_df['All Items PPI (6-mo Annualized)'],\n",
    "            mode='lines', name='All Items PPI (6-mo Annualized)',\n",
    "            line=dict(color='white', dash='dot')\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data_df.index, y=data_df['Core PPI (6-mo Annualized)'],\n",
    "            mode='lines', name='Core PPI (6-mo Annualized)',\n",
    "            line=dict(color='magenta', dash='dot')\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Add 3-month moving average (for MoM plot)\n",
    "    if selected_period == 'MoM':\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data_df.index, y=data_df['All Items PPI (3-mo MA)'],\n",
    "            mode='lines', name='All Items PPI (3-mo MA)',\n",
    "            line=dict(color='white', dash='dot')\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data_df.index, y=data_df['Core PPI (3-mo MA)'],\n",
    "            mode='lines', name='Core PPI (3-mo MA)',\n",
    "            line=dict(color='magenta', dash='dot')\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Subplot 2: Stacked bar plot for components (Foods PPI, Energy PPI, Goods PPI, Services PPI, Construction PPI)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data_df.index, y=data_df['Goods PPI'], name='Goods PPI %', marker_color='purple'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data_df.index, y=data_df['Services PPI'], name='Services PPI %', marker_color='green'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data_df.index, y=data_df['Energy PPI'], name='Energy PPI %', marker_color='orange'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data_df.index, y=data_df['Foods PPI'], name='Foods PPI %', marker_color='blue'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data_df.index, y=data_df['Construction PPI'], name='Construction PPI %', marker_color='yellow'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # Create a table summarizing % changes for the selected number of months, with the specified order\n",
    "    table_data = data_df[['All Items PPI', 'Core PPI', 'Goods PPI', 'Services PPI', 'Foods PPI', 'Energy PPI', 'Construction PPI']].tail(months_for_table).round(1)\n",
    "    \n",
    "    # Transpose the table for desired format: Dates as column headers, items on the left-hand side\n",
    "    table_data = table_data.T  # Transpose the dataframe to switch rows and columns\n",
    "    \n",
    "    # Function to generate colors for each row based on values\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "    \n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "    \n",
    "    # Generate colors for the table\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_data.iterrows()]\n",
    "    \n",
    "    # Transpose the list of colors to match Plotly's requirement (each sublist represents a column of colors)\n",
    "    flat_colors = list(map(list, zip(*colors)))\n",
    "    \n",
    "    # Add the initial table\n",
    "    table_trace = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Items\"] + list(table_data.columns.strftime(\"%y-%m\")),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_data.index,  # Row labels\n",
    "                *[table_data[col] for col in table_data.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(table_data.columns)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[2] + [1] * len(table_data.columns)  # Ensure uniform column width\n",
    "    )\n",
    "    fig.add_trace(table_trace, row=3, col=1)  # Table is the third subplot\n",
    "    \n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "    \n",
    "    # Function to prepare table data for a given window\n",
    "    def prepare_table_data(window):\n",
    "        window_data = window[['All Items PPI', 'Core PPI', 'Goods PPI', 'Services PPI', 'Foods PPI', 'Energy PPI', 'Construction PPI']].round(1)\n",
    "        window_df = window_data.copy()\n",
    "        window_df = window_df.T  # Transpose for desired format\n",
    "        window_dates = window_df.columns.strftime(\"%y-%m\")\n",
    "        return window_df, window_dates\n",
    "    \n",
    "    # Generate all possible windows starting from display_start_date\n",
    "    windows = [data_df.iloc[i:i + window_size] for i in range(len(data_df) - window_size + 1)]\n",
    "    \n",
    "    # Function to generate colors for each row based on values (for frames)\n",
    "    def get_row_heatmap_colors_frame(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "    \n",
    "    # Generate frames for the slider\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        frame_table_df, window_dates = prepare_table_data(window)\n",
    "        \n",
    "        # Generate colors for the table\n",
    "        frame_colors = [get_row_heatmap_colors_frame(row) for _, row in frame_table_df.iterrows()]\n",
    "        frame_flat_colors = list(map(list, zip(*frame_colors)))  # Transpose to match Plotly's requirement\n",
    "        \n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                frame_table_df.index,  # Row labels\n",
    "                *[frame_table_df[col] for col in frame_table_df.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(window_dates)] + frame_flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left', 'center'],\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Items\"] + list(window_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "        \n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window.index.min()\n",
    "        window_end = window.index.max()\n",
    "        \n",
    "        # Define the shaded rectangle shapes for both plots with fixed y-axis ranges\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=y1_min,\n",
    "            y1=y1_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        shaded_shape_plot2 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # Shared x-axis\n",
    "            yref=\"y2\",  # References the y-axis of the second subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=y2_min,\n",
    "            y1=y2_max,\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "        \n",
    "        # Create the frame with updated table and shaded shapes\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape_plot1, shaded_shape_plot2]\n",
    "            ),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]  # Update the existing table trace\n",
    "        )\n",
    "        frames.append(frame)\n",
    "    \n",
    "    fig.frames = frames\n",
    "    \n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i in range(len(windows)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows[i].index.min().strftime(\"%Y-%m\")  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "    \n",
    "    # Optionally, reverse the slider steps to have newest on the left\n",
    "    slider_steps = slider_steps[::-1]\n",
    "    \n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps\n",
    "    )]\n",
    "    \n",
    "    # Update layout with the slider\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "    \n",
    "    # Add source annotation based on selected_period\n",
    "    fig.add_annotation(\n",
    "        text=(\"Source: \" + source_links + \" <br><a href='https://www.bls.gov/news.release/ppi.nr0.htm' style='color:white;' target='_blank'>BLS PPI Report (Weight needs to be updated manually)</a>\"),\n",
    "        font=dict(size=8, color=\"white\"),\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=-0.03,  # Position the source annotation at the bottom\n",
    "        showarrow=False\n",
    "    )\n",
    "    \n",
    "    # Update layout with dynamic title and other aesthetics\n",
    "    fig.update_layout(\n",
    "        title=title,  # Dynamic title based on MoM or YoY\n",
    "        title_font=dict(size=8),\n",
    "        width=1000,\n",
    "        height=1000,  # Increased height for larger plots\n",
    "        margin=dict(t=80, b=80, l=20, r=20),  # Adjusted side margins\n",
    "        template='plotly_dark',\n",
    "        barmode='relative',  # Enable stacked bars for the component plot\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",  # Set the legend to be horizontal\n",
    "            yanchor=\"top\",    # Align to top\n",
    "            y=1.2,            # Set the legend position slightly above the plots\n",
    "            xanchor=\"center\", # Center the legend\n",
    "            x=0.5,\n",
    "            font=dict(size=8)  # Set font size for the legend\n",
    "        ),\n",
    "        font=dict(size=8)  # Global font size for axis labels, tick marks, etc.\n",
    "    )\n",
    "    \n",
    "    # Set fixed y-axis ranges based on selected_period\n",
    "    fig.update_yaxes(range=[y1_min, y1_max], row=1, col=1)\n",
    "    fig.update_yaxes(range=[y2_min, y2_max], row=2, col=1)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "324d22aa-d8c1-4f12-8230-33dbeb9fbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_9(contribution_type='MoM'):\n",
    "    # Initialize Fred API with your API key\n",
    "    fred = Fred(api_key='7227512392e5e5d2a2679a261d2bb3a9')  # Replace with your actual FRED API key\n",
    "    \n",
    "    # Fetch PPI component data from FRED\n",
    "    series_ids = {\n",
    "        'All Items PPI': 'PPIFID',        # All Items PPI\n",
    "        'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
    "        'Foods PPI': 'PPIFDF',            # Foods PPI\n",
    "        'Energy PPI': 'PPIFDE',           # Energy PPI\n",
    "        'Goods PPI': 'PPIFDG',            # Goods PPI (Final Demand)\n",
    "        'Services PPI': 'PPIFDS',         # Services PPI\n",
    "        'Construction PPI': 'PPIFDC'      # Construction PPI\n",
    "    }\n",
    "    \n",
    "    # Fetch data for each series from FRED and store in a DataFrame\n",
    "    ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
    "    df = pd.DataFrame(ppi_data)\n",
    "    \n",
    "    # Ensure the DataFrame index is in datetime format\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # Define relative importance weights (these need to be manually updated based on the latest BLS release)\n",
    "    relative_importance = {\n",
    "        \"Goods PPI\": 33.2,         # Example weight, please update according to BLS data\n",
    "        \"Services PPI\": 66.8,      # Example weight, please update according to BLS data\n",
    "        \"Foods PPI\": 10.0,         # Example weight, please update according to BLS data\n",
    "        \"Energy PPI\": 5.4,         # Example weight, please update according to BLS data\n",
    "        \"Construction PPI\": 7.8,   # Example weight, please update according to BLS data\n",
    "        \"All Items PPI\": 100.0     # Already includes Foods, Energy, etc.\n",
    "    }\n",
    "    \n",
    "    # Determine the required buffer period and window size based on contribution_type\n",
    "    if contribution_type == 'MoM':\n",
    "        buffer_period = 1  # To compute MoM for the first display month\n",
    "        window_size = 30   # Number of months in each window\n",
    "        y1_min, y1_max = -3, 3      # Fixed y-axis range for Plot 1\n",
    "    elif contribution_type == 'YoY':\n",
    "        buffer_period = 12  # To compute YoY for the first display month\n",
    "        window_size = 30    # Number of months in each window\n",
    "        y1_min, y1_max = -3, 3      # Fixed y-axis range for Plot 1\n",
    "    else:\n",
    "        raise ValueError(\"contribution_type must be either 'MoM' or 'YoY'.\")\n",
    "    \n",
    "    # Calculate the start date needed to accommodate the buffer\n",
    "    display_start_date = datetime(2015, 1, 1)\n",
    "    buffer_start_date = display_start_date - relativedelta(months=buffer_period)\n",
    "    \n",
    "    # Fetch data starting from buffer_start_date to ensure calculations are possible\n",
    "    df = df[df.index >= buffer_start_date.strftime('%Y-%m-%d')]\n",
    "    \n",
    "    # Calculate MoM or YoY percentage changes based on user input\n",
    "    if contribution_type == 'MoM':\n",
    "        data_df = df.pct_change(periods=1) * 100\n",
    "        title = \"Current Graph Displays Month-over-Month (MoM) Changes\"\n",
    "\n",
    "        # MoM source links\n",
    "        source_links = (\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tEWh' style='color:white'>All Items PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tEWu' style='color:white'>Core PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tEWx' style='color:white'>Foods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tEWD' style='color:white'>Energy PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tEWL' style='color:white'>Services PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF5t' style='color:white'>Goods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF5u' style='color:white'>Construction PPI</a>\"\n",
    "        )\n",
    "\n",
    "    else:  # 'YoY'\n",
    "        data_df = df.pct_change(periods=12) * 100\n",
    "        title = \"Current Graph Displays Year-over-Year (YoY) Changes\"\n",
    "\n",
    "        # Use MoM data to calculate the 6-month annualized growth rate\n",
    "        data_df_mom = df.pct_change(periods=1)\n",
    "\n",
    "        # Calculate the 6-month annualized rate using MoM data\n",
    "        data_df['All Items PPI (6-mo Annualized)'] = (\n",
    "            data_df_mom['All Items PPI'].rolling(window=6).apply(lambda x: np.prod(1 + x/100) ** (12 / 6) - 1)) * 100\n",
    "        data_df['Core PPI (6-mo Annualized)'] = (\n",
    "            data_df_mom['Core PPI'].rolling(window=6).apply(lambda x: np.prod(1 + x/100) ** (12 / 6) - 1)) * 100\n",
    "\n",
    "        # YoY source links\n",
    "        source_links = (\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF4M' style='color:white'>All Items PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF4P' style='color:white'>Core PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF4X' style='color:white'>Foods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF4D' style='color:white'>Energy PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF5t' style='color:white'>Services PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF5u' style='color:white'>Goods PPI</a>, \"\n",
    "            \"<a href='https://fred.stlouisfed.org/graph/?g=1tF5v' style='color:white'>Construction PPI</a>\"\n",
    "        )\n",
    "\n",
    "    # Drop rows with NaN values after calculations\n",
    "    data_df = data_df.dropna()\n",
    "\n",
    "    # Filter data from display_start_date onwards\n",
    "    data_df = data_df[data_df.index >= display_start_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "    # Calculate contribution by multiplying percentage changes by relative importance\n",
    "    contribution_df = data_df.copy()\n",
    "    for column in ['Energy PPI', 'Foods PPI', 'Goods PPI', 'Services PPI', 'Construction PPI', 'All Items PPI']:\n",
    "        contribution_df[column] = contribution_df[column] * relative_importance[column] / 100\n",
    "\n",
    "    # Round the contribution data to 3 decimal places for plotting\n",
    "    contribution_df = contribution_df.round(2)\n",
    "\n",
    "    # Create subplots: main plot and table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=[0.7, 0.3],  # Allocate more space for the plot\n",
    "        subplot_titles=(\"\", \"\"),\n",
    "        vertical_spacing=0.05,\n",
    "        specs=[[{\"type\": \"xy\"}], [{\"type\": \"table\"}]]\n",
    "    )\n",
    "\n",
    "    # Plot 1: Lines for All Items PPI and Core PPI\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=contribution_df.index, y=contribution_df['All Items PPI'],\n",
    "        mode='lines', name='All Items PPI',\n",
    "        line=dict(color='white')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=contribution_df.index, y=contribution_df['Core PPI'],\n",
    "        mode='lines', name='Core PPI',\n",
    "        line=dict(color='magenta', dash='dot')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Add 6-month annualized rate (for YoY plot)\n",
    "    if contribution_type == 'YoY':\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=contribution_df.index, y=contribution_df['All Items PPI (6-mo Annualized)'],\n",
    "            mode='lines', name='All Items PPI (6-mo Annualized)',\n",
    "            line=dict(color='white', dash='dot')\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=contribution_df.index, y=contribution_df['Core PPI (6-mo Annualized)'],\n",
    "            mode='lines', name='Core PPI (6-mo Annualized)',\n",
    "            line=dict(color='magenta', dash='dot')\n",
    "        ), row=1, col=1)\n",
    "\n",
    "    # Plot 1: Stacked Bar Plot for Contributions\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_df.index, y=contribution_df['Services PPI'],\n",
    "        name='Services PPI', marker_color='green'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_df.index, y=contribution_df['Goods PPI'],\n",
    "        name='Goods PPI', marker_color='purple'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_df.index, y=contribution_df['Foods PPI'],\n",
    "        name='Foods PPI', marker_color='blue'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_df.index, y=contribution_df['Energy PPI'],\n",
    "        name='Energy PPI', marker_color='orange'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=contribution_df.index, y=contribution_df['Construction PPI'],\n",
    "        name='Construction PPI', marker_color='yellow'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Ensure barmode is 'relative' for stacked bars\n",
    "    fig.update_layout(barmode='relative')\n",
    "\n",
    "    # Calculate the number of possible windows\n",
    "    window_size = 30  # Number of months in each window for the slider\n",
    "    data_length = len(contribution_df)\n",
    "    max_start_index = data_length - window_size\n",
    "\n",
    "    if max_start_index < 0:\n",
    "        raise ValueError(f\"Window size ({window_size}) is larger than the available data ({data_length} months).\")\n",
    "\n",
    "    # Generate all possible windows in chronological order\n",
    "    windows = [contribution_df.iloc[i:i + window_size] for i in range(max_start_index + 1)]\n",
    "\n",
    "    # Reverse the windows to have the most recent window first\n",
    "    windows = windows[::-1]\n",
    "\n",
    "    # Function to generate colors for each row based on values\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Prepare data for the initial table (most recent window)\n",
    "    initial_window = windows[0]\n",
    "    table_df = initial_window[['All Items PPI', 'Core PPI', 'Goods PPI', 'Services PPI', 'Foods PPI', 'Energy PPI', 'Construction PPI']].tail(window_size).round(3)\n",
    "    table_df = table_df.T  # Transpose for desired format\n",
    "    table_header_dates = table_df.columns.strftime(\"%y-%m\")  # Format dates as 'YY-MM'\n",
    "\n",
    "    # Generate colors for the initial table\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "    flat_colors = list(map(list, zip(*colors)))  # Transpose to match Plotly's requirement\n",
    "\n",
    "    # Create the initial table\n",
    "    table_trace = go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Item\", \"Relative Importance (%)\"] + list(table_header_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),  # Set font size to 8\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                table_df.index,  # Row labels (Item names)\n",
    "                [relative_importance.get(item, 0) for item in table_df.index],  # Relative Importance (%)\n",
    "                *[table_df[col] for col in table_df.columns]  # Contribution values\n",
    "            ],\n",
    "            fill_color=[['black'] * len(table_header_dates), ['black'] * len(table_header_dates)] + flat_colors,\n",
    "            font=dict(color='white', size=8),  # Set font size to 8\n",
    "            align=['left', 'center'] + ['center'] * len(table_header_dates),\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4, 4] + [1] * len(table_header_dates)  # Adjust column widths\n",
    "    )\n",
    "    fig.add_trace(table_trace, row=2, col=1)  # Table is the second subplot\n",
    "\n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1  # Last trace added\n",
    "\n",
    "    # Create frames for the slider\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        frame_table_df = window[['All Items PPI', 'Core PPI', 'Goods PPI', 'Services PPI', 'Foods PPI', 'Energy PPI', 'Construction PPI']].tail(window_size).round(3)\n",
    "        frame_table_df = frame_table_df.T  # Transpose\n",
    "        frame_header_dates = frame_table_df.columns.strftime(\"%y-%m\")  # Format dates as 'YY-MM'\n",
    "\n",
    "        # Generate colors for the table\n",
    "        frame_colors = [get_row_heatmap_colors(row) for _, row in frame_table_df.iterrows()]\n",
    "        frame_flat_colors = list(map(list, zip(*frame_colors)))  # Transpose\n",
    "\n",
    "        # Define updated table cells\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                frame_table_df.index,  # Row labels (Item names)\n",
    "                [relative_importance.get(item, 0) for item in frame_table_df.index],  # Relative Importance (%)\n",
    "                *[frame_table_df[col] for col in frame_table_df.columns]  # Contribution values\n",
    "            ],\n",
    "            fill_color=[['black'] * len(frame_header_dates), ['black'] * len(frame_header_dates)] + frame_flat_colors,\n",
    "            font=dict(color='white', size=8),  # Set font size to 8\n",
    "            align=['left', 'center'] + ['center'] * len(frame_header_dates),\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Define updated table header\n",
    "        updated_header = dict(\n",
    "            values=[\"Item\", \"Relative Importance (%)\"] + list(frame_header_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),  # Set font size to 8\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Calculate the start and end dates for the shaded window\n",
    "        window_start = window.index.min()\n",
    "        window_end = window.index.max()\n",
    "\n",
    "        # Define the shaded rectangle shapes for Plot 1 with fixed y-axis ranges\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=y1_min,  # Shaded area starts at y1_min\n",
    "            y1=y1_max,  # Shaded area ends at y1_max\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "\n",
    "        # Create the frame with updated table and shaded shape\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=updated_header,\n",
    "                    cells=updated_cells\n",
    "                )\n",
    "            ],\n",
    "            layout=go.Layout(\n",
    "                shapes=[shaded_shape_plot1]  # Update the shaded area\n",
    "            ),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]  # Reference to the existing table trace\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i in range(len(windows)):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=windows[i].index.min().strftime(\"%y-%m\")  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "\n",
    "    # No need to reverse the slider_steps since we already reversed the windows\n",
    "    # slider_steps = slider_steps[::-1]\n",
    "\n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps\n",
    "    )]\n",
    "\n",
    "    # Add the initial shaded area corresponding to the first window (most recent)\n",
    "    initial_window_start = windows[0].index.min()\n",
    "    initial_window_end = windows[0].index.max()\n",
    "    initial_shaded_shape = dict(\n",
    "        type=\"rect\",\n",
    "        xref=\"x1\",\n",
    "        yref=\"y1\",\n",
    "        x0=initial_window_start,\n",
    "        x1=initial_window_end,\n",
    "        y0=y1_min,\n",
    "        y1=y1_max,\n",
    "        fillcolor=\"grey\",\n",
    "        opacity=0.2,\n",
    "        line_width=0\n",
    "    )\n",
    "    fig.update_layout(shapes=[initial_shaded_shape])\n",
    "\n",
    "    # Update layout with the slider\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "    # Add footnote with a link to BLS PPI report\n",
    "    fig.add_annotation(\n",
    "        text=\"Source: <a href='https://www.bls.gov/news.release/ppi.nr0.htm' style='color:white;' target='_blank'>BLS PPI Report (Weights need to be updated manually)</a>\",\n",
    "        showarrow=False,\n",
    "        xref='paper', yref='paper',\n",
    "        x=0.5, y=-0.05,\n",
    "        xanchor='center', yanchor='top',\n",
    "        font=dict(size=8),\n",
    "        align='center'\n",
    "    )\n",
    "\n",
    "    # Update layout to match the Bloomberg-style chart with left and right margins set to 20\n",
    "    fig.update_layout(\n",
    "        barmode='relative',\n",
    "        height=900,\n",
    "        template='plotly_dark',\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=1.05,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "            font=dict(size=8)\n",
    "        ),\n",
    "        font=dict(size=8),  # Global font size for axis labels, tick marks, etc.\n",
    "        margin=dict(l=20, r=20, t=80, b=80)  # Adjusted side margins\n",
    "    )\n",
    "\n",
    "    # Fix the y-axis range to prevent dynamic scaling\n",
    "    fig.update_yaxes(range=[y1_min, y1_max], row=1, col=1)  # Fixed y-axis range for Plot 1\n",
    "\n",
    "    # Update Y-axis label to reflect that we're displaying Contributions (percentage points)\n",
    "    fig.update_yaxes(title_text=\"Contributions (percentage points)\", row=1, col=1)\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c3fc78c-142e-45fe-96df-6d19f5f26341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_10():\n",
    "    \n",
    "    # Filter for CPI and Core CPI YoY data\n",
    "    cpi_data = economic_calendar_data[economic_calendar_data['event'].str.contains(\"CPI\", case=False)]\n",
    "    core_cpi_yoy_data = economic_calendar_data[economic_calendar_data['event'].str.contains(\"Core CPI \\(YoY\\)\", case=False)]\n",
    "\n",
    "    core_cpi_yoy_data['date'] = pd.to_datetime(core_cpi_yoy_data['date'], format='%d/%m/%Y')\n",
    "    \n",
    "    # Ensure 'actual' and 'forecast' are strings\n",
    "    core_cpi_yoy_data['actual'] = core_cpi_yoy_data['actual'].astype(str)\n",
    "    core_cpi_yoy_data['forecast'] = core_cpi_yoy_data['forecast'].astype(str)\n",
    "    \n",
    "    # Handle missing or non-numeric values\n",
    "    core_cpi_yoy_data['actual'] = core_cpi_yoy_data['actual'].str.replace('%', '')\n",
    "    core_cpi_yoy_data['forecast'] = core_cpi_yoy_data['forecast'].str.replace('%', '')\n",
    "    \n",
    "    # Convert 'actual' and 'forecast' to float, handling non-numeric values gracefully\n",
    "    core_cpi_yoy_data['actual'] = pd.to_numeric(core_cpi_yoy_data['actual'], errors='coerce') \n",
    "    core_cpi_yoy_data['forecast'] = pd.to_numeric(core_cpi_yoy_data['forecast'], errors='coerce') \n",
    "    \n",
    "    # Drop rows with NaN values in 'actual' or 'forecast', except for the last row\n",
    "    core_cpi_yoy_data.dropna(subset=['actual', 'forecast'], inplace=True)\n",
    "    \n",
    "    # Calculate the surprise element\n",
    "    core_cpi_yoy_data['surprise'] = (core_cpi_yoy_data['actual'] - core_cpi_yoy_data['forecast']) / core_cpi_yoy_data['forecast']\n",
    "    \n",
    "    # Handle NaN in the last data point for 'surprise'\n",
    "    if core_cpi_yoy_data['surprise'].isna().iloc[-1]:\n",
    "        core_cpi_yoy_data = core_cpi_yoy_data.iloc[:-1]\n",
    "    \n",
    "    # Define the decay factor\n",
    "    decay_factor = 1 / 6\n",
    "    \n",
    "    # Apply the decay to the surprise element\n",
    "    core_cpi_yoy_data['smoothed_surprise'] = core_cpi_yoy_data['surprise'].ewm(span=6, adjust=False).mean()\n",
    "    \n",
    "    # Calculate the overall Economic Surprise Index\n",
    "    economic_surprise_index = core_cpi_yoy_data['smoothed_surprise'].mean()\n",
    "    print(\"Economic Surprise Index:\", economic_surprise_index)\n",
    "    \n",
    "    # Create the figure with two subplots\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                        subplot_titles=('', 'Inflation Surprise Index'),\n",
    "                        shared_xaxes=True,  # Share the x-axis between the two plots\n",
    "                        vertical_spacing=0.02)\n",
    "    \n",
    "    # Plot Actual vs Forecast Core CPI YoY\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=core_cpi_yoy_data['date'],\n",
    "        y=core_cpi_yoy_data['actual'],  # Keep as percentage for plotting\n",
    "        mode='lines+markers',\n",
    "        name='Actual Core CPI YoY',\n",
    "        line=dict(color='blue')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=core_cpi_yoy_data['date'],\n",
    "        y=core_cpi_yoy_data['forecast'],  # Keep as percentage for plotting\n",
    "        mode='lines+markers',\n",
    "        name='Forecast Core CPI YoY',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Plot Economic Surprise Index\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=core_cpi_yoy_data['date'],\n",
    "        y=core_cpi_yoy_data['smoothed_surprise']*100,  # Convert to percentage for plotting\n",
    "        mode='lines+markers',\n",
    "        name='Smoothed Surprise',\n",
    "        line=dict(color='green', dash='dot')\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # Add shaded areas for background\n",
    "    for index, row in core_cpi_yoy_data.iterrows():\n",
    "        if row['smoothed_surprise'] > 0:\n",
    "            fig.add_shape(\n",
    "                type='rect',\n",
    "                x0=row['date'],\n",
    "                x1=row['date'],\n",
    "                y0=0,\n",
    "                y1=row['smoothed_surprise']*100,\n",
    "                fillcolor='rgba(0, 255, 0, 0.2)',\n",
    "                line=dict(width=0),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        else:\n",
    "            fig.add_shape(\n",
    "                type='rect',\n",
    "                x0=row['date'],\n",
    "                x1=row['date'],\n",
    "                y0=row['smoothed_surprise']*100,\n",
    "                y1=0,\n",
    "                fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "                line=dict(width=0),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True,\n",
    "                thickness=0.1  # Set the thickness of the range slider\n",
    "            ),\n",
    "            type='date'\n",
    "        ),\n",
    "        template='plotly_dark',\n",
    "        height=800,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Update y-axis titles\n",
    "    fig.update_yaxes(title_text=\"Core CPI YoY (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Surprise Index (%)\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d65bbeb2-70ab-4878-b88e-bab5f66dca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_graph_11():\n",
    "    # Retrieve GDP deflator and CPI data from FRED\n",
    "    gdp_deflator = fred.get_series('GDPDEF', observation_start='2000-01-01', observation_end='2026-01-01')\n",
    "    cpi_qoq = fred.get_series('CPIAUCSL', observation_start='2000-01-01', observation_end='2026-01-01')\n",
    "\n",
    "    # Align both datasets to avoid mismatches in dates\n",
    "    combined_data = pd.concat([gdp_deflator, cpi_qoq], axis=1, join='inner')\n",
    "    combined_data.columns = ['gdp_deflator', 'cpi_qoq']\n",
    "\n",
    "    # Calculate the QoQ growth rates for GDP deflator and CPI\n",
    "    combined_data['gdp_deflator_qoq'] = combined_data['gdp_deflator'].pct_change() * 100  # Convert to percentage\n",
    "    combined_data['cpi_qoq_growth'] = combined_data['cpi_qoq'].pct_change() * 100  # Convert to percentage\n",
    "\n",
    "    # Drop the initial rows that may have NaN values due to pct_change()\n",
    "    combined_data.dropna(inplace=True)\n",
    "\n",
    "    # Colormap functions for heatmap colors\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Create subplots for graph and table\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.15,\n",
    "        row_heights=[0.7, 0.3],\n",
    "        specs=[[{\"type\": \"xy\", \"secondary_y\": True}], [{\"type\": \"table\"}]]\n",
    "    )\n",
    "\n",
    "    # Plot all data starting from 2000 in the graph\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=combined_data.index, y=combined_data['gdp_deflator_qoq'],\n",
    "        name='GDP Deflator QoQ',\n",
    "        marker=dict(color='white')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=combined_data.index, y=combined_data['cpi_qoq_growth'],\n",
    "        mode='lines', name='CPI QoQ',\n",
    "        line=dict(color='cyan')\n",
    "    ), row=1, col=1, secondary_y=True)\n",
    "\n",
    "    # Prepare all the windows for the slider (only affects the table)\n",
    "    window_size = 30\n",
    "    data_length = len(combined_data)\n",
    "    max_start_index = data_length - window_size\n",
    "    windows = [combined_data.iloc[i:i + window_size] for i in range(max_start_index + 1)]\n",
    "\n",
    "    # Reverse the windows to make new data appear on the left and old on the right\n",
    "    windows = windows[::-1]\n",
    "\n",
    "    # Function to create table based on the selected window\n",
    "    def create_table(data_window):\n",
    "        table_data = pd.DataFrame({\n",
    "            'Metric': ['GDP Deflator (%)', 'CPI (%)'],\n",
    "        })\n",
    "\n",
    "        # Add the actual values for the selected window\n",
    "        for date in data_window.index:\n",
    "            table_data[date.strftime('%y-%m')] = [\n",
    "                data_window.loc[date]['gdp_deflator'].round(1),\n",
    "                data_window.loc[date]['cpi_qoq'].round(1)\n",
    "            ]\n",
    "\n",
    "        # Generate colors for the table based on the data rows\n",
    "        colors = [get_row_heatmap_colors(row) for _, row in table_data.iloc[:, 1:].iterrows()]\n",
    "        flat_colors = list(map(list, zip(*colors)))  # Transpose the colors to match Plotly's column-wise format\n",
    "\n",
    "        # Add the table trace with custom formatting\n",
    "        table_trace = go.Table(\n",
    "            header=dict(\n",
    "                values=[\"Metric\"] + [date.strftime('%y-%m') for date in data_window.index],\n",
    "                fill_color='black',\n",
    "                font=dict(color='white', size=8),\n",
    "                align='center'\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[table_data['Metric']] + [table_data[date.strftime('%y-%m')].astype(str) for date in data_window.index],\n",
    "                fill_color=[['black'] * len(data_window.index)] + flat_colors,  # Apply the heatmap colors\n",
    "                font=dict(color='white', size=8),\n",
    "                align='center',\n",
    "                height=20\n",
    "            )\n",
    "        )\n",
    "        return table_trace\n",
    "\n",
    "    # Add the initial table\n",
    "    initial_window = windows[-1]  # Show the most recent 30 months initially\n",
    "    table_trace = create_table(initial_window)\n",
    "    fig.add_trace(table_trace, row=2, col=1)\n",
    "\n",
    "    # Add slider functionality (affecting only the table)\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        frame_table = create_table(window)\n",
    "\n",
    "        # Create frame with updated table and shaded area on the graph\n",
    "        window_start = window.index.min()\n",
    "        window_end = window.index.max()\n",
    "\n",
    "        # Define the grey shaded area for the 30-month window in the main plot\n",
    "        shaded_shape = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x\",  # Reference the x-axis of the main plot\n",
    "            yref=\"paper\",  # Reference the paper coordinates for the height of the shading\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=0,  # Shaded area starts from the bottom of the plot\n",
    "            y1=1,  # Shaded area goes to the top of the plot\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "\n",
    "        # Create frame with updated table and shaded area\n",
    "        frame = go.Frame(\n",
    "            data=[frame_table],\n",
    "            layout=go.Layout(shapes=[shaded_shape]),\n",
    "            name=str(i),\n",
    "            traces=[2]  # Reference the table trace index (traces start from 0, so table is trace 2)\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Add frames to figure\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Define slider steps (for table only) - reverse order for left-to-right new-to-old display\n",
    "    slider_steps = []\n",
    "    for i, window in enumerate(windows):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(mode=\"immediate\", frame=dict(duration=0, redraw=True), transition=dict(duration=0))\n",
    "            ],\n",
    "            label=window.index.min().strftime('%y-%m')\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "\n",
    "    # Add slider to layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps\n",
    "    )]\n",
    "\n",
    "    # Update layout with the slider\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'U.S. GDP Deflator and CPI (QoQ)',\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center'\n",
    "        },\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='GDP Deflator QoQ (%)',\n",
    "        yaxis2=dict(\n",
    "            title='CPI QoQ (%)',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            tickfont=dict(color='white'),\n",
    "            titlefont=dict(color='white'),\n",
    "            range=[-2, 2]\n",
    "        ),\n",
    "        sliders=sliders,\n",
    "        barmode='stack',\n",
    "        template='plotly_dark',\n",
    "        font=dict(color='white'),\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        ),\n",
    "        margin=dict(l=20, r=20, t=50, b=50),\n",
    "        annotations=[\n",
    "            dict(\n",
    "                x=0.5,\n",
    "                y=-0.015,\n",
    "                showarrow=False,\n",
    "                text=\"Federal Reserve Economic Data (FRED) |<a href='https://fred.stlouisfed.org/graph/?g=1tS31' style='color:white'>Gross Domestic Product: Implicit Price Deflator</a>\",\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                font=dict(color='white')\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2ce851a-e9bd-42ad-bcfa-158cb68c0593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Surprise Index: 0.006807070417542748\n"
     ]
    }
   ],
   "source": [
    "def generate_cpi_detailed_graph_12():\n",
    "    # Initialize FRED with the provided API Key\n",
    "    fred = Fred(api_key=api_key)\n",
    "\n",
    "    # Retrieve the expected inflation data for 1-year, 2-year, 3-year, and 5-year\n",
    "    expinf1yr = fred.get_series('EXPINF1YR')\n",
    "    expinf2yr = fred.get_series('EXPINF2YR')\n",
    "    expinf3yr = fred.get_series('EXPINF3YR')\n",
    "    expinf5yr = fred.get_series('EXPINF5YR')\n",
    "\n",
    "    # Filter data from 2015 onwards\n",
    "    start_date = '2015-01-01'\n",
    "    expinf1yr = expinf1yr[expinf1yr.index >= start_date]\n",
    "    expinf2yr = expinf2yr[expinf2yr.index >= start_date]\n",
    "    expinf3yr = expinf3yr[expinf3yr.index >= start_date]\n",
    "    expinf5yr = expinf5yr[expinf5yr.index >= start_date]\n",
    "\n",
    "    # Prepare date range for plotting\n",
    "    dates = expinf1yr.index\n",
    "    window_size = 30  # Number of months to display in the table and shading window\n",
    "\n",
    "    # Function to generate colormap for table cells (green for lower values, red for higher)\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()  # Get min and max values for normalization\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Create subplots: graph on top, table below\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        row_heights=[0.75, 0.25],  # 75% for graph, 25% for table\n",
    "        specs=[[{\"type\": \"scatter\"}], [{\"type\": \"table\"}]],\n",
    "        vertical_spacing=0.08  # Increase gap between the graph and the table\n",
    "    )\n",
    "\n",
    "    # Add the line plot on top\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=expinf1yr, mode='lines', name='1-Year Expected Inflation',\n",
    "        line=dict(color='cyan', width=2)\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=expinf2yr, mode='lines', name='2-Year Expected Inflation',\n",
    "        line=dict(color='yellow', width=2)\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=expinf3yr, mode='lines', name='3-Year Expected Inflation',\n",
    "        line=dict(color='green', width=2)\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=expinf5yr, mode='lines', name='5-Year Expected Inflation',\n",
    "        line=dict(color='red', width=2)\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Add 2% Fed target line (dashed) for all expected inflation plots\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates, y=[2]*len(dates), mode='lines', name='2% Fed Target',\n",
    "        line=dict(color='white', dash='dash'),  # Dotted white line\n",
    "        showlegend=True\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Create the initial table below the graph with the most recent data\n",
    "    initial_table_data = pd.DataFrame({\n",
    "        \"1-Year Exp. Inflation (%)\": expinf1yr.tail(30).values,\n",
    "        \"2-Year Exp. Inflation (%)\": expinf2yr.tail(30).values,\n",
    "        \"3-Year Exp. Inflation (%)\": expinf3yr.tail(30).values,\n",
    "        \"5-Year Exp. Inflation (%)\": expinf5yr.tail(30).values\n",
    "    }).T.round(2)\n",
    "\n",
    "    initial_dates_for_table = expinf1yr.tail(30).index.strftime(\"%y-%m\")\n",
    "\n",
    "    # Generate colors for the initial table using the green-to-red colormap function\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in initial_table_data.iterrows()]\n",
    "    flat_colors = list(map(list, zip(*colors)))  # Transpose colors to match Plotly's format\n",
    "\n",
    "    # Add the initial table to the figure\n",
    "    fig.add_trace(go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Items\"] + list(initial_dates_for_table),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                initial_table_data.index,  # Row labels\n",
    "                *[initial_table_data[col] for col in initial_table_data.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(initial_dates_for_table)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        ),\n",
    "        columnwidth=[4] + [0.5] * len(initial_dates_for_table)  # Adjust column widths\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    # Identify the trace index of the table\n",
    "    table_trace_index = len(fig.data) - 1\n",
    "\n",
    "    # Create frames for table data based on different windows\n",
    "    frames = []\n",
    "    for i in range(len(dates) - window_size):\n",
    "        window_start = dates[i]\n",
    "        window_end = dates[i + window_size]\n",
    "\n",
    "        # Create table data for each window\n",
    "        window_data = {\n",
    "            \"1-Year Exp. Inflation (%)\": expinf1yr[i:i+30].values,\n",
    "            \"2-Year Exp. Inflation (%)\": expinf2yr[i:i+30].values,\n",
    "            \"3-Year Exp. Inflation (%)\": expinf3yr[i:i+30].values,\n",
    "            \"5-Year Exp. Inflation (%)\": expinf5yr[i:i+30].values\n",
    "        }\n",
    "        table_data = pd.DataFrame(window_data).T.round(2)\n",
    "        table_dates = expinf1yr[i:i+30].index.strftime(\"%y-%m\")\n",
    "\n",
    "        # Generate heatmap colors for the current table window\n",
    "        window_colors = [get_row_heatmap_colors(row) for _, row in table_data.iterrows()]\n",
    "        flat_colors = list(map(list, zip(*window_colors)))  # Transpose colors\n",
    "\n",
    "        # Create updated header and cells for the table\n",
    "        updated_header = dict(\n",
    "            values=[\"Items\"] + list(table_dates),\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        updated_cells = dict(\n",
    "            values=[\n",
    "                table_data.index,  # Row labels\n",
    "                *[table_data[col] for col in table_data.columns]  # Column data\n",
    "            ],\n",
    "            fill_color=[['black'] * len(table_dates)] + flat_colors,\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=20\n",
    "        )\n",
    "\n",
    "        # Define shaded areas for the main plot\n",
    "        shaded_shape_plot1 = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x1\",  # References the x-axis of the first subplot\n",
    "            yref=\"y1\",  # References the y-axis of the first subplot only\n",
    "            x0=window_start,\n",
    "            x1=window_end,\n",
    "            y0=-0.5,\n",
    "            y1=5,  # Customizable range of the y-axis\n",
    "            fillcolor=\"grey\",\n",
    "            opacity=0.2,\n",
    "            line_width=0\n",
    "        )\n",
    "\n",
    "        # Create a frame with updated table data and shaded area\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Table(header=updated_header, cells=updated_cells)\n",
    "            ],\n",
    "            layout=go.Layout(shapes=[shaded_shape_plot1]),\n",
    "            name=str(i),\n",
    "            traces=[table_trace_index]\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Create slider steps for the animation (Newest to Oldest)\n",
    "    slider_steps = []\n",
    "    for i in range(len(frames)-1, -1, -1):  # Reverse the slider steps\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[[str(i)], dict(frame=dict(duration=0, redraw=True), mode=\"immediate\")],\n",
    "            label=dates[i].strftime(\"%Y-%m\")\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "\n",
    "    # Add slider that controls the table\n",
    "    fig.update_layout(\n",
    "        sliders=[{\n",
    "            \"active\": 0,\n",
    "            \"currentvalue\": {\"prefix\": \"Start Date: \"},\n",
    "            \"pad\": {\"t\": 50},\n",
    "            \"steps\": slider_steps\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Add source note with FRED links\n",
    "    fig.add_annotation(\n",
    "        text=('Source: Federal Reserve Economic Data (FRED). '\n",
    "              '<a href=\"https://fred.stlouisfed.org/series/EXPINF1YR\" style=\"color: cyan\">1-Year Expected Inflation</a>, '\n",
    "              '<a href=\"https://fred.stlouisfed.org/series/EXPINF2YR\" style=\"color: cyan\">2-Year Expected Inflation</a>, '\n",
    "              '<a href=\"https://fred.stlouisfed.org/series/EXPINF3YR\" style=\"color: cyan\">3-Year Expected Inflation</a>, '\n",
    "              '<a href=\"https://fred.stlouisfed.org/series/EXPINF5YR\" style=\"color: cyan\">5-Year Expected Inflation</a>.'),\n",
    "        font=dict(size=8, color=\"white\"),\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=-0.1,  # Position below the plot\n",
    "        showarrow=False\n",
    "    )\n",
    "\n",
    "    # Update layout settings\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_dark\",\n",
    "        font=dict(color=\"white\", size=10),\n",
    "        title=\"Expected Inflation for 1, 2, 3, and 5 Years\",\n",
    "        height=900,\n",
    "        width=1000,\n",
    "        margin=dict(t=50, b=150, l=20, r=20),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb60a2b-afe3-4717-bdd6-55d47981f9d8",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1764b1a9-6dc9-4d37-8747-d396a0da7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_table_1():\n",
    "\n",
    "    # Initialize FRED API\n",
    "    fred = Fred(api_key=api_key)\n",
    "\n",
    "    # Define the series IDs for the required inflation data from FRED\n",
    "    series_ids = {\n",
    "        'PPI': 'PPIACO',                             # Producer Price Index for All Commodities\n",
    "        'PCE': 'PCEPI',                              # Personal Consumption Expenditures Price Index\n",
    "        'Cleveland Median CPI': 'MEDCPIM158SFRBCLE', # Cleveland Median CPI\n",
    "        '16% Trimmed Mean CPI': 'TRMMEANCPIM158SFRBCLE', # 16% Trimmed Mean CPI\n",
    "        'Sticky CPI': 'STICKCPIM157SFRBATL',         # Atlanta Fed Sticky CPI\n",
    "        'Trimmed Mean PCE': 'PCETRIM1M158SFRBDAL'    # Dallas Fed Trimmed Mean PCE  \n",
    "    }\n",
    "\n",
    "    # Determine the buffer period for MoM calculations\n",
    "    buffer_period = 1  # 1 month buffer for MoM (December 2014 needed for January 2015)\n",
    "\n",
    "    # Calculate the start date needed to accommodate the buffer\n",
    "    display_start_date = datetime(2015, 1, 1)\n",
    "    buffer_start_date = display_start_date - relativedelta(months=buffer_period)\n",
    "\n",
    "    # Fetch and process data for each series\n",
    "    data = {}\n",
    "    for name, series_id in series_ids.items():\n",
    "        try:\n",
    "            # Fetch the series data\n",
    "            series_data = fred.get_series(series_id)\n",
    "            # Ensure the index is datetime\n",
    "            series_data.index = pd.to_datetime(series_data.index)\n",
    "            # Filter data from buffer_start_date onwards\n",
    "            series_data = series_data[series_data.index >= buffer_start_date]\n",
    "            # Calculate MoM percentage changes\n",
    "            series_pct_change = series_data.pct_change(periods=1) * 100\n",
    "            data[name] = series_pct_change\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
    "            data[name] = pd.Series(dtype=float)\n",
    "\n",
    "    # Create a DataFrame from the retrieved data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Drop rows with all NaN values to clean up the DataFrame\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Filter to show only data from 2015-01-01 onwards\n",
    "    df = df[df.index >= display_start_date]\n",
    "\n",
    "    # Fill NA values to avoid issues in the table\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert dates to 'YY-MM' format for the table\n",
    "    df.index = pd.to_datetime(df.index).strftime('%y-%m')\n",
    "\n",
    "    # Determine the total number of months available\n",
    "    total_months = len(df)\n",
    "    window_size = 30  # Number of months in each window\n",
    "    step_size = 6     # Step size in months\n",
    "\n",
    "    # Generate all possible windows with 6-month steps\n",
    "    windows = []\n",
    "    window_labels = []\n",
    "    for start in range(0, total_months - window_size + 1, step_size):\n",
    "        window = df.iloc[start:start + window_size]\n",
    "        windows.append(window)\n",
    "        window_labels.append(window.index[0])  # Label with the start date of the window\n",
    "\n",
    "    # Reverse the windows and labels to have newest on the left\n",
    "    windows = windows[::-1]\n",
    "    window_labels = window_labels[::-1]\n",
    "\n",
    "    # Function to generate colors for heatmap per item\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Create the initial table data (first window)\n",
    "    initial_window = windows[0]\n",
    "    table_df = initial_window.transpose().round(2)\n",
    "    table_header_dates = table_df.columns.tolist()  # Corrected: Use columns (dates) for headers\n",
    "\n",
    "    # Generate colors for the initial table\n",
    "    colors = [get_row_heatmap_colors(row) for _, row in table_df.iterrows()]\n",
    "    flat_colors = list(map(list, zip(*colors)))  # Transpose to match Plotly's requirement\n",
    "\n",
    "    # Prepare the colors for Plotly Table\n",
    "    color_fill = [['black'] * len(table_header_dates)] + flat_colors  # Header colors + Cell colors\n",
    "\n",
    "    # Modify the columnwidth to ensure the first column is wider\n",
    "    columnwidth = [4] + [1] * len(table_header_dates)\n",
    "\n",
    "    # Create the initial table\n",
    "    fig = go.Figure(\n",
    "        data=[go.Table(\n",
    "            columnwidth=columnwidth,  # Adjusted columnwidth\n",
    "            header=dict(\n",
    "                values=[\"Item\"] + list(table_header_dates),\n",
    "                fill_color='black',\n",
    "                font=dict(color='white', size=8),  # Font size for the header\n",
    "                align='center',\n",
    "                height=30\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[table_df.index] + [table_df[col] for col in table_df.columns],\n",
    "                fill=dict(color=color_fill),\n",
    "                font=dict(color='white', size=8),  # Font size for the cells\n",
    "                align=['left'] + ['center'] * len(table_header_dates),\n",
    "                height=20  # Cell height for better visibility\n",
    "            )\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    # Add frames for each window\n",
    "    frames = []\n",
    "    for i, window in enumerate(windows):\n",
    "        frame_table_df = window.transpose().round(2)\n",
    "        frame_header_dates = frame_table_df.columns.tolist()  # Corrected: Use columns (dates) for headers\n",
    "\n",
    "        # Generate colors for the table\n",
    "        frame_colors = [get_row_heatmap_colors(row) for _, row in frame_table_df.iterrows()]\n",
    "        frame_flat_colors = list(map(list, zip(*frame_colors)))  # Transpose\n",
    "\n",
    "        # Prepare fill colors\n",
    "        frame_color_fill = [['black'] * len(frame_header_dates)] + frame_flat_colors  # Header + Cells\n",
    "\n",
    "        # Define the table for this frame\n",
    "        frame_table = go.Table(\n",
    "            columnwidth=columnwidth,  # Ensure column widths are consistent\n",
    "            header=dict(\n",
    "                values=[\"Item\"] + list(frame_header_dates),\n",
    "                fill_color='black',\n",
    "                font=dict(color='white', size=8),\n",
    "                align='center',\n",
    "                height=30\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[frame_table_df.index] + [frame_table_df[col] for col in frame_table_df.columns],\n",
    "                fill=dict(color=frame_color_fill),\n",
    "                font=dict(color='white', size=8),\n",
    "                align=['left'] + ['center'] * len(frame_header_dates),\n",
    "                height=20\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Create the frame\n",
    "        frame = go.Frame(\n",
    "            data=[frame_table],\n",
    "            name=str(i)  # Frame name must be a string\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Add frames to the figure\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i, label in enumerate(window_labels):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=label  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "\n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps,\n",
    "        len=0.9,\n",
    "        x=0.05,\n",
    "        y=0\n",
    "    )]\n",
    "\n",
    "    # Update layout with the slider\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "    # Add source links as annotations below the table\n",
    "    source_text = (\n",
    "        \"Sources: \"\n",
    "        \"<a href='https://fred.stlouisfed.org/graph/?g=1uO7f' style='color:white'>PPI</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/graph/?g=1uO8j' style='color:white'>Median Consumer Price Index</a>\"\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=source_text,\n",
    "        showarrow=False,\n",
    "        xref='paper', yref='paper',\n",
    "        x=0.5, y=-0.2,  # Positioned below the table\n",
    "        xanchor='center', yanchor='top',\n",
    "        font=dict(size=8),\n",
    "        align='center'\n",
    "    )\n",
    "\n",
    "    # Update layout for a black background\n",
    "    fig.update_layout(\n",
    "        width=1000,  # Adjust width to fit the table\n",
    "        height=300,  # Adjust height for better visibility\n",
    "        template='plotly_dark',  # Use Plotly's dark template\n",
    "        margin=dict(l=20, r=20, t=20, b=50),\n",
    "        plot_bgcolor='black',  # Set the plot background color to black\n",
    "        paper_bgcolor='black'  # Set the paper background color to black\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "822f7e50-8a16-49b6-a8c6-92ef94be3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_table_2(): \n",
    "    def process_event_data(event_name):\n",
    "        # Filter event-related data (MoM events for CPI, PCE, PPI, Cleveland CPI)\n",
    "        event_data = economic_calendar_data[economic_calendar_data['event'].str.contains(f\"{event_name} \\\\(MoM\\\\)\", case=False)]\n",
    "        \n",
    "        # Convert 'date' to datetime\n",
    "        event_data['date'] = pd.to_datetime(event_data['date'], format='%d/%m/%Y')\n",
    "\n",
    "        # Ensure 'actual' and 'forecast' are strings\n",
    "        event_data['actual'] = event_data['actual'].astype(str)\n",
    "        event_data['forecast'] = event_data['forecast'].astype(str)\n",
    "\n",
    "        # Handle missing or non-numeric values\n",
    "        event_data['actual'] = event_data['actual'].str.replace('%', '')\n",
    "        event_data['forecast'] = event_data['forecast'].str.replace('%', '')\n",
    "\n",
    "        # Convert 'actual' and 'forecast' to float, handling non-numeric values\n",
    "        event_data['actual'] = pd.to_numeric(event_data['actual'], errors='coerce')\n",
    "        event_data['forecast'] = pd.to_numeric(event_data['forecast'], errors='coerce')\n",
    "\n",
    "        # Drop rows with NaN values in 'actual' or 'forecast'\n",
    "        event_data.dropna(subset=['actual', 'forecast'], inplace=True)\n",
    "\n",
    "        # Keep only the most recent event data for each month\n",
    "        event_data['year_month'] = event_data['date'].dt.to_period('M')\n",
    "        event_data = event_data.groupby('year_month').apply(lambda x: x.loc[x['date'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # Calculate the surprise element\n",
    "        event_data['surprise'] = (event_data['actual'] - event_data['forecast']) / event_data['forecast'] * 100\n",
    "\n",
    "        # Select the last 30 periods (months)\n",
    "        last_30_periods = event_data.tail(30)\n",
    "\n",
    "        # Create a DataFrame for the table\n",
    "        df_table = last_30_periods[['date', 'actual', 'forecast', 'surprise']].copy()\n",
    "        df_table.columns = ['Date', 'Actual (%)', 'Forecast (%)', 'Surprise (%)']\n",
    "\n",
    "        # Format the date to show only year and month\n",
    "        df_table['Date'] = df_table['Date'].dt.strftime('%y-%m')\n",
    "\n",
    "        # Fill NaN values with 0 to avoid invalid color generation\n",
    "        df_table.fillna(0, inplace=True)\n",
    "\n",
    "        # Transpose the DataFrame to have periods as columns and metrics as rows\n",
    "        df_table_transposed = df_table.set_index('Date').transpose()\n",
    "\n",
    "        return df_table_transposed\n",
    "\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if np.isnan(value):\n",
    "            return 'rgba(100, 100, 100, 0.6)'  # Grey for NaN values\n",
    "        norm_value = (value - vmin) / (vmax - vmin) if vmax != vmin else 0\n",
    "        if value < 0:\n",
    "            return f'rgba(0, {int(255 * (1 + norm_value))}, 0, 0.6)'  # Green for deflation\n",
    "        else:\n",
    "            return f'rgba({int(255 * norm_value)}, 0, 0, 0.6)'  # Red for inflation\n",
    "\n",
    "    def create_color_fill_per_component(df):\n",
    "        color_fill = []\n",
    "        for row in df.values:\n",
    "            row_colors = get_row_heatmap_colors(row)\n",
    "            color_fill.append(row_colors)\n",
    "        color_fill_transposed = list(zip(*color_fill))\n",
    "        return color_fill_transposed\n",
    "\n",
    "    # Process Core CPI, Cleveland CPI, PCE, and PPI data\n",
    "    cpi_table = process_event_data(\"Core CPI\")\n",
    "    pce_table = process_event_data(\"PCE Price Index\")\n",
    "    ppi_table = process_event_data(\"PPI\")\n",
    "\n",
    "    # Create subplots with 3 rows, reduced vertical spacing\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        specs=[[{'type': 'table'}], [{'type': 'table'}], [{'type': 'table'}]],\n",
    "        subplot_titles=(\"Core CPI (MoM)\", \"PCE Price Index (MoM)\", \"PPI (MoM)\"),\n",
    "        vertical_spacing=0.01  # Reduced vertical space between plots\n",
    "    )\n",
    "\n",
    "    # Add Core CPI table\n",
    "    if not cpi_table.empty:\n",
    "        color_fill_cpi = create_color_fill_per_component(cpi_table)\n",
    "        fig.add_trace(go.Table(\n",
    "            columnwidth=[150] + [80] * len(cpi_table.columns),\n",
    "            header=dict(values=[\"Item\"] + list(cpi_table.columns), fill_color='black', font=dict(color='white', size=8), align='center'),\n",
    "            cells=dict(values=[cpi_table.index] + [cpi_table[col].round(2) for col in cpi_table.columns],\n",
    "                       fill=dict(color=[['black'] * len(cpi_table.columns)] + color_fill_cpi), font=dict(color='white', size=8),\n",
    "                       align='center', height=20)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # Add PCE table\n",
    "    if not pce_table.empty:\n",
    "        color_fill_pce = create_color_fill_per_component(pce_table)\n",
    "        fig.add_trace(go.Table(\n",
    "            columnwidth=[150] + [80] * len(pce_table.columns),\n",
    "            header=dict(values=[\"Item\"] + list(pce_table.columns), fill_color='black', font=dict(color='white', size=8), align='center'),\n",
    "            cells=dict(values=[pce_table.index] + [pce_table[col].round(2) for col in pce_table.columns],\n",
    "                       fill=dict(color=[['black'] * len(pce_table.columns)] + color_fill_pce), font=dict(color='white', size=8),\n",
    "                       align='center', height=20)),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # Add PPI table\n",
    "    if not ppi_table.empty:\n",
    "        color_fill_ppi = create_color_fill_per_component(ppi_table)\n",
    "        fig.add_trace(go.Table(\n",
    "            columnwidth=[150] + [80] * len(ppi_table.columns),\n",
    "            header=dict(values=[\"Item\"] + list(ppi_table.columns), fill_color='black', font=dict(color='white', size=8), align='center'),\n",
    "            cells=dict(values=[ppi_table.index] + [ppi_table[col].round(2) for col in ppi_table.columns],\n",
    "                       fill=dict(color=[['black'] * len(ppi_table.columns)] + color_fill_ppi), font=dict(color='white', size=8),\n",
    "                       align='center', height=20)),\n",
    "            row=3, col=1\n",
    "        )\n",
    "\n",
    "    # Single source note for CPI, PCE, and PPI\n",
    "    annotations = [\n",
    "        dict(\n",
    "            text=(\"Source: Economic Calendar Data from Investing.com | \"\n",
    "                  \"<a href='https://www.investing.com/economic-calendar/cpi-733'>CPI</a>, \"\n",
    "                  \"<a href='https://www.investing.com/economic-calendar/pce-price-index-735'>PCE</a>, \"\n",
    "                  \"<a href='https://www.investing.com/economic-calendar/ppi-734'>PPI</a> | \"\n",
    "                  \"Note: MoM Growth\"),\n",
    "            xref=\"paper\", yref=\"paper\",\n",
    "            x=0, y=-0.15,\n",
    "            showarrow=False,\n",
    "            font=dict(size=8, color=\"white\"),\n",
    "            align=\"left\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Update layout for a black background, add the main title and annotations\n",
    "    fig.update_layout(\n",
    "        title=\"Economic Indicators Comparison: CPI, PCE, and PPI\",\n",
    "        width=1000,\n",
    "        height=600,  # Increased height to accommodate more rows\n",
    "        template='plotly_dark',\n",
    "        margin=dict(l=20, r=20, t=80, b=80),\n",
    "        annotations=annotations\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89075fe8-7d27-41da-a169-292c210340eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpi_detailed_summary_table_1(observation_start='2014-12-01'):\n",
    "    # Initialize FRED API\n",
    "    fred = Fred(api_key=api_key)\n",
    "\n",
    "    # Define the series IDs for the required inflation data from FRED\n",
    "    series_ids = {\n",
    "        'All Items': 'CPIAUCSL',\n",
    "        'Food and Beverages': 'CPIFABSL',\n",
    "        'Housing': 'CPIHOSSL',\n",
    "        'Apparel': 'CPIAPPSL',\n",
    "        'Transportation': 'CPITRNSL',\n",
    "        'Medical Care': 'CPIMEDSL',\n",
    "        'Recreation': 'CPIRECSL',\n",
    "        'Education and Communication': 'CPIEDUSL',\n",
    "        'Other Goods and Services': 'CPIOGSSL',\n",
    "        'Core CPI': 'CPILFESL',\n",
    "        '  Commodities': 'CUSR0000SAC',\n",
    "        '  Energy': 'CPIENGSL',\n",
    "        '  Services': 'CUSR0000SAS',\n",
    "        '  Non Durables': 'CUSR0000SAN',\n",
    "        'All Items less Food': 'CPIULFSL',\n",
    "        'All Items less Energy': 'CPILEGSL',\n",
    "        'All Items less Food and Energy': 'CPILFESL'\n",
    "    }\n",
    "\n",
    "    bold_categories = [\n",
    "        'All Items', 'Core CPI', 'All Items less Food',\n",
    "        'All Items less Energy', 'All Items less Food and Energy'\n",
    "    ]\n",
    "\n",
    "    # Fetch data from FRED and calculate MoM and YoY rates\n",
    "    data_mom = {}\n",
    "    data_yoy = {}\n",
    "    for name, series_id in series_ids.items():\n",
    "        while True:\n",
    "            try:\n",
    "                # Fetch data from FRED\n",
    "                series_data = fred.get_series(series_id, observation_start=observation_start).resample('M').mean()\n",
    "                break\n",
    "            except ValueError as e:\n",
    "                if \"Too Many Requests\" in str(e):\n",
    "                    print(\"Rate limit exceeded. Waiting before retrying...\")\n",
    "                    time.sleep(60)  # Wait for a minute before retrying\n",
    "                else:\n",
    "                    print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
    "                    data_mom[name] = pd.Series(dtype=float)\n",
    "                    data_yoy[name] = pd.Series(dtype=float)\n",
    "                    break\n",
    "\n",
    "        if not series_data.empty:\n",
    "            # Calculate MoM and YoY rates\n",
    "            data_mom[name] = series_data.pct_change() * 100  # MoM percentage change\n",
    "            data_yoy[name] = (series_data / series_data.shift(12) - 1) * 100  # YoY percentage change\n",
    "\n",
    "    # Create DataFrames for MoM and YoY\n",
    "    df_mom = pd.DataFrame(data_mom).dropna(how='all')\n",
    "    df_yoy = pd.DataFrame(data_yoy).dropna(how='all')\n",
    "\n",
    "    # Filter to show only data from January 2015 onwards\n",
    "    display_start_date = datetime(2015, 1, 1)\n",
    "    df_mom = df_mom[df_mom.index >= display_start_date]\n",
    "    df_yoy = df_yoy[df_yoy.index >= display_start_date]\n",
    "\n",
    "    # Fill NA values to avoid issues in the table\n",
    "    df_mom.fillna(0, inplace=True)\n",
    "    df_yoy.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert dates to 'YY-MM' format for the table\n",
    "    df_mom.index = pd.to_datetime(df_mom.index).strftime('%y-%m')\n",
    "    df_yoy.index = pd.to_datetime(df_yoy.index).strftime('%y-%m')\n",
    "\n",
    "    # Define window parameters\n",
    "    window_size = 15  # Number of months in each window\n",
    "    step_size = 4     # Step size in months\n",
    "\n",
    "    # Generate all possible windows with 4-month steps\n",
    "    def generate_windows(df, window_size, step_size):\n",
    "        total_months = len(df)\n",
    "        windows = []\n",
    "        window_labels = []\n",
    "        for start in range(0, total_months - window_size + 1, step_size):\n",
    "            window = df.iloc[start:start + window_size]\n",
    "            windows.append(window)\n",
    "            window_labels.append(window.index[0])  # Label with the start date of the window\n",
    "        # Reverse to have newest on the left\n",
    "        windows = windows[::-1]\n",
    "        window_labels = window_labels[::-1]\n",
    "        return windows, window_labels\n",
    "\n",
    "    windows_mom, window_labels_mom = generate_windows(df_mom, window_size, step_size)\n",
    "    windows_yoy, window_labels_yoy = generate_windows(df_yoy, window_size, step_size)\n",
    "\n",
    "    # Ensure both MoM and YoY have the same number of windows\n",
    "    min_windows = min(len(windows_mom), len(windows_yoy))\n",
    "    windows_mom = windows_mom[:min_windows]\n",
    "    windows_yoy = windows_yoy[:min_windows]\n",
    "    window_labels = window_labels_mom[:min_windows]  # Use MoM labels\n",
    "\n",
    "    # Function to generate colors for heatmap per row\n",
    "    def get_row_heatmap_colors(row):\n",
    "        vmin, vmax = row.min(), row.max()\n",
    "        return [get_heatmap_color(value, vmin, vmax) for value in row]\n",
    "\n",
    "    # Function to get a heatmap color for a given value\n",
    "    def get_heatmap_color(value, vmin, vmax):\n",
    "        if vmax - vmin == 0:\n",
    "            norm_value = 0.5  # Avoid division by zero\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize between 0 and 1\n",
    "        if value < 0:\n",
    "            # Green shades for negative values (deflation)\n",
    "            green_intensity = int(255 * (1 + norm_value))  # Scale between 0 and 255\n",
    "            return f'rgba(0, {green_intensity}, 0, 0.6)'\n",
    "        else:\n",
    "            # Red shades for positive values (inflation)\n",
    "            red_intensity = int(255 * norm_value)  # Scale between 0 and 255\n",
    "            return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
    "\n",
    "    # Create the initial MoM table (first window)\n",
    "    initial_window_mom = windows_mom[0]\n",
    "    table_df_mom = initial_window_mom.transpose().round(1)\n",
    "    table_header_dates_mom = table_df_mom.columns.tolist()  # Dates as 'YY-MM'\n",
    "\n",
    "    # Generate colors for the initial MoM table\n",
    "    colors_mom = [get_row_heatmap_colors(row) for _, row in table_df_mom.iterrows()]\n",
    "    flat_colors_mom = list(map(list, zip(*colors_mom)))  # Transpose to match Plotly's requirement\n",
    "\n",
    "    # Prepare the colors for Plotly Table (MoM)\n",
    "    color_fill_mom = [['black'] * len(table_header_dates_mom)] + flat_colors_mom  # Header + Cells\n",
    "\n",
    "    # Format categories with bold and indentation\n",
    "    formatted_categories_mom = []\n",
    "    for category in table_df_mom.index:\n",
    "        if category in bold_categories:\n",
    "            formatted_categories_mom.append(f\"<b>{category.strip()}</b>\")\n",
    "        elif category.startswith('  '):  # Indent subcategories\n",
    "            formatted_categories_mom.append(f\"&nbsp;&nbsp;&nbsp;{category.strip()}\")\n",
    "        else:\n",
    "            formatted_categories_mom.append(category)\n",
    "\n",
    "    # Create the initial MoM table\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Table(\n",
    "        name='MoM',\n",
    "        columnwidth=[200] + [80 for _ in range(len(table_header_dates_mom))],\n",
    "        header=dict(\n",
    "            values=[\"Category\"] + table_header_dates_mom,\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=30\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[formatted_categories_mom] + [table_df_mom[col] for col in table_df_mom.columns],\n",
    "            fill=dict(color=color_fill_mom),\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left'] + ['center'] * len(table_header_dates_mom),\n",
    "            height=20\n",
    "        ),\n",
    "        visible=True\n",
    "    ))\n",
    "\n",
    "    # Create the initial YoY table (first window)\n",
    "    initial_window_yoy = windows_yoy[0]\n",
    "    table_df_yoy = initial_window_yoy.transpose().round(1)\n",
    "    table_header_dates_yoy = table_df_yoy.columns.tolist()  # Dates as 'YY-MM'\n",
    "\n",
    "    # Generate colors for the initial YoY table\n",
    "    colors_yoy = [get_row_heatmap_colors(row) for _, row in table_df_yoy.iterrows()]\n",
    "    flat_colors_yoy = list(map(list, zip(*colors_yoy)))  # Transpose to match Plotly's requirement\n",
    "\n",
    "    # Prepare the colors for Plotly Table (YoY)\n",
    "    color_fill_yoy = [['black'] * len(table_header_dates_yoy)] + flat_colors_yoy  # Header + Cells\n",
    "\n",
    "    # Format categories with bold and indentation\n",
    "    formatted_categories_yoy = []\n",
    "    for category in table_df_yoy.index:\n",
    "        if category in bold_categories:\n",
    "            formatted_categories_yoy.append(f\"<b>{category.strip()}</b>\")\n",
    "        elif category.startswith('  '):  # Indent subcategories\n",
    "            formatted_categories_yoy.append(f\"&nbsp;&nbsp;&nbsp;{category.strip()}\")\n",
    "        else:\n",
    "            formatted_categories_yoy.append(category)\n",
    "\n",
    "    # Create the YoY table (hidden by default)\n",
    "    fig.add_trace(go.Table(\n",
    "        name='YoY',\n",
    "        columnwidth=[200] + [80 for _ in range(len(table_header_dates_yoy))],\n",
    "        header=dict(\n",
    "            values=[\"Category\"] + table_header_dates_yoy,\n",
    "            fill_color='black',\n",
    "            font=dict(color='white', size=8),\n",
    "            align='center',\n",
    "            height=30\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[formatted_categories_yoy] + [table_df_yoy[col] for col in table_df_yoy.columns],\n",
    "            fill=dict(color=color_fill_yoy),\n",
    "            font=dict(color='white', size=8),\n",
    "            align=['left'] + ['center'] * len(table_header_dates_yoy),\n",
    "            height=20\n",
    "        ),\n",
    "        visible=False\n",
    "    ))\n",
    "\n",
    "    # Add frames for each window\n",
    "    frames = []\n",
    "    for i in range(min_windows):\n",
    "        window_mom = windows_mom[i].transpose().round(1)\n",
    "        window_yoy = windows_yoy[i].transpose().round(1)\n",
    "        header_dates_mom = window_mom.columns.tolist()\n",
    "        header_dates_yoy = window_yoy.columns.tolist()\n",
    "\n",
    "        # Generate colors for MoM\n",
    "        colors_mom_frame = [get_row_heatmap_colors(row) for _, row in window_mom.iterrows()]\n",
    "        flat_colors_mom_frame = list(map(list, zip(*colors_mom_frame)))\n",
    "\n",
    "        # Prepare fill colors for MoM\n",
    "        color_fill_mom_frame = [['black'] * len(header_dates_mom)] + flat_colors_mom_frame\n",
    "\n",
    "        # Format categories for MoM\n",
    "        formatted_categories_mom_frame = []\n",
    "        for category in window_mom.index:\n",
    "            if category in bold_categories:\n",
    "                formatted_categories_mom_frame.append(f\"<b>{category.strip()}</b>\")\n",
    "            elif category.startswith('  '):\n",
    "                formatted_categories_mom_frame.append(f\"&nbsp;&nbsp;&nbsp;{category.strip()}\")\n",
    "            else:\n",
    "                formatted_categories_mom_frame.append(category)\n",
    "\n",
    "        # Generate MoM table frame\n",
    "        frame_mom = go.Table(\n",
    "            columnwidth=[200] + [80 for _ in range(len(header_dates_mom))],\n",
    "            header=dict(\n",
    "                values=[\"Category\"] + header_dates_mom,\n",
    "                fill_color='black',\n",
    "                font=dict(color='white', size=8),\n",
    "                align='center',\n",
    "                height=20\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[formatted_categories_mom_frame] + [window_mom[col] for col in window_mom.columns],\n",
    "                fill=dict(color=color_fill_mom_frame),\n",
    "                font=dict(color='white', size=8),\n",
    "                align=['left'] + ['center'] * len(header_dates_mom),\n",
    "                height=20\n",
    "            ),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "        # Generate colors for YoY\n",
    "        colors_yoy_frame = [get_row_heatmap_colors(row) for _, row in window_yoy.iterrows()]\n",
    "        flat_colors_yoy_frame = list(map(list, zip(*colors_yoy_frame)))\n",
    "\n",
    "        # Prepare fill colors for YoY\n",
    "        color_fill_yoy_frame = [['black'] * len(header_dates_yoy)] + flat_colors_yoy_frame\n",
    "\n",
    "        # Format categories for YoY\n",
    "        formatted_categories_yoy_frame = []\n",
    "        for category in window_yoy.index:\n",
    "            if category in bold_categories:\n",
    "                formatted_categories_yoy_frame.append(f\"<b>{category.strip()}</b>\")\n",
    "            elif category.startswith('  '):\n",
    "                formatted_categories_yoy_frame.append(f\"&nbsp;&nbsp;&nbsp;{category.strip()}\")\n",
    "            else:\n",
    "                formatted_categories_yoy_frame.append(category)\n",
    "\n",
    "        # Generate YoY table frame\n",
    "        frame_yoy = go.Table(\n",
    "            columnwidth=[200] + [80 for _ in range(len(header_dates_yoy))],\n",
    "            header=dict(\n",
    "                values=[\"Category\"] + header_dates_yoy,\n",
    "                fill_color='black',\n",
    "                font=dict(color='white', size=8),\n",
    "                align='center',\n",
    "                height=20\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[formatted_categories_yoy_frame] + [window_yoy[col] for col in window_yoy.columns],\n",
    "                fill=dict(color=color_fill_yoy_frame),\n",
    "                font=dict(color='white', size=8),\n",
    "                align=['left'] + ['center'] * len(header_dates_yoy),\n",
    "                height=20\n",
    "            ),\n",
    "            visible=False\n",
    "        )\n",
    "\n",
    "        # Create the frame\n",
    "        frame = go.Frame(\n",
    "            data=[frame_mom, frame_yoy],\n",
    "            name=str(i)\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Define slider steps\n",
    "    slider_steps = []\n",
    "    for i, label in enumerate(window_labels):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [str(i)],\n",
    "                dict(\n",
    "                    mode=\"immediate\",\n",
    "                    frame=dict(duration=0, redraw=True),\n",
    "                    transition=dict(duration=0)\n",
    "                )\n",
    "            ],\n",
    "            label=label  # Label represents the start date of the window\n",
    "        )\n",
    "        slider_steps.append(step)\n",
    "\n",
    "    # Add slider to the layout\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Start Date: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=slider_steps,\n",
    "        len=0.9,\n",
    "        x=0.05,\n",
    "        y=0\n",
    "    )]\n",
    "\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "    # Add buttons for MoM and YoY tabs\n",
    "    fig.update_layout(\n",
    "        updatemenus=[{\n",
    "            'buttons': [\n",
    "                {\n",
    "                    'label': 'MoM',\n",
    "                    'method': 'update',\n",
    "                    'args': [{'visible': [True, False]}, {'title': 'CPI MoM % Change'}]\n",
    "                },\n",
    "                {\n",
    "                    'label': 'YoY',\n",
    "                    'method': 'update',\n",
    "                    'args': [{'visible': [False, True]}, {'title': 'CPI YoY % Change'}]\n",
    "                }\n",
    "            ],\n",
    "            'direction': 'left',\n",
    "            'pad': {'r': 10, 't': 10},\n",
    "            'showactive': True,\n",
    "            'x': 0.2,  # Position the buttons in the top left\n",
    "            'xanchor': 'left',\n",
    "            'y': 1.1,  # Position above the table\n",
    "            'yanchor': 'top',\n",
    "            'bgcolor': 'black',  # Set background to black\n",
    "            'bordercolor': 'white',  # Set border to white\n",
    "            'font': {'color': 'white'},  # White text on buttons\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Add source links as annotations below the table\n",
    "    source_text = (\n",
    "        \"Sources: \"\n",
    "        \"<a href='https://fred.stlouisfed.org/graph/?g=1uO7f' style='color:white'>PPI</a>, \"\n",
    "        \"<a href='https://fred.stlouisfed.org/graph/?g=1uO8j' style='color:white'>Median Consumer Price Index</a>\"\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=source_text,\n",
    "        showarrow=False,\n",
    "        xref='paper', yref='paper',\n",
    "        x=0.5, y=-0.25,  # Positioned below the tables\n",
    "        xanchor='center', yanchor='top',\n",
    "        font=dict(size=8),\n",
    "        align='center'\n",
    "    )\n",
    "\n",
    "    # Update layout for a black background and proper sizing\n",
    "    fig.update_layout(\n",
    "        width=1000,  # Adjust width to fit the tables\n",
    "        height=700,  # Adjust height for better visibility\n",
    "        template='plotly_dark',  # Use Plotly's dark template\n",
    "        margin=dict(l=20, r=20, t=100, b=100),\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70833ead-10be-4264-9bb9-7301833ac574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c646f38f-ba9a-4199-9d10-23af5c584882",
   "metadata": {},
   "source": [
    "# Initialize Dash App and Deploy Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "750f72f1-a2a6-4b73-8929-6abf6c2f1cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8042/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x17cec3d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Surprise Index: 0.006807070417542748\n",
      "Rate limit exceeded. Waiting before retrying...\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17be1b7c0>\n",
      "        req = <urllib.request.Request object at 0x17c4f5dd0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17be1b7c0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17d0c8610>\n",
      "        request = <urllib.request.Request object at 0x17c4f5dd0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17c4f5dd0>, <http.client.HTTPResponse object at 0x17be1b7c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17d0c8610>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17c4f5dd0>, <http.client.HTTPResponse object at 0x17be1b7c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17d0c8610>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17d0c8610>\n",
      "        fp = <http.client.HTTPResponse object at 0x17be1b7c0>\n",
      "        req = <urllib.request.Request object at 0x17c4f5dd0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 304, in update_cpi_detailed_graph_12(selected_data='CPI')\n",
      "    299 @app.callback(\n",
      "    300     Output('cpi-detailed-graph-12', 'figure'),\n",
      "    301     [Input('data-dropdown', 'value')]\n",
      "    302 )\n",
      "    303 def update_cpi_detailed_graph_12(selected_data):\n",
      "--> 304     return generate_cpi_detailed_graph_12() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[54], line 6, in generate_cpi_detailed_graph_12()\n",
      "      3 fred = Fred(api_key=api_key)\n",
      "      5 # Retrieve the expected inflation data for 1-year, 2-year, 3-year, and 5-year\n",
      "----> 6 expinf1yr = fred.get_series('EXPINF1YR')\n",
      "        fred = <fredapi.fred.Fred object at 0x301803190>\n",
      "      7 expinf2yr = fred.get_series('EXPINF2YR')\n",
      "      8 expinf3yr = fred.get_series('EXPINF3YR')\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='EXPINF1YR',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR'\n",
      "        self = <fredapi.fred.Fred object at 0x301803190>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17c4c58f0>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Rate limit exceeded. Waiting before retrying...\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SAS&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SAS&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17be1b850>\n",
      "        req = <urllib.request.Request object at 0x17a9e3e90>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17be1b850>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17c43a850>\n",
      "        request = <urllib.request.Request object at 0x17a9e3e90>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17a9e3e90>, <http.client.HTTPResponse object at 0x17be1b850>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17c43a850>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17a9e3e90>, <http.client.HTTPResponse object at 0x17be1b850>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17c43a850>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17c43a850>\n",
      "        fp = <http.client.HTTPResponse object at 0x17be1b850>\n",
      "        req = <urllib.request.Request object at 0x17a9e3e90>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[57], line 38, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     36 try:\n",
      "     37     # Fetch data from FRED\n",
      "---> 38     series_data = fred.get_series(series_id, observation_start=observation_start).resample('M').mean()\n",
      "        fred = <fredapi.fred.Fred object at 0x17ab7e110>\n",
      "        series_id = 'CUSR0000SAS'\n",
      "        series_data = 2014-12-31    218.536\n",
      "2015-01-31    199.926\n",
      "2015-02-28    203.021\n",
      "2015-03-31    205.757\n",
      "2015-04-30    203.577\n",
      "               ...   \n",
      "2024-05-31    284.742\n",
      "2024-06-30    278.938\n",
      "2024-07-31    279.012\n",
      "2024-08-31    276.826\n",
      "2024-09-30    271.703\n",
      "Freq: M, Length: 118, dtype: float64\n",
      "        observation_start = '2014-12-01'\n",
      "     39     break\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CUSR0000SAS',\n",
      "    observation_start=Timestamp('2014-12-01 00:00:00'),\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SAS&observation_start=2014-12-01'\n",
      "        self = <fredapi.fred.Fred object at 0x17ab7e110>\n",
      "    152 if root is None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17d23d5d0>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[58], line 223, in update_cpi_detailed_summary_table_1(selected_data='CPI')\n",
      "    218 @app.callback(\n",
      "    219     Output('cpi-detailed-summary-table-1', 'figure'),\n",
      "    220     [Input('data-dropdown', 'value')]  # Input to trigger update based on selected data\n",
      "    221 )\n",
      "    222 def update_cpi_detailed_summary_table_1(selected_data):\n",
      "--> 223      return generate_cpi_detailed_summary_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[57], line 43, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     41 if \"Too Many Requests\" in str(e):\n",
      "     42     print(\"Rate limit exceeded. Waiting before retrying...\")\n",
      "---> 43     time.sleep(60)  # Wait for a minute before retrying\n",
      "     44 else:\n",
      "     45     print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
      "\n",
      "NameError: name 'time' is not defined\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x13a85bf10>\n",
      "        req = <urllib.request.Request object at 0x3004824d0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x13a85bf10>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17abb7d50>\n",
      "        request = <urllib.request.Request object at 0x3004824d0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x3004824d0>, <http.client.HTTPResponse object at 0x13a85bf10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17abb7d50>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x3004824d0>, <http.client.HTTPResponse object at 0x13a85bf10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17abb7d50>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17abb7d50>\n",
      "        fp = <http.client.HTTPResponse object at 0x13a85bf10>\n",
      "        req = <urllib.request.Request object at 0x3004824d0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 214, in update_cpi_detailed_graph_3(selected_data='CPI')\n",
      "    209 @app.callback(\n",
      "    210     Output('cpi-detailed-graph-3', 'figure'),\n",
      "    211     [Input('data-dropdown', 'value')]\n",
      "    212 )\n",
      "    213 def update_cpi_detailed_graph_3(selected_data):\n",
      "--> 214      return generate_cpi_detailed_graph_3() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[45], line 16, in generate_cpi_detailed_graph_3()\n",
      "      6 series_ids = {\n",
      "      7     'All Items': 'CPIAUCSL',         # All Items CPI\n",
      "      8     'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
      "   (...)\n",
      "     12     'Core Services': 'CUSR0000SASLE' # Core Services\n",
      "     13 }\n",
      "     15 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17c74d410>\n",
      "        series_ids = {'All Items': 'CPIAUCSL', 'Core CPI': 'CPILFESL', 'Food': 'CPIUFDNS', 'Energy': 'CPIENGSL', 'Core Goods': 'CUSR0000SACL1E', 'Core Services': 'CUSR0000SASLE'}\n",
      "     17 df = pd.DataFrame(cpi_data)\n",
      "     19 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "Cell In[45], line 16, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items': 'CPIAUCSL',         # All Items CPI\n",
      "      8     'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
      "   (...)\n",
      "     12     'Core Services': 'CUSR0000SASLE' # Core Services\n",
      "     13 }\n",
      "     15 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17c74d410>\n",
      "        name = 'Energy'\n",
      "        series_id = 'CPIENGSL'\n",
      "        name, series_id = ('Energy', 'CPIENGSL')\n",
      "     17 df = pd.DataFrame(cpi_data)\n",
      "     19 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CPIENGSL',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIENGSL'\n",
      "        self = <fredapi.fred.Fred object at 0x17c74d410>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17c4c5710>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Rate limit exceeded. Waiting before retrying...\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cd40c10>\n",
      "        req = <urllib.request.Request object at 0x17a7ba810>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cd40c10>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x300480490>\n",
      "        request = <urllib.request.Request object at 0x17a7ba810>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17a7ba810>, <http.client.HTTPResponse object at 0x17cd40c10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x300480490>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17a7ba810>, <http.client.HTTPResponse object at 0x17cd40c10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x300480490>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x300480490>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cd40c10>\n",
      "        req = <urllib.request.Request object at 0x17a7ba810>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 206, in update_cpi_detailed_graph_2(selected_data='CPI')\n",
      "    201 @app.callback(\n",
      "    202     Output('cpi-detailed-graph-2', 'figure'),\n",
      "    203     [Input('data-dropdown', 'value')]\n",
      "    204 )\n",
      "    205 def update_cpi_detailed_graph_2(selected_data):\n",
      "--> 206     return generate_cpi_detailed_graph_2() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[44], line 16, in generate_cpi_detailed_graph_2()\n",
      "      6 series_ids = {\n",
      "      7     \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
      "      8     \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
      "   (...)\n",
      "     12     \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
      "     13 }\n",
      "     15 # Fetch the data from FRED\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17cc877d0>\n",
      "        series_ids = {'All Items': 'CPIAUCSL', 'Core CPI': 'CPILFESL', 'Food': 'CPIUFDNS', 'Energy': 'CPIENGSL', 'Core Services': 'CUSR0000SASLE', 'Core Goods': 'CUSR0000SACL1E'}\n",
      "     18 # Convert the data into a DataFrame\n",
      "     19 cpi_df = pd.DataFrame(cpi_data)\n",
      "\n",
      "Cell In[44], line 16, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
      "      8     \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
      "   (...)\n",
      "     12     \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
      "     13 }\n",
      "     15 # Fetch the data from FRED\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17cc877d0>\n",
      "        name = 'Core Services'\n",
      "        series_id = 'CUSR0000SASLE'\n",
      "        name, series_id = ('Core Services', 'CUSR0000SASLE')\n",
      "     18 # Convert the data into a DataFrame\n",
      "     19 cpi_df = pd.DataFrame(cpi_data)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CUSR0000SASLE',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SASLE'\n",
      "        self = <fredapi.fred.Fred object at 0x17cc877d0>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17c7f4e00>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...WPUFD413&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=WPUFD413&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...WPUFD413&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=WPUFD413&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...WPUFD413&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cd43c10>\n",
      "        req = <urllib.request.Request object at 0x17c4e9f10>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cd43c10>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17bfd6450>\n",
      "        request = <urllib.request.Request object at 0x17c4e9f10>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17c4e9f10>, <http.client.HTTPResponse object at 0x17cd43c10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17bfd6450>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17c4e9f10>, <http.client.HTTPResponse object at 0x17cd43c10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17bfd6450>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17bfd6450>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cd43c10>\n",
      "        req = <urllib.request.Request object at 0x17c4e9f10>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 268, in update_cpi_detailed_graph_8(selected_data='CPI')\n",
      "    263 @app.callback(\n",
      "    264     Output('cpi-detailed-graph-8', 'figure'),\n",
      "    265     [Input('data-dropdown', 'value')]\n",
      "    266 )\n",
      "    267 def update_cpi_detailed_graph_8(selected_data):\n",
      "--> 268     return generate_cpi_detailed_graph_8() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[50], line 17, in generate_cpi_detailed_graph_8(\n",
      "    selected_period='MoM',\n",
      "    months_for_table=30\n",
      ")\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',            # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',               # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'          # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch the data from FRED\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17f5f0510>\n",
      "        series_ids = {'All Items PPI': 'PPIFID', 'Core PPI': 'WPUFD413', 'Foods PPI': 'PPIFDF', 'Energy PPI': 'PPIFDE', 'Goods PPI': 'PPIFDG', 'Services PPI': 'PPIFDS', 'Construction PPI': 'PPIFDC'}\n",
      "     19 # Convert the data into a DataFrame\n",
      "     20 ppi_df = pd.DataFrame(ppi_data)\n",
      "\n",
      "Cell In[50], line 17, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',            # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',               # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'          # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch the data from FRED\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17f5f0510>\n",
      "        name = 'Core PPI'\n",
      "        series_id = 'WPUFD413'\n",
      "        name, series_id = ('Core PPI', 'WPUFD413')\n",
      "     19 # Convert the data into a DataFrame\n",
      "     20 ppi_df = pd.DataFrame(ppi_data)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='WPUFD413',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=WPUFD413'\n",
      "        self = <fredapi.fred.Fred object at 0x17f5f0510>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...WPUFD413&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17d23d350>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIRECSL&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIRECSL&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x168f61a80>\n",
      "        req = <urllib.request.Request object at 0x17a807690>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x168f61a80>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x300482390>\n",
      "        request = <urllib.request.Request object at 0x17a807690>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17a807690>, <http.client.HTTPResponse object at 0x168f61a80>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x300482390>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17a807690>, <http.client.HTTPResponse object at 0x168f61a80>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x300482390>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x300482390>\n",
      "        fp = <http.client.HTTPResponse object at 0x168f61a80>\n",
      "        req = <urllib.request.Request object at 0x17a807690>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[57], line 38, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     36 try:\n",
      "     37     # Fetch data from FRED\n",
      "---> 38     series_data = fred.get_series(series_id, observation_start=observation_start).resample('M').mean()\n",
      "        fred = <fredapi.fred.Fred object at 0x301930350>\n",
      "        series_id = 'CPIRECSL'\n",
      "        series_data = 2014-12-31    441.464\n",
      "2015-01-31    441.351\n",
      "2015-02-28    441.101\n",
      "2015-03-31    442.943\n",
      "2015-04-30    445.822\n",
      "               ...   \n",
      "2024-05-31    564.732\n",
      "2024-06-30    565.711\n",
      "2024-07-31    564.310\n",
      "2024-08-31    563.654\n",
      "2024-09-30    565.984\n",
      "Freq: M, Length: 118, dtype: float64\n",
      "        observation_start = '2014-12-01'\n",
      "     39     break\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CPIRECSL',\n",
      "    observation_start=Timestamp('2014-12-01 00:00:00'),\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIRECSL&observation_start=2014-12-01'\n",
      "        self = <fredapi.fred.Fred object at 0x301930350>\n",
      "    152 if root is None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17aa585e0>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[58], line 223, in update_cpi_detailed_summary_table_1(selected_data='CPI')\n",
      "    218 @app.callback(\n",
      "    219     Output('cpi-detailed-summary-table-1', 'figure'),\n",
      "    220     [Input('data-dropdown', 'value')]  # Input to trigger update based on selected data\n",
      "    221 )\n",
      "    222 def update_cpi_detailed_summary_table_1(selected_data):\n",
      "--> 223      return generate_cpi_detailed_summary_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[57], line 43, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     41 if \"Too Many Requests\" in str(e):\n",
      "     42     print(\"Rate limit exceeded. Waiting before retrying...\")\n",
      "---> 43     time.sleep(60)  # Wait for a minute before retrying\n",
      "     44 else:\n",
      "     45     print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
      "\n",
      "NameError: name 'time' is not defined\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFDE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFDE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFDE&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFDE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...d=PPIFDE&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x16c7b5b70>\n",
      "        req = <urllib.request.Request object at 0x30bbc31d0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x16c7b5b70>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17d211310>\n",
      "        request = <urllib.request.Request object at 0x30bbc31d0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x30bbc31d0>, <http.client.HTTPResponse object at 0x16c7b5b70>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17d211310>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x30bbc31d0>, <http.client.HTTPResponse object at 0x16c7b5b70>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17d211310>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17d211310>\n",
      "        fp = <http.client.HTTPResponse object at 0x16c7b5b70>\n",
      "        req = <urllib.request.Request object at 0x30bbc31d0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 277, in update_cpi_detailed_graph_9(selected_data='CPI')\n",
      "    272 @app.callback(\n",
      "    273     Output('cpi-detailed-graph-9', 'figure'),\n",
      "    274     [Input('data-dropdown', 'value')]\n",
      "    275 )\n",
      "    276 def update_cpi_detailed_graph_9(selected_data):\n",
      "--> 277     return generate_cpi_detailed_graph_9() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[51], line 17, in generate_cpi_detailed_graph_9(contribution_type='MoM')\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',        # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'      # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17d280390>\n",
      "        series_ids = {'All Items PPI': 'PPIFID', 'Core PPI': 'WPUFD413', 'Foods PPI': 'PPIFDF', 'Energy PPI': 'PPIFDE', 'Goods PPI': 'PPIFDG', 'Services PPI': 'PPIFDS', 'Construction PPI': 'PPIFDC'}\n",
      "     18 df = pd.DataFrame(ppi_data)\n",
      "     20 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "Cell In[51], line 17, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',        # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'      # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17d280390>\n",
      "        name = 'Energy PPI'\n",
      "        series_id = 'PPIFDE'\n",
      "        name, series_id = ('Energy PPI', 'PPIFDE')\n",
      "     18 df = pd.DataFrame(ppi_data)\n",
      "     20 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PPIFDE',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFDE'\n",
      "        self = <fredapi.fred.Fred object at 0x17d280390>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFDE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17ff10090>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFES&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFES&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFES&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFES&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...d=PPIFES&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cd42770>\n",
      "        req = <urllib.request.Request object at 0x17c5a8ed0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cd42770>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f5ad890>\n",
      "        request = <urllib.request.Request object at 0x17c5a8ed0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17c5a8ed0>, <http.client.HTTPResponse object at 0x17cd42770>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f5ad890>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17c5a8ed0>, <http.client.HTTPResponse object at 0x17cd42770>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f5ad890>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f5ad890>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cd42770>\n",
      "        req = <urllib.request.Request object at 0x17c5a8ed0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 259, in update_cpi_detailed_graph_7(selected_data='CPI')\n",
      "    254 @app.callback(\n",
      "    255     Output('cpi-detailed-graph-7', 'figure'),\n",
      "    256     [Input('data-dropdown', 'value')]\n",
      "    257 )\n",
      "    258 def update_cpi_detailed_graph_7(selected_data):\n",
      "--> 259     return generate_cpi_detailed_graph_7() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[49], line 7, in generate_cpi_detailed_graph_7()\n",
      "      5 # Retrieve PPI data\n",
      "      6 ppiaco_data = fred.get_series('PPIACO')  # Producer Price Index for All Commodities\n",
      "----> 7 ppifes_data = fred.get_series('PPIFES')  # Producer Price Index for Finished Goods\n",
      "        fred = <fredapi.fred.Fred object at 0x17cea1d90>\n",
      "      9 # Resample data monthly and compute the six-month annualized growth rate\n",
      "     10 def annualized_growth_rate(series, window=6):\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PPIFES',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFES'\n",
      "        self = <fredapi.fred.Fred object at 0x17cea1d90>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFES&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x13f111ad0>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Error fetching data: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SAS&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SAS&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x16c7b48b0>\n",
      "        req = <urllib.request.Request object at 0x17f9bb910>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x16c7b48b0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f54a3d0>\n",
      "        request = <urllib.request.Request object at 0x17f9bb910>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17f9bb910>, <http.client.HTTPResponse object at 0x16c7b48b0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f54a3d0>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17f9bb910>, <http.client.HTTPResponse object at 0x16c7b48b0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f54a3d0>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f54a3d0>\n",
      "        fp = <http.client.HTTPResponse object at 0x16c7b48b0>\n",
      "        req = <urllib.request.Request object at 0x17f9bb910>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[57], line 38, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     36 try:\n",
      "     37     # Fetch data from FRED\n",
      "---> 38     series_data = fred.get_series(series_id, observation_start=observation_start).resample('M').mean()\n",
      "        fred = <fredapi.fred.Fred object at 0x17cbdf850>\n",
      "        series_id = 'CUSR0000SAS'\n",
      "        series_data = 2014-12-31    218.536\n",
      "2015-01-31    199.926\n",
      "2015-02-28    203.021\n",
      "2015-03-31    205.757\n",
      "2015-04-30    203.577\n",
      "               ...   \n",
      "2024-05-31    284.742\n",
      "2024-06-30    278.938\n",
      "2024-07-31    279.012\n",
      "2024-08-31    276.826\n",
      "2024-09-30    271.703\n",
      "Freq: M, Length: 118, dtype: float64\n",
      "        observation_start = '2014-12-01'\n",
      "     39     break\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CUSR0000SAS',\n",
      "    observation_start=Timestamp('2014-12-01 00:00:00'),\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SAS&observation_start=2014-12-01'\n",
      "        self = <fredapi.fred.Fred object at 0x17cbdf850>\n",
      "    152 if root is None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x13f113920>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[58], line 223, in update_cpi_detailed_summary_table_1(selected_data='CPI')\n",
      "    218 @app.callback(\n",
      "    219     Output('cpi-detailed-summary-table-1', 'figure'),\n",
      "    220     [Input('data-dropdown', 'value')]  # Input to trigger update based on selected data\n",
      "    221 )\n",
      "    222 def update_cpi_detailed_summary_table_1(selected_data):\n",
      "--> 223      return generate_cpi_detailed_summary_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[57], line 43, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     41 if \"Too Many Requests\" in str(e):\n",
      "     42     print(\"Rate limit exceeded. Waiting before retrying...\")\n",
      "---> 43     time.sleep(60)  # Wait for a minute before retrying\n",
      "     44 else:\n",
      "     45     print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
      "\n",
      "NameError: name 'time' is not defined\n",
      "\n",
      "Error fetching series PCE with ID PCEPI: Too Many Requests.  Exceeded Rate Limit\n",
      "Economic Surprise Index: 0.006807070417542748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching series Cleveland Median CPI with ID MEDCPIM158SFRBCLE: Too Many Requests.  Exceeded Rate Limit---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cc05e40>\n",
      "        req = <urllib.request.Request object at 0x17f4ac0d0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cc05e40>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17bf83690>\n",
      "        request = <urllib.request.Request object at 0x17f4ac0d0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17f4ac0d0>, <http.client.HTTPResponse object at 0x17cc05e40>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17bf83690>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17f4ac0d0>, <http.client.HTTPResponse object at 0x17cc05e40>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17bf83690>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17bf83690>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cc05e40>\n",
      "        req = <urllib.request.Request object at 0x17f4ac0d0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 277, in update_cpi_detailed_graph_9(selected_data='CPI')\n",
      "    272 @app.callback(\n",
      "    273     Output('cpi-detailed-graph-9', 'figure'),\n",
      "    274     [Input('data-dropdown', 'value')]\n",
      "    275 )\n",
      "    276 def update_cpi_detailed_graph_9(selected_data):\n",
      "--> 277     return generate_cpi_detailed_graph_9() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[51], line 17, in generate_cpi_detailed_graph_9(contribution_type='MoM')\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',        # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'      # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x16c8bf810>\n",
      "        series_ids = {'All Items PPI': 'PPIFID', 'Core PPI': 'WPUFD413', 'Foods PPI': 'PPIFDF', 'Energy PPI': 'PPIFDE', 'Goods PPI': 'PPIFDG', 'Services PPI': 'PPIFDS', 'Construction PPI': 'PPIFDC'}\n",
      "     18 df = pd.DataFrame(ppi_data)\n",
      "     20 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "Cell In[51], line 17, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',        # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'      # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x16c8bf810>\n",
      "        name = 'All Items PPI'\n",
      "        series_id = 'PPIFID'\n",
      "        name, series_id = ('All Items PPI', 'PPIFID')\n",
      "     18 df = pd.DataFrame(ppi_data)\n",
      "     20 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PPIFID',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID'\n",
      "        self = <fredapi.fred.Fred object at 0x16c8bf810>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17aa4db20>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cc05ab0>\n",
      "        req = <urllib.request.Request object at 0x17c3c2a50>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cc05ab0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f92e750>\n",
      "        request = <urllib.request.Request object at 0x17c3c2a50>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17c3c2a50>, <http.client.HTTPResponse object at 0x17cc05ab0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f92e750>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17c3c2a50>, <http.client.HTTPResponse object at 0x17cc05ab0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f92e750>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f92e750>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cc05ab0>\n",
      "        req = <urllib.request.Request object at 0x17c3c2a50>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 304, in update_cpi_detailed_graph_12(selected_data='CPI')\n",
      "    299 @app.callback(\n",
      "    300     Output('cpi-detailed-graph-12', 'figure'),\n",
      "    301     [Input('data-dropdown', 'value')]\n",
      "    302 )\n",
      "    303 def update_cpi_detailed_graph_12(selected_data):\n",
      "--> 304     return generate_cpi_detailed_graph_12() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[54], line 6, in generate_cpi_detailed_graph_12()\n",
      "      3 fred = Fred(api_key=api_key)\n",
      "      5 # Retrieve the expected inflation data for 1-year, 2-year, 3-year, and 5-year\n",
      "----> 6 expinf1yr = fred.get_series('EXPINF1YR')\n",
      "        fred = <fredapi.fred.Fred object at 0x17c3c0c90>\n",
      "      7 expinf2yr = fred.get_series('EXPINF2YR')\n",
      "      8 expinf3yr = fred.get_series('EXPINF3YR')\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='EXPINF1YR',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR'\n",
      "        self = <fredapi.fred.Fred object at 0x17c3c0c90>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17fc8f9c0>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=GDPDEF&observation_start=2000-01-01&observation_end=2026-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=GDPDEF&observation_start=2000-01-01&observation_end=2026-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cd43c10>\n",
      "        req = <urllib.request.Request object at 0x17cb355d0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cd43c10>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x16a0ca1d0>\n",
      "        request = <urllib.request.Request object at 0x17cb355d0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17cb355d0>, <http.client.HTTPResponse object at 0x17cd43c10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x16a0ca1d0>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17cb355d0>, <http.client.HTTPResponse object at 0x17cd43c10>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x16a0ca1d0>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x16a0ca1d0>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cd43c10>\n",
      "        req = <urllib.request.Request object at 0x17cb355d0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[58], line 295, in update_cpi_detailed_graph_11(selected_data='CPI')\n",
      "    290 @app.callback(\n",
      "    291     Output('cpi-detailed-graph-11', 'figure'),\n",
      "    292     [Input('data-dropdown', 'value')]\n",
      "    293 )\n",
      "    294 def update_cpi_detailed_graph_11(selected_data):\n",
      "--> 295     return generate_cpi_detailed_graph_11() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[53], line 3, in generate_cpi_detailed_graph_11()\n",
      "      1 def generate_cpi_detailed_graph_11():\n",
      "      2     # Retrieve GDP deflator and CPI data from FRED\n",
      "----> 3     gdp_deflator = fred.get_series('GDPDEF', observation_start='2000-01-01', observation_end='2026-01-01')\n",
      "        fred = <fredapi.fred.Fred object at 0x17ca11150>\n",
      "      4     cpi_qoq = fred.get_series('CPIAUCSL', observation_start='2000-01-01', observation_end='2026-01-01')\n",
      "      6     # Align both datasets to avoid mismatches in dates\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='GDPDEF',\n",
      "    observation_start=Timestamp('2000-01-01 00:00:00'),\n",
      "    observation_end=Timestamp('2026-01-01 00:00:00'),\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=GDPDEF&observation_start=2000-01-01&observation_end=2026-01-01'\n",
      "        self = <fredapi.fred.Fred object at 0x17ca11150>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x16c77dc60>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Error fetching series 16% Trimmed Mean CPI with ID TRMMEANCPIM158SFRBCLE: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series PPI with ID PPIACO: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Sticky CPI with ID STICKCPIM157SFRBATL: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series PCE with ID PCEPI: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Trimmed Mean PCE with ID PCETRIM1M158SFRBDAL: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Cleveland Median CPI with ID MEDCPIM158SFRBCLE: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series 16% Trimmed Mean CPI with ID TRMMEANCPIM158SFRBCLE: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Sticky CPI with ID STICKCPIM157SFRBATL: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Trimmed Mean PCE with ID PCETRIM1M158SFRBDAL: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "IndexError                                Traceback (most recent call last)\n",
      "Cell In[58], line 179, in update_cpi_detailed_table_1(selected_data='CPI')\n",
      "    174 @app.callback(\n",
      "    175     Output('cpi-detailed-table-1', 'figure'),\n",
      "    176     [Input('data-dropdown', 'value')]\n",
      "    177 )\n",
      "    178 def update_cpi_detailed_table_1(selected_data):\n",
      "--> 179     return generate_cpi_detailed_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[55], line 93, in generate_cpi_detailed_table_1()\n",
      "     90         return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
      "     92 # Create the initial table data (first window)\n",
      "---> 93 initial_window = windows[0]\n",
      "        windows = []\n",
      "     94 table_df = initial_window.transpose().round(2)\n",
      "     95 table_header_dates = table_df.columns.tolist()  # Corrected: Use columns (dates) for headers\n",
      "\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dash import Dash, dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Add custom CSS to set the entire page background to black and adjust container width to 1000px\n",
    "app.index_string = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        {%metas%}\n",
    "        <title>{%title%}</title>\n",
    "        {%favicon%}\n",
    "        {%css%}\n",
    "        <style>\n",
    "            body { \n",
    "                background-color: black !important;\n",
    "                color: white;\n",
    "                margin: 0;\n",
    "                padding: 0;\n",
    "                display: flex;\n",
    "                justify-content: center;\n",
    "                align-items: flex-start;\n",
    "                min-height: 100vh;\n",
    "            }\n",
    "            .container {\n",
    "                width: 100%;\n",
    "                max-width: 1000px; /* Set the max width to 1000px */\n",
    "                padding: 0;\n",
    "                box-sizing: border-box;\n",
    "                display: flex;\n",
    "                justify-content: center;\n",
    "                align-items: center;\n",
    "                flex-direction: column;\n",
    "            }\n",
    "            .graph-container {\n",
    "                display: block;\n",
    "                width: 100%;\n",
    "                text-align: center;\n",
    "                padding: 0;\n",
    "                box-sizing: border-box;\n",
    "                margin: 0 auto;\n",
    "            }\n",
    "            .graph-container > div {\n",
    "                display: inline-block;\n",
    "                width: 100%;\n",
    "                padding: 0;\n",
    "                box-sizing: border-box;\n",
    "                margin: 0 auto;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            {%app_entry%}\n",
    "        </div>\n",
    "        <footer>\n",
    "            {%config%}\n",
    "            {%scripts%}\n",
    "            {%renderer%}\n",
    "        </footer>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Define a default period (e.g., 'YoY')\n",
    "DEFAULT_PERIOD = 'YoY'\n",
    "\n",
    "# App layout with adjusted container width and graph size\n",
    "app.layout = html.Div(className='container', children=[\n",
    "    html.H1(\"Economic Data Dashboard\", style={'textAlign': 'center'}),\n",
    "\n",
    "    # General data dropdown (CPI)\n",
    "    dcc.Dropdown(\n",
    "        id='data-dropdown',\n",
    "        options=[\n",
    "            {'label': 'CPI', 'value': 'CPI'},\n",
    "        ],\n",
    "        value='CPI',\n",
    "        style={\n",
    "            'backgroundColor': '#000000',\n",
    "            'color': 'white',  # Changed to white for better visibility on black background\n",
    "            'width': '25%',\n",
    "            'margin': '0 auto',\n",
    "            'textAlign': 'center'\n",
    "        }\n",
    "    ),\n",
    "    \n",
    "    html.Div(id='cpi-graphs', children=[\n",
    "        html.H2(\"Headline and Core CPI Growth Rate (YoY and 6mo Ann Graph 1)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-1', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "        \n",
    "        html.H2(\"CPI Components (Graph 2)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-2', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "        \n",
    "        html.H2(\"CPI Components (Graph 3)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-3', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        # Add summary table after Graph 3\n",
    "        html.H2(\"CPI Growth Rate Table (MoM % Non-Weighted Table 1)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-summary-table-1', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"CPI Trend 6mo Annualized (Graph 4)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-4', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"Headline and Core PCE Growth Rate (YoY and 6mo Ann Graph 5)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-5', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"PCE Annualized Ex:Food and Energy (Graph 6)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-6', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"PPI Detailed Graph (Graph 7)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-7', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"PPI Components (Graph 8)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-8', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "        \n",
    "        html.H2(\"PPI (Graph 9)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-9', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "        \n",
    "        html.H2(\"Other Inflation Related Indicators (Table 1)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-table-1', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]), \n",
    "\n",
    "        html.H2(\"CPI vs Surprise (Table 2)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-table-2', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"CPI Components vs Wage Growth (Graph 10)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-10', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"GDP Deflator (Graph 11)\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-11', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "\n",
    "        html.H2(\"CPI Inflation Expectation\", style={'textAlign': 'center'}),\n",
    "        html.Div(className='graph-container', children=[\n",
    "            dcc.Graph(id='cpi-detailed-graph-12', style={'width': '100%', 'max-width': '1000px'})\n",
    "        ]),\n",
    "    \n",
    "    ], style={'display': 'block'})\n",
    "])\n",
    "\n",
    "# Callbacks to manage visibility based on dropdown selection\n",
    "\n",
    "# Callback for CPI Detailed Table 1\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-table-1', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_table_1(selected_data):\n",
    "    return generate_cpi_detailed_table_1() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Table 2\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-table-2', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_table_2(selected_data):\n",
    "    return generate_cpi_detailed_table_2() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 1\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-1', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_1(selected_data):\n",
    "    return generate_cpi_detailed_graph_1() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 2 (Removed period-dropdown)\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-2', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_2(selected_data):\n",
    "    return generate_cpi_detailed_graph_2() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "# Callback for CPI Detailed Graph 3 (Removed period-dropdown-graph-3)\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-3', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_3(selected_data):\n",
    "     return generate_cpi_detailed_graph_3() if selected_data == 'CPI' else go.Figure()\n",
    "      \n",
    "\n",
    "# Callback for CPI Detailed Summary Table 1\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-summary-table-1', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]  # Input to trigger update based on selected data\n",
    ")\n",
    "def update_cpi_detailed_summary_table_1(selected_data):\n",
    "     return generate_cpi_detailed_summary_table_1() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 4\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-4', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_4(selected_data):\n",
    "    return generate_cpi_detailed_graph_4() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 5\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-5', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_5(selected_data):\n",
    "    return generate_cpi_detailed_graph_5() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 6\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-6', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_6(selected_data):\n",
    "    return generate_cpi_detailed_graph_6() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 7\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-7', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_7(selected_data):\n",
    "    return generate_cpi_detailed_graph_7() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 8\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-8', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_8(selected_data):\n",
    "    return generate_cpi_detailed_graph_8() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 9\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-9', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_9(selected_data):\n",
    "    return generate_cpi_detailed_graph_9() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 10\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-10', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_10(selected_data):\n",
    "    return generate_cpi_detailed_graph_10() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 11\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-11', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_11(selected_data):\n",
    "    return generate_cpi_detailed_graph_11() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "\n",
    "# Callback for CPI Detailed Graph 12\n",
    "@app.callback(\n",
    "    Output('cpi-detailed-graph-12', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "def update_cpi_detailed_graph_12(selected_data):\n",
    "    return generate_cpi_detailed_graph_12() if selected_data == 'CPI' else go.Figure()\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8042)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af0431-f955-471f-88d2-3ccf45a1de7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "500f6030-3164-4a16-9d8e-323fdb07a160",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ERR#0012: incorrect to_date format, it should be 'dd/mm/yyyy'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/investpy/news.py:173\u001b[0m, in \u001b[0;36meconomic_calendar\u001b[0;34m(\n    time_zone,\n    time_filter,\n    countries,\n    importances,\n    categories,\n    from_date,\n    to_date\n)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     datetime\u001b[38;5;241m.\u001b[39mstrptime(to_date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m _strptime(data_string, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[0;31mValueError\u001b[0m: time data 'today' does not match format '%d/%m/%Y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m event_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforecast\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Fetch data for NFP, ADP, and Unemployment Rate\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m nfp_data \u001b[38;5;241m=\u001b[39m fetch_event_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNonfarm Payrolls\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m adp_data \u001b[38;5;241m=\u001b[39m fetch_event_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADP Nonfarm Employment Change\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m unemployment_data \u001b[38;5;241m=\u001b[39m fetch_event_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnemployment Rate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m, in \u001b[0;36mfetch_event_data\u001b[0;34m(event_name, from_date, to_date)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_event_data\u001b[39m(event_name, from_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01/01/2020\u001b[39m\u001b[38;5;124m'\u001b[39m, to_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoday\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Fetch the global economic calendar data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     data \u001b[38;5;241m=\u001b[39m investpy\u001b[38;5;241m.\u001b[39meconomic_calendar(from_date\u001b[38;5;241m=\u001b[39mfrom_date, to_date\u001b[38;5;241m=\u001b[39mto_date)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Filter for the specific event and the United States\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     event_data \u001b[38;5;241m=\u001b[39m data[(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(event_name, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/investpy/news.py:175\u001b[0m, in \u001b[0;36meconomic_calendar\u001b[0;34m(\n    time_zone,\n    time_filter,\n    countries,\n    importances,\n    categories,\n    from_date,\n    to_date\n)\u001b[0m\n\u001b[1;32m    173\u001b[0m     datetime\u001b[38;5;241m.\u001b[39mstrptime(to_date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERR#0012: incorrect to_date format, it should be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd/mm/yyyy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m     )\n\u001b[1;32m    179\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(to_date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_date \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_date:\n",
      "\u001b[0;31mValueError\u001b[0m: ERR#0012: incorrect to_date format, it should be 'dd/mm/yyyy'."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Surprise Index: 0.006807070417542748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Surprise Index: 0.006807070417542748\n",
      "Rate limit exceeded. Waiting before retrying...\n",
      "Rate limit exceeded. Waiting before retrying...\n",
      "Error fetching data: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF5YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF5YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF5YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF5YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...XPINF5YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x30010d330>\n",
      "        req = <urllib.request.Request object at 0x16a74f5d0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x30010d330>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x3019d3190>\n",
      "        request = <urllib.request.Request object at 0x16a74f5d0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x16a74f5d0>, <http.client.HTTPResponse object at 0x30010d330>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x3019d3190>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x16a74f5d0>, <http.client.HTTPResponse object at 0x30010d330>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x3019d3190>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x3019d3190>\n",
      "        fp = <http.client.HTTPResponse object at 0x30010d330>\n",
      "        req = <urllib.request.Request object at 0x16a74f5d0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 304, in update_cpi_detailed_graph_12(selected_data='CPI')\n",
      "    299 @app.callback(\n",
      "    300     Output('cpi-detailed-graph-12', 'figure'),\n",
      "    301     [Input('data-dropdown', 'value')]\n",
      "    302 )\n",
      "    303 def update_cpi_detailed_graph_12(selected_data):\n",
      "--> 304     return generate_cpi_detailed_graph_12() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[31], line 9, in generate_cpi_detailed_graph_12()\n",
      "      7 expinf2yr = fred.get_series('EXPINF2YR')\n",
      "      8 expinf3yr = fred.get_series('EXPINF3YR')\n",
      "----> 9 expinf5yr = fred.get_series('EXPINF5YR')\n",
      "        fred = <fredapi.fred.Fred object at 0x300104d10>\n",
      "     11 # Filter data from 2015 onwards\n",
      "     12 start_date = '2015-01-01'\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='EXPINF5YR',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF5YR'\n",
      "        self = <fredapi.fred.Fred object at 0x300104d10>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF5YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x16c793c40>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIUFDNS&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIUFDNS&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIUFDNS&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIUFDNS&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...CPIUFDNS&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x30193e6e0>\n",
      "        req = <urllib.request.Request object at 0x17a79bf10>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x30193e6e0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f6a7490>\n",
      "        request = <urllib.request.Request object at 0x17a79bf10>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17a79bf10>, <http.client.HTTPResponse object at 0x30193e6e0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f6a7490>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17a79bf10>, <http.client.HTTPResponse object at 0x30193e6e0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17f6a7490>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17f6a7490>\n",
      "        fp = <http.client.HTTPResponse object at 0x30193e6e0>\n",
      "        req = <urllib.request.Request object at 0x17a79bf10>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 206, in update_cpi_detailed_graph_2(selected_data='CPI')\n",
      "    201 @app.callback(\n",
      "    202     Output('cpi-detailed-graph-2', 'figure'),\n",
      "    203     [Input('data-dropdown', 'value')]\n",
      "    204 )\n",
      "    205 def update_cpi_detailed_graph_2(selected_data):\n",
      "--> 206     return generate_cpi_detailed_graph_2() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[21], line 16, in generate_cpi_detailed_graph_2()\n",
      "      6 series_ids = {\n",
      "      7     \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
      "      8     \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
      "   (...)\n",
      "     12     \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
      "     13 }\n",
      "     15 # Fetch the data from FRED\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x16e90dfd0>\n",
      "        series_ids = {'All Items': 'CPIAUCSL', 'Core CPI': 'CPILFESL', 'Food': 'CPIUFDNS', 'Energy': 'CPIENGSL', 'Core Services': 'CUSR0000SASLE', 'Core Goods': 'CUSR0000SACL1E'}\n",
      "     18 # Convert the data into a DataFrame\n",
      "     19 cpi_df = pd.DataFrame(cpi_data)\n",
      "\n",
      "Cell In[21], line 16, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
      "      8     \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
      "   (...)\n",
      "     12     \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
      "     13 }\n",
      "     15 # Fetch the data from FRED\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x16e90dfd0>\n",
      "        name = 'Food'\n",
      "        series_id = 'CPIUFDNS'\n",
      "        name, series_id = ('Food', 'CPIUFDNS')\n",
      "     18 # Convert the data into a DataFrame\n",
      "     19 cpi_df = pd.DataFrame(cpi_data)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CPIUFDNS',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIUFDNS'\n",
      "        self = <fredapi.fred.Fred object at 0x16e90dfd0>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIUFDNS&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x16c7c4c20>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPILFESL&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPILFESL&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x30010c400>\n",
      "        req = <urllib.request.Request object at 0x16e9d9390>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x30010c400>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17aa70950>\n",
      "        request = <urllib.request.Request object at 0x16e9d9390>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x16e9d9390>, <http.client.HTTPResponse object at 0x30010c400>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17aa70950>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x16e9d9390>, <http.client.HTTPResponse object at 0x30010c400>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17aa70950>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17aa70950>\n",
      "        fp = <http.client.HTTPResponse object at 0x30010c400>\n",
      "        req = <urllib.request.Request object at 0x16e9d9390>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[34], line 38, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     36 try:\n",
      "     37     # Fetch data from FRED\n",
      "---> 38     series_data = fred.get_series(series_id, observation_start=observation_start).resample('M').mean()\n",
      "        fred = <fredapi.fred.Fred object at 0x17fb8a810>\n",
      "        series_id = 'CPILFESL'\n",
      "        series_data = 2014-12-31    410.443\n",
      "2015-01-31    412.314\n",
      "2015-02-28    411.875\n",
      "2015-03-31    412.540\n",
      "2015-04-30    412.550\n",
      "               ...   \n",
      "2024-05-31    556.024\n",
      "2024-06-30    559.174\n",
      "2024-07-31    560.551\n",
      "2024-08-31    561.416\n",
      "2024-09-30    562.793\n",
      "Freq: M, Length: 118, dtype: float64\n",
      "        observation_start = '2014-12-01'\n",
      "     39     break\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CPILFESL',\n",
      "    observation_start=Timestamp('2014-12-01 00:00:00'),\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPILFESL&observation_start=2014-12-01'\n",
      "        self = <fredapi.fred.Fred object at 0x17fb8a810>\n",
      "    152 if root is None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x16c748270>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[35], line 223, in update_cpi_detailed_summary_table_1(selected_data='CPI')\n",
      "    218 @app.callback(\n",
      "    219     Output('cpi-detailed-summary-table-1', 'figure'),\n",
      "    220     [Input('data-dropdown', 'value')]  # Input to trigger update based on selected data\n",
      "    221 )\n",
      "    222 def update_cpi_detailed_summary_table_1(selected_data):\n",
      "--> 223      return generate_cpi_detailed_summary_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[34], line 43, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     41 if \"Too Many Requests\" in str(e):\n",
      "     42     print(\"Rate limit exceeded. Waiting before retrying...\")\n",
      "---> 43     time.sleep(60)  # Wait for a minute before retrying\n",
      "     44 else:\n",
      "     45     print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
      "\n",
      "NameError: name 'time' is not defined\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIRECSL&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIRECSL&observation_start=2014-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x16c467e20>\n",
      "        req = <urllib.request.Request object at 0x17fba5190>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x16c467e20>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17aac4cd0>\n",
      "        request = <urllib.request.Request object at 0x17fba5190>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17fba5190>, <http.client.HTTPResponse object at 0x16c467e20>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17aac4cd0>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17fba5190>, <http.client.HTTPResponse object at 0x16c467e20>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17aac4cd0>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17aac4cd0>\n",
      "        fp = <http.client.HTTPResponse object at 0x16c467e20>\n",
      "        req = <urllib.request.Request object at 0x17fba5190>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[34], line 38, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     36 try:\n",
      "     37     # Fetch data from FRED\n",
      "---> 38     series_data = fred.get_series(series_id, observation_start=observation_start).resample('M').mean()\n",
      "        fred = <fredapi.fred.Fred object at 0x3002ec550>\n",
      "        series_id = 'CPIRECSL'\n",
      "        series_data = 2014-12-31    441.464\n",
      "2015-01-31    441.351\n",
      "2015-02-28    441.101\n",
      "2015-03-31    442.943\n",
      "2015-04-30    445.822\n",
      "               ...   \n",
      "2024-05-31    564.732\n",
      "2024-06-30    565.711\n",
      "2024-07-31    564.310\n",
      "2024-08-31    563.654\n",
      "2024-09-30    565.984\n",
      "Freq: M, Length: 118, dtype: float64\n",
      "        observation_start = '2014-12-01'\n",
      "     39     break\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CPIRECSL',\n",
      "    observation_start=Timestamp('2014-12-01 00:00:00'),\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIRECSL&observation_start=2014-12-01'\n",
      "        self = <fredapi.fred.Fred object at 0x3002ec550>\n",
      "    152 if root is None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...14-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17f996b10>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[35], line 223, in update_cpi_detailed_summary_table_1(selected_data='CPI')\n",
      "    218 @app.callback(\n",
      "    219     Output('cpi-detailed-summary-table-1', 'figure'),\n",
      "    220     [Input('data-dropdown', 'value')]  # Input to trigger update based on selected data\n",
      "    221 )\n",
      "    222 def update_cpi_detailed_summary_table_1(selected_data):\n",
      "--> 223      return generate_cpi_detailed_summary_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[34], line 43, in generate_cpi_detailed_summary_table_1(observation_start='2014-12-01')\n",
      "     41 if \"Too Many Requests\" in str(e):\n",
      "     42     print(\"Rate limit exceeded. Waiting before retrying...\")\n",
      "---> 43     time.sleep(60)  # Wait for a minute before retrying\n",
      "     44 else:\n",
      "     45     print(f\"Error fetching series {name} with ID {series_id}: {e}\")\n",
      "\n",
      "NameError: name 'time' is not defined\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...00SACL1E&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SACL1E&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...00SACL1E&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SACL1E&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...00SACL1E&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17ccc5bd0>\n",
      "        req = <urllib.request.Request object at 0x17a77bed0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17ccc5bd0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17ce67410>\n",
      "        request = <urllib.request.Request object at 0x17a77bed0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17a77bed0>, <http.client.HTTPResponse object at 0x17ccc5bd0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17ce67410>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17a77bed0>, <http.client.HTTPResponse object at 0x17ccc5bd0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17ce67410>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17ce67410>\n",
      "        fp = <http.client.HTTPResponse object at 0x17ccc5bd0>\n",
      "        req = <urllib.request.Request object at 0x17a77bed0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 214, in update_cpi_detailed_graph_3(selected_data='CPI')\n",
      "    209 @app.callback(\n",
      "    210     Output('cpi-detailed-graph-3', 'figure'),\n",
      "    211     [Input('data-dropdown', 'value')]\n",
      "    212 )\n",
      "    213 def update_cpi_detailed_graph_3(selected_data):\n",
      "--> 214      return generate_cpi_detailed_graph_3() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[22], line 16, in generate_cpi_detailed_graph_3()\n",
      "      6 series_ids = {\n",
      "      7     'All Items': 'CPIAUCSL',         # All Items CPI\n",
      "      8     'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
      "   (...)\n",
      "     12     'Core Services': 'CUSR0000SASLE' # Core Services\n",
      "     13 }\n",
      "     15 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17fb956d0>\n",
      "        series_ids = {'All Items': 'CPIAUCSL', 'Core CPI': 'CPILFESL', 'Food': 'CPIUFDNS', 'Energy': 'CPIENGSL', 'Core Goods': 'CUSR0000SACL1E', 'Core Services': 'CUSR0000SASLE'}\n",
      "     17 df = pd.DataFrame(cpi_data)\n",
      "     19 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "Cell In[22], line 16, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items': 'CPIAUCSL',         # All Items CPI\n",
      "      8     'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
      "   (...)\n",
      "     12     'Core Services': 'CUSR0000SASLE' # Core Services\n",
      "     13 }\n",
      "     15 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17fb956d0>\n",
      "        name = 'Core Goods'\n",
      "        series_id = 'CUSR0000SACL1E'\n",
      "        name, series_id = ('Core Goods', 'CUSR0000SACL1E')\n",
      "     17 df = pd.DataFrame(cpi_data)\n",
      "     19 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CUSR0000SACL1E',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SACL1E'\n",
      "        self = <fredapi.fred.Fred object at 0x17fb956d0>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...00SACL1E&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17d0a8220>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x16c6d3f40>\n",
      "        req = <urllib.request.Request object at 0x17d066b90>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x16c6d3f40>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x16c71b190>\n",
      "        request = <urllib.request.Request object at 0x17d066b90>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17d066b90>, <http.client.HTTPResponse object at 0x16c6d3f40>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x16c71b190>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17d066b90>, <http.client.HTTPResponse object at 0x16c6d3f40>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x16c71b190>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x16c71b190>\n",
      "        fp = <http.client.HTTPResponse object at 0x16c6d3f40>\n",
      "        req = <urllib.request.Request object at 0x17d066b90>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 206, in update_cpi_detailed_graph_2(selected_data='CPI')\n",
      "    201 @app.callback(\n",
      "    202     Output('cpi-detailed-graph-2', 'figure'),\n",
      "    203     [Input('data-dropdown', 'value')]\n",
      "    204 )\n",
      "    205 def update_cpi_detailed_graph_2(selected_data):\n",
      "--> 206     return generate_cpi_detailed_graph_2() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[21], line 16, in generate_cpi_detailed_graph_2()\n",
      "      6 series_ids = {\n",
      "      7     \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
      "      8     \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
      "   (...)\n",
      "     12     \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
      "     13 }\n",
      "     15 # Fetch the data from FRED\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17fb978d0>\n",
      "        series_ids = {'All Items': 'CPIAUCSL', 'Core CPI': 'CPILFESL', 'Food': 'CPIUFDNS', 'Energy': 'CPIENGSL', 'Core Services': 'CUSR0000SASLE', 'Core Goods': 'CUSR0000SACL1E'}\n",
      "     18 # Convert the data into a DataFrame\n",
      "     19 cpi_df = pd.DataFrame(cpi_data)\n",
      "\n",
      "Cell In[21], line 16, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     \"All Items\": \"CPIAUCSL\",               # All Items CPI\n",
      "      8     \"Core CPI\": \"CPILFESL\",                # Core CPI\n",
      "   (...)\n",
      "     12     \"Core Goods\": \"CUSR0000SACL1E\"         # Core Goods CPI\n",
      "     13 }\n",
      "     15 # Fetch the data from FRED\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17fb978d0>\n",
      "        name = 'Core Services'\n",
      "        series_id = 'CUSR0000SASLE'\n",
      "        name, series_id = ('Core Services', 'CUSR0000SASLE')\n",
      "     18 # Convert the data into a DataFrame\n",
      "     19 cpi_df = pd.DataFrame(cpi_data)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CUSR0000SASLE',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CUSR0000SASLE'\n",
      "        self = <fredapi.fred.Fred object at 0x17fb978d0>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...000SASLE&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x13c546160>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Error fetching data: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x30193f550>\n",
      "        req = <urllib.request.Request object at 0x16e917cd0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x30193f550>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17fa3c550>\n",
      "        request = <urllib.request.Request object at 0x16e917cd0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x16e917cd0>, <http.client.HTTPResponse object at 0x30193f550>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17fa3c550>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x16e917cd0>, <http.client.HTTPResponse object at 0x30193f550>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17fa3c550>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17fa3c550>\n",
      "        fp = <http.client.HTTPResponse object at 0x30193f550>\n",
      "        req = <urllib.request.Request object at 0x16e917cd0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 214, in update_cpi_detailed_graph_3(selected_data='CPI')\n",
      "    209 @app.callback(\n",
      "    210     Output('cpi-detailed-graph-3', 'figure'),\n",
      "    211     [Input('data-dropdown', 'value')]\n",
      "    212 )\n",
      "    213 def update_cpi_detailed_graph_3(selected_data):\n",
      "--> 214      return generate_cpi_detailed_graph_3() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[22], line 16, in generate_cpi_detailed_graph_3()\n",
      "      6 series_ids = {\n",
      "      7     'All Items': 'CPIAUCSL',         # All Items CPI\n",
      "      8     'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
      "   (...)\n",
      "     12     'Core Services': 'CUSR0000SASLE' # Core Services\n",
      "     13 }\n",
      "     15 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x16c78a390>\n",
      "        series_ids = {'All Items': 'CPIAUCSL', 'Core CPI': 'CPILFESL', 'Food': 'CPIUFDNS', 'Energy': 'CPIENGSL', 'Core Goods': 'CUSR0000SACL1E', 'Core Services': 'CUSR0000SASLE'}\n",
      "     17 df = pd.DataFrame(cpi_data)\n",
      "     19 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "Cell In[22], line 16, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items': 'CPIAUCSL',         # All Items CPI\n",
      "      8     'Core CPI': 'CPILFESL',          # Core CPI (less food and energy)\n",
      "   (...)\n",
      "     12     'Core Services': 'CUSR0000SASLE' # Core Services\n",
      "     13 }\n",
      "     15 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 16 cpi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x16c78a390>\n",
      "        name = 'Energy'\n",
      "        series_id = 'CPIENGSL'\n",
      "        name, series_id = ('Energy', 'CPIENGSL')\n",
      "     17 df = pd.DataFrame(cpi_data)\n",
      "     19 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='CPIENGSL',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=CPIENGSL'\n",
      "        self = <fredapi.fred.Fred object at 0x16c78a390>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...CPIENGSL&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x3001d1c60>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...22-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PCEPILFE&observation_start=2022-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...22-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PCEPILFE&observation_start=2022-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...22-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17f964be0>\n",
      "        req = <urllib.request.Request object at 0x300295ad0>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17f964be0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x30175e6d0>\n",
      "        request = <urllib.request.Request object at 0x300295ad0>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x300295ad0>, <http.client.HTTPResponse object at 0x17f964be0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x30175e6d0>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x300295ad0>, <http.client.HTTPResponse object at 0x17f964be0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x30175e6d0>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x30175e6d0>\n",
      "        fp = <http.client.HTTPResponse object at 0x17f964be0>\n",
      "        req = <urllib.request.Request object at 0x300295ad0>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 250, in update_cpi_detailed_graph_6(selected_data='CPI')\n",
      "    245 @app.callback(\n",
      "    246     Output('cpi-detailed-graph-6', 'figure'),\n",
      "    247     [Input('data-dropdown', 'value')]\n",
      "    248 )\n",
      "    249 def update_cpi_detailed_graph_6(selected_data):\n",
      "--> 250     return generate_cpi_detailed_graph_6() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[25], line 6, in generate_cpi_detailed_graph_6()\n",
      "      3 fred = Fred(api_key=api_key)\n",
      "      5 # Fetch Core PCE data starting from December 2022 to get accurate MoM for January 2023\n",
      "----> 6 data = fred.get_series('PCEPILFE', observation_start='2022-12-01')\n",
      "        fred = <fredapi.fred.Fred object at 0x17d093d50>\n",
      "      8 # Calculate month-over-month changes (annualized)\n",
      "      9 core_pce_mom_ann = data.pct_change().dropna() * 12 * 100\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PCEPILFE',\n",
      "    observation_start=Timestamp('2022-12-01 00:00:00'),\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PCEPILFE&observation_start=2022-12-01'\n",
      "        self = <fredapi.fred.Fred object at 0x17d093d50>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...22-12-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17aa81080>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIACO&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIACO&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIACO&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIACO&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...d=PPIACO&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x16c6e65c0>\n",
      "        req = <urllib.request.Request object at 0x17fdf1910>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x16c6e65c0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x16e8fd610>\n",
      "        request = <urllib.request.Request object at 0x17fdf1910>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17fdf1910>, <http.client.HTTPResponse object at 0x16c6e65c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x16e8fd610>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17fdf1910>, <http.client.HTTPResponse object at 0x16c6e65c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x16e8fd610>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x16e8fd610>\n",
      "        fp = <http.client.HTTPResponse object at 0x16c6e65c0>\n",
      "        req = <urllib.request.Request object at 0x17fdf1910>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 259, in update_cpi_detailed_graph_7(selected_data='CPI')\n",
      "    254 @app.callback(\n",
      "    255     Output('cpi-detailed-graph-7', 'figure'),\n",
      "    256     [Input('data-dropdown', 'value')]\n",
      "    257 )\n",
      "    258 def update_cpi_detailed_graph_7(selected_data):\n",
      "--> 259     return generate_cpi_detailed_graph_7() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[26], line 6, in generate_cpi_detailed_graph_7()\n",
      "      3 fred = Fred(api_key=api_key)\n",
      "      5 # Retrieve PPI data\n",
      "----> 6 ppiaco_data = fred.get_series('PPIACO')  # Producer Price Index for All Commodities\n",
      "        fred = <fredapi.fred.Fred object at 0x17fdf3c10>\n",
      "      7 ppifes_data = fred.get_series('PPIFES')  # Producer Price Index for Finished Goods\n",
      "      9 # Resample data monthly and compute the six-month annualized growth rate\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PPIACO',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIACO'\n",
      "        self = <fredapi.fred.Fred object at 0x17fdf3c10>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIACO&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x3001d2d40>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Error fetching series PPI with ID PPIACO: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cca6a70>\n",
      "        req = <urllib.request.Request object at 0x30172c210>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cca6a70>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17a7b00d0>\n",
      "        request = <urllib.request.Request object at 0x30172c210>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x30172c210>, <http.client.HTTPResponse object at 0x17cca6a70>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17a7b00d0>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x30172c210>, <http.client.HTTPResponse object at 0x17cca6a70>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17a7b00d0>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17a7b00d0>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cca6a70>\n",
      "        req = <urllib.request.Request object at 0x30172c210>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 268, in update_cpi_detailed_graph_8(selected_data='CPI')\n",
      "    263 @app.callback(\n",
      "    264     Output('cpi-detailed-graph-8', 'figure'),\n",
      "    265     [Input('data-dropdown', 'value')]\n",
      "    266 )\n",
      "    267 def update_cpi_detailed_graph_8(selected_data):\n",
      "--> 268     return generate_cpi_detailed_graph_8() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[27], line 17, in generate_cpi_detailed_graph_8(\n",
      "    selected_period='MoM',\n",
      "    months_for_table=30\n",
      ")\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',            # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',               # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'          # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch the data from FRED\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17c9d0710>\n",
      "        series_ids = {'All Items PPI': 'PPIFID', 'Core PPI': 'WPUFD413', 'Foods PPI': 'PPIFDF', 'Energy PPI': 'PPIFDE', 'Goods PPI': 'PPIFDG', 'Services PPI': 'PPIFDS', 'Construction PPI': 'PPIFDC'}\n",
      "     19 # Convert the data into a DataFrame\n",
      "     20 ppi_df = pd.DataFrame(ppi_data)\n",
      "\n",
      "Cell In[27], line 17, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',            # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',               # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'          # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch the data from FRED\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x17c9d0710>\n",
      "        name = 'All Items PPI'\n",
      "        series_id = 'PPIFID'\n",
      "        name, series_id = ('All Items PPI', 'PPIFID')\n",
      "     19 # Convert the data into a DataFrame\n",
      "     20 ppi_df = pd.DataFrame(ppi_data)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PPIFID',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID'\n",
      "        self = <fredapi.fred.Fred object at 0x17c9d0710>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x17ce56c00>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x137086620>\n",
      "        req = <urllib.request.Request object at 0x30011e150>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x137086620>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x30046edd0>\n",
      "        request = <urllib.request.Request object at 0x30011e150>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x30011e150>, <http.client.HTTPResponse object at 0x137086620>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x30046edd0>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x30011e150>, <http.client.HTTPResponse object at 0x137086620>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x30046edd0>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x30046edd0>\n",
      "        fp = <http.client.HTTPResponse object at 0x137086620>\n",
      "        req = <urllib.request.Request object at 0x30011e150>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 277, in update_cpi_detailed_graph_9(selected_data='CPI')\n",
      "    272 @app.callback(\n",
      "    273     Output('cpi-detailed-graph-9', 'figure'),\n",
      "    274     [Input('data-dropdown', 'value')]\n",
      "    275 )\n",
      "    276 def update_cpi_detailed_graph_9(selected_data):\n",
      "--> 277     return generate_cpi_detailed_graph_9() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[28], line 17, in generate_cpi_detailed_graph_9(contribution_type='MoM')\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',        # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'      # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x30011cd50>\n",
      "        series_ids = {'All Items PPI': 'PPIFID', 'Core PPI': 'WPUFD413', 'Foods PPI': 'PPIFDF', 'Energy PPI': 'PPIFDE', 'Goods PPI': 'PPIFDG', 'Services PPI': 'PPIFDS', 'Construction PPI': 'PPIFDC'}\n",
      "     18 df = pd.DataFrame(ppi_data)\n",
      "     20 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "Cell In[28], line 17, in <dictcomp>(.0=<dict_itemiterator object>)\n",
      "      6 series_ids = {\n",
      "      7     'All Items PPI': 'PPIFID',        # All Items PPI\n",
      "      8     'Core PPI': 'WPUFD413',           # Core PPI (Final Demand Goods Less Foods and Energy)\n",
      "   (...)\n",
      "     13     'Construction PPI': 'PPIFDC'      # Construction PPI\n",
      "     14 }\n",
      "     16 # Fetch data for each series from FRED and store in a DataFrame\n",
      "---> 17 ppi_data = {name: fred.get_series(series_id) for name, series_id in series_ids.items()}\n",
      "        fred = <fredapi.fred.Fred object at 0x30011cd50>\n",
      "        name = 'All Items PPI'\n",
      "        series_id = 'PPIFID'\n",
      "        name, series_id = ('All Items PPI', 'PPIFID')\n",
      "     18 df = pd.DataFrame(ppi_data)\n",
      "     20 # Ensure the DataFrame index is in datetime format\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='PPIFID',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=PPIFID'\n",
      "        self = <fredapi.fred.Fred object at 0x30011cd50>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...d=PPIFID&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x300000860>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/3162984980.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:22: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/lg/dbmt0tnx1h74vny5m2398l980000gr/T/ipykernel_64593/723068416.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Surprise Index: 0.006807070417542748\n",
      "Error fetching series PCE with ID PCEPI: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x3019399c0>\n",
      "        req = <urllib.request.Request object at 0x17a72c110>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x3019399c0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17fd73750>\n",
      "        request = <urllib.request.Request object at 0x17a72c110>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17a72c110>, <http.client.HTTPResponse object at 0x3019399c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17fd73750>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17a72c110>, <http.client.HTTPResponse object at 0x3019399c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x17fd73750>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x17fd73750>\n",
      "        fp = <http.client.HTTPResponse object at 0x3019399c0>\n",
      "        req = <urllib.request.Request object at 0x17a72c110>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 304, in update_cpi_detailed_graph_12(selected_data='CPI')\n",
      "    299 @app.callback(\n",
      "    300     Output('cpi-detailed-graph-12', 'figure'),\n",
      "    301     [Input('data-dropdown', 'value')]\n",
      "    302 )\n",
      "    303 def update_cpi_detailed_graph_12(selected_data):\n",
      "--> 304     return generate_cpi_detailed_graph_12() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[31], line 6, in generate_cpi_detailed_graph_12()\n",
      "      3 fred = Fred(api_key=api_key)\n",
      "      5 # Retrieve the expected inflation data for 1-year, 2-year, 3-year, and 5-year\n",
      "----> 6 expinf1yr = fred.get_series('EXPINF1YR')\n",
      "        fred = <fredapi.fred.Fred object at 0x17a72c1d0>\n",
      "      7 expinf2yr = fred.get_series('EXPINF2YR')\n",
      "      8 expinf3yr = fred.get_series('EXPINF3YR')\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='EXPINF1YR',\n",
      "    observation_start=None,\n",
      "    observation_end=None,\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=EXPINF1YR'\n",
      "        self = <fredapi.fred.Fred object at 0x17a72c1d0>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...XPINF1YR&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x3004ba9d0>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "HTTPError                                 Traceback (most recent call last)\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:84, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     83 try:\n",
      "---> 84     response = urlopen(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=GDPDEF&observation_start=2000-01-01&observation_end=2026-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "     85     root = ET.fromstring(response.read())\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:216, in urlopen(\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>,\n",
      "    cafile=None,\n",
      "    capath=None,\n",
      "    cadefault=False,\n",
      "    context=None\n",
      ")\n",
      "    215     opener = _opener\n",
      "--> 216 return opener.open(url, data, timeout)\n",
      "        opener = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=GDPDEF&observation_start=2000-01-01&observation_end=2026-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      "        data = None\n",
      "        timeout = <object object at 0x1009b8b00>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:525, in OpenerDirector.open(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    fullurl='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9',\n",
      "    data=None,\n",
      "    timeout=<object object>\n",
      ")\n",
      "    524     meth = getattr(processor, meth_name)\n",
      "--> 525     response = meth(req, response)\n",
      "        response = <http.client.HTTPResponse object at 0x17cbd50c0>\n",
      "        req = <urllib.request.Request object at 0x17fa35b50>\n",
      "        meth = <bound method HTTPErrorProcessor.http_response of <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>>\n",
      "    527 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:634, in HTTPErrorProcessor.http_response(\n",
      "    self=<urllib.request.HTTPErrorProcessor object>,\n",
      "    request=<urllib.request.Request object>,\n",
      "    response=<http.client.HTTPResponse object>\n",
      ")\n",
      "    633 if not (200 <= code < 300):\n",
      "--> 634     response = self.parent.error(\n",
      "        response = <http.client.HTTPResponse object at 0x17cbd50c0>\n",
      "        self.parent = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "        self = <urllib.request.HTTPErrorProcessor object at 0x13908b6d0>\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x3003d4c10>\n",
      "        request = <urllib.request.Request object at 0x17fa35b50>\n",
      "    635         'http', request, response, code, msg, hdrs)\n",
      "    637 return response\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:563, in OpenerDirector.error(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    proto=429,\n",
      "    *args=({'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]}, 'default', 'http_error_default', <urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    562 args = (dict, 'default', 'http_error_default') + orig_args\n",
      "--> 563 return self._call_chain(*args)\n",
      "        args = ({'default': [<urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>], 301: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 302: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 303: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 307: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>], 308: [<urllib.request.HTTPRedirectHandler object at 0x139089b50>]}, 'default', 'http_error_default', <urllib.request.Request object at 0x17fa35b50>, <http.client.HTTPResponse object at 0x17cbd50c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x3003d4c10>)\n",
      "        self = <urllib.request.OpenerDirector object at 0x1390a5810>\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:496, in OpenerDirector._call_chain(\n",
      "    self=<urllib.request.OpenerDirector object>,\n",
      "    chain={'default': [<urllib.request.HTTPDefaultErrorHandler object>], 301: [<urllib.request.HTTPRedirectHandler object>], 302: [<urllib.request.HTTPRedirectHandler object>], 303: [<urllib.request.HTTPRedirectHandler object>], 307: [<urllib.request.HTTPRedirectHandler object>], 308: [<urllib.request.HTTPRedirectHandler object>]},\n",
      "    kind='default',\n",
      "    meth_name='http_error_default',\n",
      "    *args=(<urllib.request.Request object>, <http.client.HTTPResponse object>, 429, 'Too Many Requests', <http.client.HTTPMessage object>)\n",
      ")\n",
      "    495 func = getattr(handler, meth_name)\n",
      "--> 496 result = func(*args)\n",
      "        func = <bound method HTTPDefaultErrorHandler.http_error_default of <urllib.request.HTTPDefaultErrorHandler object at 0x139088c10>>\n",
      "        args = (<urllib.request.Request object at 0x17fa35b50>, <http.client.HTTPResponse object at 0x17cbd50c0>, 429, 'Too Many Requests', <http.client.HTTPMessage object at 0x3003d4c10>)\n",
      "    497 if result is not None:\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/urllib/request.py:643, in HTTPDefaultErrorHandler.http_error_default(\n",
      "    self=<urllib.request.HTTPDefaultErrorHandler object>,\n",
      "    req=<urllib.request.Request object>,\n",
      "    fp=<http.client.HTTPResponse object>,\n",
      "    code=429,\n",
      "    msg='Too Many Requests',\n",
      "    hdrs=<http.client.HTTPMessage object>\n",
      ")\n",
      "    642 def http_error_default(self, req, fp, code, msg, hdrs):\n",
      "--> 643     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "        code = 429\n",
      "        msg = 'Too Many Requests'\n",
      "        hdrs = <http.client.HTTPMessage object at 0x3003d4c10>\n",
      "        fp = <http.client.HTTPResponse object at 0x17cbd50c0>\n",
      "        req = <urllib.request.Request object at 0x17fa35b50>\n",
      "\n",
      "HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[35], line 295, in update_cpi_detailed_graph_11(selected_data='CPI')\n",
      "    290 @app.callback(\n",
      "    291     Output('cpi-detailed-graph-11', 'figure'),\n",
      "    292     [Input('data-dropdown', 'value')]\n",
      "    293 )\n",
      "    294 def update_cpi_detailed_graph_11(selected_data):\n",
      "--> 295     return generate_cpi_detailed_graph_11() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[30], line 3, in generate_cpi_detailed_graph_11()\n",
      "      1 def generate_cpi_detailed_graph_11():\n",
      "      2     # Retrieve GDP deflator and CPI data from FRED\n",
      "----> 3     gdp_deflator = fred.get_series('GDPDEF', observation_start='2000-01-01', observation_end='2026-01-01')\n",
      "        fred = <fredapi.fred.Fred object at 0x13f0ac550>\n",
      "      4     cpi_qoq = fred.get_series('CPIAUCSL', observation_start='2000-01-01', observation_end='2026-01-01')\n",
      "      6     # Align both datasets to avoid mismatches in dates\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:151, in Fred.get_series(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    series_id='GDPDEF',\n",
      "    observation_start=Timestamp('2000-01-01 00:00:00'),\n",
      "    observation_end=Timestamp('2026-01-01 00:00:00'),\n",
      "    **kwargs={}\n",
      ")\n",
      "    149 if kwargs.keys():\n",
      "    150     url += '&' + urlencode(kwargs)\n",
      "--> 151 root = self.__fetch_data(url)\n",
      "        url = 'https://api.stlouisfed.org/fred/series/observations?series_id=GDPDEF&observation_start=2000-01-01&observation_end=2026-01-01'\n",
      "        self = <fredapi.fred.Fred object at 0x13f0ac550>\n",
      "    152 if root is None:\n",
      "    153     raise ValueError('No data exists for series id: ' + series_id)\n",
      "\n",
      "File /opt/anaconda3/lib/python3.11/site-packages/fredapi/fred.py:88, in Fred.__fetch_data(\n",
      "    self=<fredapi.fred.Fred object>,\n",
      "    url='https://api.stlouisfed.org/fred/series/observati...26-01-01&api_key=7227512392e5e5d2a2679a261d2bb3a9'\n",
      ")\n",
      "     86 except HTTPError as exc:\n",
      "     87     root = ET.fromstring(exc.read())\n",
      "---> 88     raise ValueError(root.get('message'))\n",
      "        root = <Element 'error' at 0x300108450>\n",
      "     89 return root\n",
      "\n",
      "ValueError: Too Many Requests.  Exceeded Rate Limit\n",
      "\n",
      "Error fetching series Cleveland Median CPI with ID MEDCPIM158SFRBCLE: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series 16% Trimmed Mean CPI with ID TRMMEANCPIM158SFRBCLE: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Sticky CPI with ID STICKCPIM157SFRBATL: Too Many Requests.  Exceeded Rate Limit\n",
      "Error fetching series Trimmed Mean PCE with ID PCETRIM1M158SFRBDAL: Too Many Requests.  Exceeded Rate Limit\n",
      "---------------------------------------------------------------------------\n",
      "IndexError                                Traceback (most recent call last)\n",
      "Cell In[35], line 179, in update_cpi_detailed_table_1(selected_data='CPI')\n",
      "    174 @app.callback(\n",
      "    175     Output('cpi-detailed-table-1', 'figure'),\n",
      "    176     [Input('data-dropdown', 'value')]\n",
      "    177 )\n",
      "    178 def update_cpi_detailed_table_1(selected_data):\n",
      "--> 179     return generate_cpi_detailed_table_1() if selected_data == 'CPI' else go.Figure()\n",
      "        selected_data == 'CPI' = True\n",
      "        selected_data = 'CPI'\n",
      "        go = <module 'plotly.graph_objects' from '/opt/anaconda3/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'>\n",
      "\n",
      "Cell In[32], line 93, in generate_cpi_detailed_table_1()\n",
      "     90         return f'rgba({red_intensity}, 0, 0, 0.6)'\n",
      "     92 # Create the initial table data (first window)\n",
      "---> 93 initial_window = windows[0]\n",
      "        windows = []\n",
      "     94 table_df = initial_window.transpose().round(2)\n",
      "     95 table_header_dates = table_df.columns.tolist()  # Corrected: Use columns (dates) for headers\n",
      "\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import investpy\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch economic calendar data for specific events\n",
    "def fetch_event_data(event_name, from_date='01/01/2020', to_date='today'):\n",
    "    # Fetch the global economic calendar data\n",
    "    data = investpy.economic_calendar(from_date=from_date, to_date=to_date)\n",
    "    # Filter for the specific event and the United States\n",
    "    event_data = data[(data['event'].str.contains(event_name, case=False)) & (data['country'] == 'United States')]\n",
    "    event_data['date'] = pd.to_datetime(event_data['date'])\n",
    "    return event_data[['date', 'actual', 'forecast']]\n",
    "\n",
    "# Fetch data for NFP, ADP, and Unemployment Rate\n",
    "nfp_data = fetch_event_data(\"Nonfarm Payrolls\")\n",
    "adp_data = fetch_event_data(\"ADP Nonfarm Employment Change\")\n",
    "unemployment_data = fetch_event_data(\"Unemployment Rate\")\n",
    "\n",
    "# Generate the employment detailed graph\n",
    "def generate_employment_detailed_graph(nfp_data, adp_data, unemployment_data):\n",
    "    def process_event_data(event_data):\n",
    "        # Ensure 'actual' and 'forecast' are numeric\n",
    "        event_data['actual'] = pd.to_numeric(event_data['actual'], errors='coerce')\n",
    "        event_data['forecast'] = pd.to_numeric(event_data['forecast'], errors='coerce')\n",
    "        event_data.dropna(subset=['actual', 'forecast'], inplace=True)\n",
    "\n",
    "        # Calculate the surprise\n",
    "        event_data['surprise'] = np.where(\n",
    "            event_data['forecast'] != 0,\n",
    "            (event_data['actual'] - event_data['forecast']) / event_data['forecast'] * 100,\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        # Select the last 30 data points\n",
    "        last_30_points = event_data.sort_values('date', ascending=False).head(30).sort_values('date')\n",
    "        df_table = last_30_points[['date', 'actual', 'forecast', 'surprise']].copy()\n",
    "        df_table.columns = ['Date', 'Actual', 'Forecast', 'Surprise']\n",
    "        df_table['Date'] = df_table['Date'].dt.strftime('%y-%m')\n",
    "        df_table.fillna(0, inplace=True)\n",
    "        df_table_transposed = df_table.set_index('Date').transpose()\n",
    "        return last_30_points, df_table_transposed\n",
    "\n",
    "    # Process each data category\n",
    "    nfp_points, nfp_table = process_event_data(nfp_data)\n",
    "    adp_points, adp_table = process_event_data(adp_data)\n",
    "    unemployment_points, unemployment_table = process_event_data(unemployment_data)\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=8, cols=1,\n",
    "        specs=[[{'type': 'xy'}], [{'type': 'xy'}], [{'type': 'table'}], [{'type': 'xy'}], [{'type': 'table'}],\n",
    "               [{'type': 'xy'}], [{'type': 'table'}], [{'type': 'table'}]],\n",
    "        subplot_titles=(\"Combined Graph\", \"NFP\", \"NFP Table\", \"ADP\", \"ADP Table\", \"Unemployment\", \"Unemployment Table\"),\n",
    "        vertical_spacing=0.05\n",
    "    )\n",
    "\n",
    "    # Combined Graph\n",
    "    fig.add_trace(go.Scatter(x=nfp_points['date'], y=nfp_points['actual'], mode='lines', name='NFP Actual', line=dict(color='cyan')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=adp_points['date'], y=adp_points['actual'], mode='lines', name='ADP Actual', line=dict(color='gray')), row=1, col=1)\n",
    "\n",
    "    # NFP Graph with Forecast\n",
    "    fig.add_trace(go.Scatter(x=nfp_points['date'], y=nfp_points['actual'], mode='lines', name='NFP Actual', line=dict(color='cyan')), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=nfp_points['date'], y=nfp_points['forecast'], mode='lines', name='NFP Forecast', line=dict(color='cyan', dash='dot')), row=2, col=1)\n",
    "\n",
    "    # NFP Table with heatmap\n",
    "    if not nfp_table.empty:\n",
    "        color_fill_nfp = create_color_fill(nfp_table)\n",
    "        fig.add_trace(go.Table(\n",
    "            header=dict(values=[\"Item\"] + list(nfp_table.columns), fill_color='black', font=dict(color='white', size=8), align='center'),\n",
    "            cells=dict(values=[nfp_table.index] + [nfp_table[col].round(2) for col in nfp_table.columns],\n",
    "                       fill=dict(color=[['black'] * len(nfp_table.columns)] + color_fill_nfp), font=dict(color='white', size=8),\n",
    "                       align='center', height=20)),\n",
    "            row=3, col=1\n",
    "        )\n",
    "\n",
    "    # Repeat for ADP and Unemployment plots and tables, as shown in the previous examples\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"Employment Data Overview - NFP, ADP, Unemployment\",\n",
    "        height=1800,\n",
    "        template='plotly_dark',\n",
    "        margin=dict(l=20, r=20, t=40, b=40),\n",
    "        font=dict(size=10),\n",
    "        showlegend=True,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate the graph\n",
    "fig = generate_employment_detailed_graph(nfp_data, adp_data, unemployment_data)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b231bd-5ae1-4810-92f2-9e1b0fbbaaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8e9eb-7994-4ad2-a588-a19057ee748d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
